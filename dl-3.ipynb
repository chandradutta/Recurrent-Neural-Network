{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport copy\nimport random","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-05-17T05:44:54.702522Z","iopub.execute_input":"2024-05-17T05:44:54.702901Z","iopub.status.idle":"2024-05-17T05:45:12.796025Z","shell.execute_reply.started":"2024-05-17T05:44:54.702870Z","shell.execute_reply":"2024-05-17T05:45:12.794947Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nfrom wandb.keras import WandbCallback\nimport socket\nsocket.setdefaulttimeout(30)\nwandb.login()\nwandb.init(project ='vanillaRNN')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:45:12.798070Z","iopub.execute_input":"2024-05-17T05:45:12.798515Z","iopub.status.idle":"2024-05-17T05:46:37.102403Z","shell.execute_reply.started":"2024-05-17T05:45:12.798486Z","shell.execute_reply":"2024-05-17T05:46:37.101320Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"2024-05-17 05:45:28.320153: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-17 05:45:28.320294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-17 05:45:28.425201: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchandraduttamamidi\u001b[0m (\u001b[33mcs23m021\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_054620-gg22ul3y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/vanillaRNN/runs/gg22ul3y' target=\"_blank\">lucky-darkness-28</a></strong> to <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/vanillaRNN/runs/gg22ul3y' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/runs/gg22ul3y</a>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cs23m021/vanillaRNN/runs/gg22ul3y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7913028c2b30>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:37.103757Z","iopub.execute_input":"2024-05-17T05:46:37.104098Z","iopub.status.idle":"2024-05-17T05:46:37.158485Z","shell.execute_reply.started":"2024-05-17T05:46:37.104063Z","shell.execute_reply":"2024-05-17T05:46:37.157382Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"trainCSV = \"/kaggle/input/telugu/tel/tel_train.csv\"\nvalidCSV = \"/kaggle/input/telugu/tel/tel_valid.csv\"\ntestCSV = \"/kaggle/input/telugu/tel/tel_test.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:37.161366Z","iopub.execute_input":"2024-05-17T05:46:37.161753Z","iopub.status.idle":"2024-05-17T05:46:37.177328Z","shell.execute_reply.started":"2024-05-17T05:46:37.161721Z","shell.execute_reply":"2024-05-17T05:46:37.176240Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainingData = pd.read_csv(trainCSV, header=None)\nvalidationData = pd.read_csv(validCSV,header = None)\ntestData = pd.read_csv(testCSV,header= None)\n\n\ntrainingInput = trainingData[0].to_numpy()\ntrainingOutput = trainingData[1].to_numpy()\n#the size of input and output is 4096\nvalidationInput = validationData[0].to_numpy()\nvalidationOutput = validationData[1].to_numpy()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:37.179895Z","iopub.execute_input":"2024-05-17T05:46:37.180338Z","iopub.status.idle":"2024-05-17T05:46:37.353100Z","shell.execute_reply.started":"2024-05-17T05:46:37.180302Z","shell.execute_reply":"2024-05-17T05:46:37.351933Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"maxLength = 0\nmaxLengthElement =''\n# Loop through elements in validationInput\nfor element in validationInput:\n    maxLength = max(maxLength,len(element))\n    if(maxLength == len(element)):\n        maxLengthElement=element\n\nmaxLength =0 \nmaxLengthElement =''\n# Loop through elements in validationOutput\nfor element in validationOutput:\n    maxLength = max(maxLength,len(element))\n    if(maxLength == len(element)):\n        maxLengthElement=element    ","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:37.354593Z","iopub.execute_input":"2024-05-17T05:46:37.354915Z","iopub.status.idle":"2024-05-17T05:46:37.373335Z","shell.execute_reply.started":"2024-05-17T05:46:37.354888Z","shell.execute_reply":"2024-05-17T05:46:37.371582Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def preProcessTheData(input, output, validation):\n    data = {\n        \"allCharacters1\" : [],\n        \"charNumMap1\" : {},\n        \"numCharMap1\" : {},\n        \"inputCharToNum\": torch.zeros(len(input),30, dtype=torch.int, device=device),\n        \"inputData\" : input,\n            \n        \"allCharacters2\" : [],\n        \"charNumMap2\" : {},\n        \"numCharMap2\" : {},\n        \"outputCharToNum\": torch.zeros(len(output),23, dtype=torch.int, device=device),\n        \"outputData\" : output,\n        \n        \"inputLength\" : 0,\n        \"outputLength\" : 0\n    }\n    \n    k = 0 \n\n    m1 = data[\"charNumMap1\"]\n    m2 = data[\"charNumMap2\"]\n    if validation:\n        m1 = preProcessedData[\"charNumMap1\"]\n        m2 = preProcessedData[\"charNumMap2\"]\n\n    for i in range(0,len(input)):\n        input[i] = \"{\" + input[i] + \"}\"*(29-len(input[i]))\n        charToNum = []\n        for char in (input[i]):\n            index = 0\n            if(char not in data[\"allCharacters1\"]):\n                data[\"allCharacters1\"].append(char)\n                if validation:\n                    index = m1[char]\n                else:\n                    index = data[\"allCharacters1\"].index(char)\n                data[\"charNumMap1\"][char] = index\n                data[\"numCharMap1\"][index] = char\n            else:\n                if validation:\n                    index = m1[char]\n                else:\n                    index = data[\"allCharacters1\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"inputCharToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        output[i] = \"{\" + output[i] + \"}\"*(22-len(output[i]))\n        for char in (output[i]):\n            index = 0\n            if(char not in data[\"allCharacters2\"]):\n                data[\"allCharacters2\"].append(char)\n                if validation:\n                    index = m2[char]\n                else:\n                    index = data[\"allCharacters2\"].index(char)\n                data[\"charNumMap2\"][char] = index\n                data[\"numCharMap2\"][index] = char\n            else:\n                if validation:\n                    index = m2[char]\n                else:\n                    index = data[\"allCharacters2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"outputCharToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"inputLength\"] = len(data[\"allCharacters1\"])\n    data[\"outputLength\"] = len(data[\"allCharacters2\"])\n        \n    return data\n\npreProcessedData = preProcessTheData(copy.copy(trainingInput),copy.copy(trainingOutput), False)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:37.375699Z","iopub.execute_input":"2024-05-17T05:46:37.376071Z","iopub.status.idle":"2024-05-17T05:46:45.810948Z","shell.execute_reply.started":"2024-05-17T05:46:37.376037Z","shell.execute_reply":"2024-05-17T05:46:45.809761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessedValidationData = preProcessTheData(copy.copy(validationInput),copy.copy(validationOutput), True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:45.812638Z","iopub.execute_input":"2024-05-17T05:46:45.813033Z","iopub.status.idle":"2024-05-17T05:46:46.390562Z","shell.execute_reply.started":"2024-05-17T05:46:45.812997Z","shell.execute_reply":"2024-05-17T05:46:46.389224Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class createDataset(Dataset):\n    def __getitem__(self, idx):\n        inputData = self.source[idx]\n        outputData = self.target[idx]\n        return inputData, outputData\n    def __len__(self):\n        return len(self.source)\n    \n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:46.392039Z","iopub.execute_input":"2024-05-17T05:46:46.394433Z","iopub.status.idle":"2024-05-17T05:46:46.402717Z","shell.execute_reply.started":"2024-05-17T05:46:46.394391Z","shell.execute_reply":"2024-05-17T05:46:46.401572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data = preProcessTheData(copy.copy(trainingInput),copy.copy(trainingOutput), False)\n\ndef getDataLoader(mode, batchSize):\n    if(mode == 'train'):\n        dataset = createDataset(data[\"inputCharToNum\"],data['outputCharToNum'])\n        return DataLoader(dataset, batch_size=batchSize, shuffle=True)\n    else:\n        dataset = createDataset(preprocessedValidationData[\"inputCharToNum\"],preprocessedValidationData['outputCharToNum'])\n        return  DataLoader(dataset, batch_size=batchSize, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:46.406373Z","iopub.execute_input":"2024-05-17T05:46:46.406751Z","iopub.status.idle":"2024-05-17T05:46:54.511953Z","shell.execute_reply.started":"2024-05-17T05:46:46.406713Z","shell.execute_reply":"2024-05-17T05:46:54.510813Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def evaluateModelPerformance(encoder, decoder, batchSize, temporalFusionParameter):\n    \n    dataLoader = getDataLoader(\"validation\", batchSize) # Fetch data loader based on the operation mode\n    decoder.eval()\n    encoder.eval()\n    \n    \n    accumulatedValidationAccuracy = 0\n    totalValidationLoss = 0\n    \n    lossCriterion = nn.NLLLoss()\n    \n    for batchIndex, (sourceSequence, targetSequence) in enumerate(dataLoader):\n        \n        initialEncoderState = encoder.getInitialState() \n        \n        encoderOutput, currentStateAfterEncoding = encoder(sourceSequence, initialEncoderState)\n\n        cumulativeLoss = 0 \n\n        sequenceLength = targetSequence.shape[1]\n\n        predictedOutputs = []\n\n        randomSelectionFactor = random.random()\n\n        currentDecoderState = currentStateAfterEncoding\n\n        for index in range(sequenceLength):\n\n            if(index == 0):\n                inputTensorForDecoder = targetSequence[:, index].view(batchSize, 1) # Reshape to match expected dimensions\n            else:\n                if randomSelectionFactor < temporalFusionParameter:\n                    inputTensorForDecoder = targetSequence[:, index].view(batchSize, 1) # Pass current batch element\n                else:\n                    inputTensorForDecoder = inputTensorForDecoder.view(batchSize, 1) # Pass previously selected element\n\n            decodedOutput, updatedDecoderState = decoder(inputTensorForDecoder, currentDecoderState)\n            topValues, topIndices = decodedOutput.topk(1)  # Retrieve top values and their indices\n            inputTensorForDecoder = topIndices.squeeze().detach() # Convert to 1D tensor\n            predictedOutputs.append(inputTensorForDecoder) # Append softmax values\n                    \n            decodedOutput = decodedOutput[:, -1, :] # Reduce size from (batchSize*1*embeddingSize) to (batchSize*embeddingSize)\n\n            targetCharacters = targetSequence[:, index] #(batchSize)\n            targetCharacters = targetCharacters.type(dtype=torch.long)\n\n            cumulativeLoss += lossCriterion(decodedOutput, targetCharacters) # Pass softmax values to target characters\n\n        stackedPredictions = torch.stack(predictedOutputs)\n        predictionsMatrix = stackedPredictions.transpose(0, 1) # Transpose to match expected format\n\n        accumulatedValidationAccuracy += (predictionsMatrix == targetSequence).all(dim=1).sum().item() # Sum up matching values\n        totalValidationLoss += (cumulativeLoss.item()/sequenceLength)\n\n        if(batchIndex % 20 == 0):\n            print(f\"Batch: {batchIndex}, Loss: {cumulativeLoss.item()/sequenceLength}\")\n    \n    encoder.train()\n    decoder.train()\n#     print(f\"Validation Accuracy: {accumulatedValidationAccuracy/40.96}\")\n#     print(f\"Validation Loss: {totalValidationLoss}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:54.513351Z","iopub.execute_input":"2024-05-17T05:46:54.513666Z","iopub.status.idle":"2024-05-17T05:46:54.529321Z","shell.execute_reply.started":"2024-05-17T05:46:54.513639Z","shell.execute_reply":"2024-05-17T05:46:54.528424Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self, inputDimension, embeddingSize, layerCount, neuronCount, cellType, batchSize):\n        super(Encoder, self).__init__()\n        self.embeddingLayer = nn.Embedding(inputDimension, embeddingSize)\n        self.layerStack = layerCount\n        self.neuronCountInHiddenLayer = neuronCount\n        self.batchSize = batchSize\n        \n        if(cellType=='GRU'):\n            self.recurrentLayer = nn.GRU(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n        elif(cellType=='LSTM'):\n            self.recurrentLayer = nn.LSTM(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n        else:\n            self.recurrentLayer = nn.RNN(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n    \n    def getInitialState(self):\n        return torch.zeros(self.layerStack, self.batchSize, self.neuronCountInHiddenLayer, device=device)\n            \n    def forward(self, inputData, previousState):\n        embeddedInput = self.embeddingLayer(inputData)\n        output, stateAfterPassing = self.recurrentLayer(embeddedInput, previousState)\n        return output, stateAfterPassing\n    \n    \nclass Decoder(nn.Module):\n    def __init__(self, outputDimension, embeddingSize, neuronCount, layerCount, cellType, dropoutProbability):\n        super(Decoder, self).__init__()\n        self.embeddingLayerForOutput = nn.Embedding(outputDimension, embeddingSize)\n        \n        if(cellType==\"GRU\"):\n            self.recurrentLayerForOutput = nn.GRU(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n        elif(cellType==\"LSTM\"):\n            self.recurrentLayerForOutput = nn.LSTM(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n        else:\n            self.recurrentLayerForOutput = nn.RNN(embeddingSize, neuronCount, num_layers=layerCount, batch_first=True)\n            \n        self.finalLinearTransformation = nn.Linear(neuronCount, outputDimension)\n        self.applySoftMax = nn.LogSoftmax(dim=2)\n        self.dropOutLayer = nn.Dropout(dropoutProbability)\n\n    def forward(self, currentInput, previousState):\n        embeddedCurrentInput = self.embeddingLayerForOutput(currentInput)\n        processedInput = F.relu(embeddedCurrentInput)\n        outputFromRecurrent, stateAfterProcessing = self.recurrentLayerForOutput(processedInput, previousState)\n        outputFromRecurrent = self.dropOutLayer(outputFromRecurrent)\n        finalOutput = self.applySoftMax(self.finalLinearTransformation(outputFromRecurrent))\n        return finalOutput, stateAfterProcessing\n","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:54.530846Z","iopub.execute_input":"2024-05-17T05:46:54.531420Z","iopub.status.idle":"2024-05-17T05:46:54.548400Z","shell.execute_reply.started":"2024-05-17T05:46:54.531387Z","shell.execute_reply":"2024-05-17T05:46:54.547340Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def num_to_char_converter(source_array, target_array, data):\n    num_to_char_map = data['numCharMap2']\n    source_string = ''\n    target_string = ''\n    for source_row, target_row in zip(source_array, target_array):\n        source_string = ''\n        target_string = ''\n        for source_element, target_element in zip(source_row, target_row):\n            source_string += num_to_char_map[source_element.item()]\n            target_string += num_to_char_map[target_element.item()]\n        print(source_string, \" \", target_string)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:54.549839Z","iopub.execute_input":"2024-05-17T05:46:54.550488Z","iopub.status.idle":"2024-05-17T05:46:54.560909Z","shell.execute_reply.started":"2024-05-17T05:46:54.550452Z","shell.execute_reply":"2024-05-17T05:46:54.559789Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def modelTrainingProcess(embeddingSize, encoderLayerCount, decoderLayerCount, hiddenNeuronsPerLayer, cellType, bidirectionalOption, dropoutRate, numberOfTrainingEpochs, batchSizeForTraining, learningRateValue, chosenOptimizer, temporalFusionThreshold):\n   \n    dataLoaderInstance = getDataLoader(\"train\", batchSizeForTraining) # Data loader setup for training\n    \n    encoderInstance = Encoder(data[\"inputLength\"], embeddingSize, encoderLayerCount, hiddenNeuronsPerLayer, cellType, batchSizeForTraining).to(device)\n    decoderInstance = Decoder(data[\"outputLength\"], embeddingSize, hiddenNeuronsPerLayer, encoderLayerCount, cellType, dropoutRate).to(device)\n    \n    if(chosenOptimizer == 'Adam'):\n        optimizerForEncoder = optim.Adam(encoderInstance.parameters(), lr=learningRateValue)\n        optimizerForDecoder = optim.Adam(decoderInstance.parameters(), lr=learningRateValue)\n    else:\n        optimizerForEncoder = optim.NAdam(encoderInstance.parameters(), lr=learningRateValue)\n        optimizerForDecoder = optim.NAdam(decoderInstance.parameters(), lr=learningRateValue)\n    \n    lossCalculationMethod = nn.NLLLoss()\n\n    for epochIteration in range(numberOfTrainingEpochs):\n    \n        accumulatedTrainAccuracy = 0 \n        totalTrainLoss = 0 \n\n        for batchIndex, (sourceDataBatch, targetDataBatch) in enumerate(dataLoaderInstance):\n                        \n            initialEncoderState = encoderInstance.getInitialState() \n            \n            if(bidirectionalOption == \"Yes\"):\n                flippedSourceBatch = torch.flip(sourceDataBatch, dims=[1]) # Reverse the batch along rows\n                sourceDataBatch = (sourceDataBatch + flippedSourceBatch)//2 # Average reversed and original batches\n                \n            encodedOutput, currentStateAfterEncoding = encoderInstance(sourceDataBatch, initialEncoderState)\n            \n            lossAccumulator = 0 \n            \n            sequenceLength = targetDataBatch.shape[1]\n\n            predictedSequence = []\n            \n            randomChoiceFactor = random.random()\n\n            currentDecoderState = currentStateAfterEncoding\n\n            for indexPosition in range(sequenceLength):\n                \n                if(indexPosition == 0):\n                    inputTensorForDecoding = targetDataBatch[:, indexPosition].view(batchSizeForTraining, 1) # Reshape to match expected dimensions\n                else:\n                    if randomChoiceFactor < temporalFusionThreshold:\n                        inputTensorForDecoding = targetDataBatch[:, indexPosition].view(batchSizeForTraining, 1) # Pass current batch element\n                    else:\n                        inputTensorForDecoding = inputTensorForDecoding.view(batchSizeForTraining, 1) # Pass previously selected element\n\n                decodedResult, updatedDecoderState = decoderInstance(inputTensorForDecoding, currentDecoderState)\n                topValuedIndices, topIndexPositions = decodedResult.topk(1)  # Get top values and their indices\n               \n                inputTensorForDecoding = topIndexPositions.squeeze().detach() # Convert to 1D tensor\n                predictedSequence.append(inputTensorForDecoding) # Append softmax values\n                    \n                decodedResult = decodedResult[:, -1, :] # Reduce size from (batchSize*1*embeddingSize) to (batchSize*embeddingSize)\n\n                targetCharacterIndices = targetDataBatch[:, indexPosition] #(batchSize)\n                targetCharacterIndices = targetCharacterIndices.type(dtype=torch.long)\n\n                lossAccumulator += lossCalculationMethod(decodedResult, targetCharacterIndices) # Pass softmax values to target characters\n\n            stackedPredictions = torch.stack(predictedSequence)\n            predictionsMatrix = stackedPredictions.transpose(0, 1) # Transpose to match expected format\n\n            if(batchIndex == 0 and epochIteration == numberOfTrainingEpochs-1):\n                num_to_char_converter(targetDataBatch, predictionsMatrix, data) \n\n            accumulatedTrainAccuracy += (predictionsMatrix == targetDataBatch).all(dim=1).sum().item() # Sum up matching values\n            totalTrainLoss += (lossAccumulator.item()/sequenceLength)\n            \n            optimizerForEncoder.zero_grad()\n            optimizerForDecoder.zero_grad()\n            lossAccumulator.backward()\n            optimizerForEncoder.step()\n            optimizerForDecoder.step()\n            \n        print(f\"Train Accuracy: {accumulatedTrainAccuracy/512}\")\n        print(f\"Train Loss: {totalTrainLoss}\")\n        evaluateModelPerformance(encoderInstance,decoderInstance,batchSizeForTraining,temporalFusionThreshold)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:54.562533Z","iopub.execute_input":"2024-05-17T05:46:54.563566Z","iopub.status.idle":"2024-05-17T05:46:54.592297Z","shell.execute_reply.started":"2024-05-17T05:46:54.563526Z","shell.execute_reply":"2024-05-17T05:46:54.591340Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='vanillaRNN')\n    params = wandb.config\n    with wandb.init(project = 'vanillaRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n        modelTrainingProcess(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DeepLearningAssignment3',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'validation_accuracy',\n    },\n    'parameters' : {\n        'embSize':{'values':[16,32,64]},\n        'encoderLayers':{'values':[1,5,10]},\n        'decoderLayers' : {'values' : [1,5,10]},\n        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n        'cellType' : {'values' : ['GRU'] } ,\n        'bidirection' : {'values' : ['no']},\n        'dropout' : {'values' : [0,0.2,0.3]},\n        'epochs'  : {'values': [10,20,30]},\n        'batchsize' : {'values' : [32,64]},\n        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n        'optimizer':{'values' : ['Adam','Nadam']},\n        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'vanillaRNN')\nwandb.agent(sweepId,function =main_fun,count = 2)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-17T05:46:54.593538Z","iopub.execute_input":"2024-05-17T05:46:54.594459Z","iopub.status.idle":"2024-05-17T05:49:25.526270Z","shell.execute_reply.started":"2024-05-17T05:46:54.594420Z","shell.execute_reply":"2024-05-17T05:49:25.525340Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: 66qndl4s\nSweep URL: https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r0l68hmn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.2\n","output_type":"stream"},{"name":"stdout","text":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n<IPython.core.display.HTML object>\n<IPython.core.display.HTML object>\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\nException in thread IntMsgThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    return self._deliver_stop_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n        self.run()return self._deliver_record(record)    \n\nself._loop_check_status(  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n    return self._deliver_internal_messages(internal_message)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    return self._deliver_network_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    handle = mailbox._deliver_record(record, interface=self)\n      File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\ninterface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n        self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\ninterface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    self.send_server_request(server_req)\n      File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\nsent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_054702-r0l68hmn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">fresh-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:r0l68hmn) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fresh-sweep-1</strong> at: <a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn</a><br/> View project at: <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_054702-r0l68hmn/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:r0l68hmn). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_054718-r0l68hmn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">embedding16cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/sweeps/66qndl4s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn</a>"},"metadata":{}},{"name":"stdout","text":"Batch Index: 0, Loss: 4.130984099014945\nBatch Index: 200, Loss: 2.1057168711786685\nBatch Index: 400, Loss: 2.09216772991678\nBatch Index: 600, Loss: 0.30458985204282013\nBatch Index: 800, Loss: 0.3610176832779594\nBatch Index: 1000, Loss: 0.37117497817329737\nBatch Index: 1200, Loss: 1.801563428795856\nBatch Index: 1400, Loss: 1.8346156244692595\nTrain Accuracy: 2.0390625\nTrain Loss: 2778.2933566052\nBatch: 0, Loss: 0.2198844163314156\nBatch: 20, Loss: 1.5503092226774797\nBatch: 40, Loss: 1.5099094225012737\nBatch: 60, Loss: 0.20830550401107126\nBatch: 80, Loss: 1.485968714175017\nBatch: 100, Loss: 0.22671942088914954\nBatch: 120, Loss: 1.756406535273013\nValidation Accuracy: 0.0\nValidation Loss: 162.40367868672251\nBatch Index: 0, Loss: 0.23031504257865573\nBatch Index: 200, Loss: 1.9195616348930027\nBatch Index: 400, Loss: 0.47616062993588654\nBatch Index: 600, Loss: 2.00346158898395\nBatch Index: 800, Loss: 1.8199285424273948\nBatch Index: 1000, Loss: 2.064175813094429\nBatch Index: 1200, Loss: 1.937184706978176\nBatch Index: 1400, Loss: 1.8041889356530232\nTrain Accuracy: 2.13671875\nTrain Loss: 2528.8846667642224\nBatch: 0, Loss: 1.6509621661642324\nBatch: 20, Loss: 1.788902946140455\nBatch: 40, Loss: 1.713933861773947\nBatch: 60, Loss: 1.5188139210576597\nBatch: 80, Loss: 1.5445913231891135\nBatch: 100, Loss: 1.6216833695121433\nBatch: 120, Loss: 1.523546965225883\nValidation Accuracy: 0.0\nValidation Loss: 173.81038047956383\nBatch Index: 0, Loss: 2.0000683328379756\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Batch Index: 200, Loss: 1.8888398875360903","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding16cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN/runs/r0l68hmn</a><br/> View project at: <a href='https://wandb.ai/cs23m021/vanillaRNN' target=\"_blank\">https://wandb.ai/cs23m021/vanillaRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240517_054718-r0l68hmn/logs</code>"},"metadata":{}},{"name":"stdout","text":"Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x79141c0ce170>> (for post_run_cell), with arguments args (<ExecutionResult object at 791302910fd0, execution_count=15 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 791302913f40, raw_cell=\"def main_fun():\n    wandb.init(project ='vanillaRN..\" store_history=True silent=False shell_futures=True cell_id=7fcc390b-34e7-4b04-907c-b612d189218c> result=None>,),kwargs {}:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:433\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:682\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}