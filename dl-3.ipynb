{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T18:54:52.407701Z","iopub.execute_input":"2024-05-16T18:54:52.408103Z","iopub.status.idle":"2024-05-16T18:54:56.959494Z","shell.execute_reply.started":"2024-05-16T18:54:52.408060Z","shell.execute_reply":"2024-05-16T18:54:56.958582Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nfrom wandb.keras import WandbCallback\nimport socket\nsocket.setdefaulttimeout(30)\nwandb.login()\nwandb.init(project ='DL_Assignment_3')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:54:56.961203Z","iopub.execute_input":"2024-05-16T18:54:56.961616Z","iopub.status.idle":"2024-05-16T18:57:06.034072Z","shell.execute_reply.started":"2024-05-16T18:54:56.961590Z","shell.execute_reply":"2024-05-16T18:57:06.032531Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"2024-05-16 18:55:13.143138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-16 18:55:13.143238: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-16 18:55:13.314619: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchandraduttamamidi\u001b[0m (\u001b[33mcs23m021\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_185648-99ndoa1r</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/99ndoa1r' target=\"_blank\">iconic-breeze-74</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/99ndoa1r' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/99ndoa1r</a>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cs23m021/DL_Assignment_3/runs/99ndoa1r?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x786e9c1eaf20>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# print(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:06.035584Z","iopub.execute_input":"2024-05-16T18:57:06.036227Z","iopub.status.idle":"2024-05-16T18:57:06.149438Z","shell.execute_reply.started":"2024-05-16T18:57:06.036188Z","shell.execute_reply":"2024-05-16T18:57:06.148103Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_csv = \"/kaggle/input/telugu/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/telugu/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/telugu/tel/tel_valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:06.152458Z","iopub.execute_input":"2024-05-16T18:57:06.152839Z","iopub.status.idle":"2024-05-16T18:57:06.160132Z","shell.execute_reply.started":"2024-05-16T18:57:06.152783Z","shell.execute_reply":"2024-05-16T18:57:06.158590Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv,header = None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv,header= None)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:06.161922Z","iopub.execute_input":"2024-05-16T18:57:06.163947Z","iopub.status.idle":"2024-05-16T18:57:06.367178Z","shell.execute_reply.started":"2024-05-16T18:57:06.163857Z","shell.execute_reply":"2024-05-16T18:57:06.364238Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# print(train_output[0][5]) #the size of input and output is 4096\n# maxi = 0\n# t =''\n# for x in val_input:\n#     maxi = max(maxi,len(x))\n#     if(maxi == len(x)):\n#         t=x\n        \n# print(maxi,t)\n# t =''\n# maxi =0 \n# for x in val_output:\n#     maxi = max(maxi,len(x))\n#     if(maxi == len(x)):\n#         t=x\n        \n# print(maxi,t)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:06.368696Z","iopub.execute_input":"2024-05-16T18:57:06.369102Z","iopub.status.idle":"2024-05-16T18:57:06.375440Z","shell.execute_reply.started":"2024-05-16T18:57:06.369064Z","shell.execute_reply":"2024-05-16T18:57:06.374385Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\ndef pre_processing(train_input,train_output):\n    data = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device),\n    \"source_data\" : train_input,\n        \n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device),\n    \"target_data\" : train_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    for i in range(0,len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n        charToNum = []\n        for char in (train_input[i]):\n            index = 0\n            if(char not in data[\"all_characters\"]):\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n        for char in (train_output[i]):\n            index = 0\n            if(char not in data[\"all_characters_2\"]):\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n        \n    return data\n    \n    \ndata = pre_processing(copy.copy(train_input),copy.copy(train_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data[\"source_charToNum\"])\nprint(data['val_charToNum'])\nprint(data[\"num_char_map_2\"])\nprint(data[\"num_char_map\"])\nprint(train_input[0])\nprint(data['source_len'])\nprint(data['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:06.376937Z","iopub.execute_input":"2024-05-16T18:57:06.377821Z","iopub.status.idle":"2024-05-16T18:57:14.199072Z","shell.execute_reply.started":"2024-05-16T18:57:06.377765Z","shell.execute_reply":"2024-05-16T18:57:14.197854Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([[ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0, 13,  2,  ...,  9,  9,  9],\n        ...,\n        [ 0,  1,  8,  ...,  9,  9,  9],\n        [ 0,  3, 16,  ...,  9,  9,  9],\n        [ 0, 14, 20,  ...,  9,  9,  9]], device='cuda:0', dtype=torch.int32)\ntensor([[ 0,  1,  2,  ..., 10, 10, 10],\n        [ 0,  1, 11,  ..., 10, 10, 10],\n        [ 0, 14,  3,  ..., 10, 10, 10],\n        ...,\n        [ 0,  1, 25,  ..., 10, 10, 10],\n        [ 0,  2, 20,  ..., 10, 10, 10],\n        [ 0, 27, 25,  ..., 10, 10, 10]], device='cuda:0', dtype=torch.int32)\n{0: '{', 1: 'వ', 2: 'ర', 3: '్', 4: 'గ', 5: 'ా', 6: 'ల', 7: 'ి', 8: 'న', 9: 'ే', 10: '}', 11: 'స', 12: 'త', 13: 'ద', 14: 'ఫ', 15: 'య', 16: 'క', 17: 'ట', 18: 'మ', 19: 'ో', 20: 'ూ', 21: 'ళ', 22: 'ప', 23: 'ధ', 24: 'ు', 25: 'ె', 26: 'ం', 27: 'చ', 28: 'ై', 29: 'డ', 30: 'ఖ', 31: 'ఉ', 32: 'ష', 33: 'ఆ', 34: 'ొ', 35: 'శ', 36: 'అ', 37: 'భ', 38: 'ృ', 39: 'ణ', 40: 'హ', 41: 'జ', 42: 'ీ', 43: 'ఇ', 44: 'బ', 45: 'ఐ', 46: 'ఒ', 47: 'ఎ', 48: 'ౌ', 49: 'థ', 50: 'ఈ', 51: 'ఊ', 52: 'ఏ', 53: 'ఢ', 54: 'ఓ', 55: 'ఔ', 56: 'ఞ', 57: 'ఠ', 58: 'ఘ', 59: 'ఛ', 60: 'ః', 61: 'ఝ', 62: 'ఋ', 63: 'ఱ'}\n{0: '{', 1: 'v', 2: 'a', 3: 'r', 4: 'g', 5: 'l', 6: 'i', 7: 'n', 8: 'e', 9: '}', 10: 's', 11: 't', 12: 'd', 13: 'f', 14: 'c', 15: 'm', 16: 'o', 17: 'u', 18: 'w', 19: 'p', 20: 'h', 21: 'k', 22: 'y', 23: 'b', 24: 'j', 25: 'z', 26: 'x', 27: 'q'}\nvargaalavaarine\n28\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_input[2])\nprint(train_output[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.200600Z","iopub.execute_input":"2024-05-16T18:57:14.201021Z","iopub.status.idle":"2024-05-16T18:57:14.208599Z","shell.execute_reply.started":"2024-05-16T18:57:14.200986Z","shell.execute_reply":"2024-05-16T18:57:14.207491Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"factamfos\nఫ్యాక్టమ్ఫోస్\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing_validation(val_input,val_output):\n    data2 = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n    \"source_data\" : val_input,\n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n    \"target_data\" : val_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    \n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(0,len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n        charToNum = []\n        for char in (val_input[i]):\n            index = 0\n            if(char not in data2[\"all_characters\"]):\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data2[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n        for char in (val_output[i]):\n            index = 0\n            if(char not in data2[\"all_characters_2\"]):\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n        \n    return data2\n    \n    \ndata2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data2[\"num_char_map\"])\nprint(data2[\"source_charToNum\"].shape)\n\nprint(data2[\"num_char_map_2\"])\nprint(data2['val_charToNum'][0])\n\n\nprint(val_input[0])\nprint(data2['source_len'])\nprint(data2['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.210292Z","iopub.execute_input":"2024-05-16T18:57:14.210614Z","iopub.status.idle":"2024-05-16T18:57:14.755928Z","shell.execute_reply.started":"2024-05-16T18:57:14.210585Z","shell.execute_reply":"2024-05-16T18:57:14.754860Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"{0: '{', 23: 'b', 20: 'h', 8: 'e', 10: 's', 15: 'm', 17: 'u', 12: 'd', 6: 'i', 7: 'n', 9: '}', 1: 'v', 22: 'y', 2: 'a', 21: 'k', 14: 'c', 11: 't', 3: 'r', 19: 'p', 5: 'l', 16: 'o', 4: 'g', 24: 'j', 18: 'w', 26: 'x', 13: 'f', 25: 'z', 27: 'q'}\ntorch.Size([4096, 30])\n{0: '{', 37: 'భ', 42: 'ీ', 32: 'ష', 3: '్', 18: 'మ', 24: 'ు', 29: 'డ', 7: 'ి', 8: 'న', 10: '}', 1: 'వ', 15: 'య', 5: 'ా', 11: 'స', 16: 'క', 27: 'చ', 12: 'త', 2: 'ర', 26: 'ం', 22: 'ప', 6: 'ల', 20: 'ూ', 49: 'థ', 33: 'ఆ', 35: 'శ', 40: 'హ', 19: 'ో', 4: 'గ', 41: 'జ', 13: 'ద', 34: 'ొ', 28: 'ై', 9: 'ే', 46: 'ఒ', 25: 'ె', 17: 'ట', 39: 'ణ', 43: 'ఇ', 38: 'ృ', 54: 'ఓ', 23: 'ధ', 45: 'ఐ', 47: 'ఎ', 36: 'అ', 44: 'బ', 52: 'ఏ', 14: 'ఫ', 31: 'ఉ', 30: 'ఖ', 21: 'ళ', 51: 'ఊ', 48: 'ౌ', 55: 'ఔ', 57: 'ఠ', 58: 'ఘ', 56: 'ఞ', 50: 'ఈ', 59: 'ఛ', 62: 'ఋ', 60: 'ః', 53: 'ఢ'}\ntensor([ 0, 37, 42, 32,  3, 18, 24, 29,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n        10, 10, 10, 10, 10], device='cuda:0', dtype=torch.int32)\nbheeshmudini\n28\n62\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.758915Z","iopub.execute_input":"2024-05-16T18:57:14.759204Z","iopub.status.idle":"2024-05-16T18:57:14.766011Z","shell.execute_reply.started":"2024-05-16T18:57:14.759179Z","shell.execute_reply":"2024-05-16T18:57:14.764877Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class MyDataset2(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.767207Z","iopub.execute_input":"2024-05-16T18:57:14.767623Z","iopub.status.idle":"2024-05-16T18:57:14.776470Z","shell.execute_reply.started":"2024-05-16T18:57:14.767591Z","shell.execute_reply":"2024-05-16T18:57:14.775345Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def validationAccuracy(encoder,decoder,batchsize,tf_ratio):\n    \n    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n        \n        encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n        #print(encoder_output)\n        #success till here\n\n        loss = 0 # decoder starts form here\n        correct = 0\n\n        output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n\n        decoder_actual_output = []\n        #print(target_batch)\n\n        randNumber = random.random()\n\n        decoder_curr_state = encoder_current_state\n\n        for i in range(0,output_seq_len):\n\n            if(i == 0):\n                decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            #print(curr_target_chars.shape) #32\n            decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n            #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n            topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n            #print(\"topv\", topv)\n            decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n            #print(decoder_input_tensor.shape)\n            decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n\n            decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n            #print(decoder_output.shape,curr_target_chars.shape)\n            #print(decoder_output.shape,curr_target_chars.shape)\n\n            curr_target_chars = target_batch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            #print(curr_target_chars)\n\n            loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n\n        tensor_2d = torch.stack(decoder_actual_output)\n        decoder_actual_output = tensor_2d.t() #it is outside the for loop\n\n        validation_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n        validation_loss += (loss.item()/output_seq_len)\n\n        if(batch_num%20 == 0):\n            print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n        #'k'/24\n        # here you get the actual word letters seqeunces softamx indeces\n        #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n        #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        #accuracy = accuracy + correct\n    \n    encoder.train()\n    decoder.train()\n#     print(\"validation_accuracy\",validation_accuracy/40.96)\n#     print(\"validation_loss\",validation_loss)\n    wandb.log({'validation_accuracy':validation_accuracy/40.96})\n    wandb.log({'validation_loss':validation_loss})","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.777882Z","iopub.execute_input":"2024-05-16T18:57:14.778197Z","iopub.status.idle":"2024-05-16T18:57:14.795983Z","shell.execute_reply.started":"2024-05-16T18:57:14.778174Z","shell.execute_reply":"2024-05-16T18:57:14.795087Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.batch_size = batch_size\n        \n        if(cellType=='GRU'):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        elif(cellType=='LSTM'):\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n            \n    def forward(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prev_state = self.rnn(embdInput, prevState)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n    \nclass Decoder(nn.Module):\n    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n        \n        if(cellType==\"GRU\"):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        elif(cellType==\"LSTM\"):\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n            \n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim) # it is useful for mapping the calculation to vocabularu\n        self.softmax = nn.LogSoftmax(dim=2) #output is in 3rd column \n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        output, prev_state = self.rnn(curr_embd, prev_state)\n        output = self.dropout(output)\n        output = self.softmax(self.fc(output)) \n        return output, prev_state ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.797360Z","iopub.execute_input":"2024-05-16T18:57:14.797886Z","iopub.status.idle":"2024-05-16T18:57:14.812389Z","shell.execute_reply.started":"2024-05-16T18:57:14.797855Z","shell.execute_reply":"2024-05-16T18:57:14.811343Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"input_dim = data[\"source_len\"]\noutput_dim = data[\"target_len\"]\nchar_embd_dim=64\nhidden_layer_neurons = 512\nlearning_rate  =0.0001\nbatch_size = 64\nnumber_of_layers = 10\ntf_ratio = 0.2\nepochs = 50\n#train(64,1,1,512,'GRU','Yes',0.4,20,32,1e-4,\"Adam\",0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.813522Z","iopub.execute_input":"2024-05-16T18:57:14.814069Z","iopub.status.idle":"2024-05-16T18:57:14.827917Z","shell.execute_reply.started":"2024-05-16T18:57:14.814043Z","shell.execute_reply":"2024-05-16T18:57:14.826854Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input),copy.copy(train_output))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:14.829001Z","iopub.execute_input":"2024-05-16T18:57:14.829680Z","iopub.status.idle":"2024-05-16T18:57:22.267661Z","shell.execute_reply.started":"2024-05-16T18:57:14.829648Z","shell.execute_reply":"2024-05-16T18:57:22.266629Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def dataLoaderFun(dataName,batch_size):\n    if(dataName == 'train'):\n        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:22.269079Z","iopub.execute_input":"2024-05-16T18:57:22.269495Z","iopub.status.idle":"2024-05-16T18:57:22.277959Z","shell.execute_reply.started":"2024-05-16T18:57:22.269454Z","shell.execute_reply":"2024-05-16T18:57:22.276837Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def getNetwork(network,a,b,c,d,e,f):\n    if(network == \"enc\"):\n        return Encoder(a,b,c,d,e,f)\n    else:\n        return Decoder(a,b,c,d,e,f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n    #add optimizer,tf_ratio to wandb parameters\n    \n    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n    \n    encoder = getNetwork(\"enc\",data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n    decoder = getNetwork(\"dec\",data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    #encoder = Encoder()\n    #decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    \n    # done till here\n    if(optimizer == 'Adam'):\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n    \n    lossFunction = nn.NLLLoss()\n\n    for epoch in range (0,epochs):\n    \n        train_accuracy = 0 \n        train_loss = 0 \n\n        for batch_num, (source_batch, target_batch) in enumerate(dataLoader):\n                        \n            encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n            if(bidirection == \"Yes\"):\n                reversed_batch = torch.flip(source_batch, dims=[1]) # reverse the batch across rows.\n                source_batch = (source_batch + reversed_batch)//2 # adding reversed data to source data by averaging\n                \n            encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n            \n            #print(encoder_output)\n            #success till here3\n            \n            \n            # decoder starts form here\n            correct = 0\n            loss = 0 \n            \n            output_seq_len = target_batch.shape[1] # here you will get as name justified. 40\n\n            decoder_actual_output = []\n            #print(target_batch)\n            \n            randNumber = random.random()\n\n            decoder_curr_state = encoder_current_state\n\n            for i in range(0,output_seq_len):\n                \n                if(i == 0):\n                    decoder_input_tensor = target_batch[:, i].reshape(batchsize,1) #32*1\n                    #print(dec_input_tensor.shape)\n                else:\n                    if randNumber < tf_ratio:\n                        decoder_input_tensor = target_batch[:, i].reshape(batchsize, 1) # current batch is passed\n                    else:\n                        decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n                #print(curr_target_chars.shape) #32\n                decoder_output, decoder_curr_state = decoder(decoder_input_tensor,decoder_curr_state)\n                #print(decoder_output.shape) #(32*1*67) but your output is (32*1*65) becz ur output size is 65\n                topv, topi = decoder_output.topk(1)  # you will get top vales and their indices.\n                #print(\"topv\", topv)\n                decoder_input_tensor = topi.squeeze().detach()  # here whatever top softmax indeces are present but converted to 1 dimension\n                #print(decoder_input_tensor.shape)\n                decoder_actual_output.append(decoder_input_tensor) # softmax values are attached                    \n                        \n                decoder_output = decoder_output[:, -1, :] #it is just reduce the size from (32*1*67) to (32*67)\n                #print(decoder_output.shape,curr_target_chars.shape)\n                #print(decoder_output.shape,curr_target_chars.shape)\n\n                curr_target_chars = target_batch[:, i] #(32)\n                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                #print(curr_target_chars)\n                \n                loss+=(lossFunction(decoder_output, curr_target_chars)) # you are passing 32*67 softmax values to curr_target_chars which has the 32*1\n                \n            tensor_2d = torch.stack(decoder_actual_output)\n            decoder_actual_output = tensor_2d.t() #it is outside the for loop\n            #print(decoder_actual_output) #32*40\n            if(batch_num == 0 and epoch == epochs-1):\n                numToCharConverter(target_batch,decoder_actual_output,data) \n                \n            train_accuracy += (decoder_actual_output == target_batch).all(dim=1).sum().item() # it is simple just summing up the equal values\n            train_loss += (loss.item()/output_seq_len)\n            \n            if(batch_num%200 == 0):\n                print(\"bt:\", batch_num, \" loss:\", loss.item()/output_seq_len)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct\n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n            \n#         print(\"train_accuracy\",train_accuracy/512)\n#         print(\"train_loss\",train_loss)\n        wandb.log({'train_accuracy':train_accuracy/512})\n        wandb.log({'train_loss':train_loss})\n        validationAccuracy(encoder,decoder,batchsize,tf_ratio)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:22.280911Z","iopub.execute_input":"2024-05-16T18:57:22.281168Z","iopub.status.idle":"2024-05-16T18:57:22.300968Z","shell.execute_reply.started":"2024-05-16T18:57:22.281147Z","shell.execute_reply":"2024-05-16T18:57:22.299847Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def numToCharConverter(inputArray,outputArray,data):\n    mp = data['num_char_map_2']\n    t1 = ''\n    t2 = ''\n    for row1, row2 in zip(inputArray,outputArray):\n        t1=''\n        t2=''\n        for e1, e2 in zip(row1,row2):\n            t1+=mp[e1.item()]\n            t2+=mp[e2.item()]\n        print(t1,\" \",t2) ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:22.302084Z","iopub.execute_input":"2024-05-16T18:57:22.302378Z","iopub.status.idle":"2024-05-16T18:57:22.315763Z","shell.execute_reply.started":"2024-05-16T18:57:22.302355Z","shell.execute_reply":"2024-05-16T18:57:22.314437Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='DL_Assignment_3')\n    params = wandb.config\n    with wandb.init(project = 'DL_Assignment_3', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DeepLearningAssignment3',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'validation_accuracy',\n    },\n    'parameters' : {\n        'embSize':{'values':[32]},\n        'encoderLayers':{'values':[5]},\n        'decoderLayers' : {'values' : [10]},\n        'hiddenLayerNuerons'   : {'values' : [64]},\n        'cellType' : {'values' : ['GRU','LSTM','RNN'] } ,\n        'bidirection' : {'values' : ['no']},\n        'dropout' : {'values' : [0,0.2,0.3]},\n        'epochs'  : {'values': [10,20,30]},\n        'batchsize' : {'values' : [32]},\n        'learningRate' : {'values' : [1e-2]},\n        'optimizer':{'values' : ['Adam','Nadam']},\n        'tf_ratio' :{'values' : [0.4]}\n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'DL_Assignment_3')\nwandb.agent(sweepId,function =main_fun,count = 10)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T18:57:22.316709Z","iopub.execute_input":"2024-05-16T18:57:22.317219Z","iopub.status.idle":"2024-05-16T22:44:51.373844Z","shell.execute_reply.started":"2024-05-16T18:57:22.317187Z","shell.execute_reply":"2024-05-16T22:44:51.372861Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: szetb869\nSweep URL: https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mtvcmlss with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n","output_type":"stream"},{"name":"stdout","text":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n<IPython.core.display.HTML object>\n<IPython.core.display.HTML object>\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\nException in thread NetStatThr:\nTraceback (most recent call last):\n      File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\nreturn self._deliver_stop_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\nException in thread IntMsgThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n        return self._deliver_record(record)    self.run()\nlocal_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    return self._deliver_network_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    return self._deliver_internal_messages(internal_message)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n        self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\nreturn self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_185728-mtvcmlss</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">different-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:mtvcmlss) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">different-sweep-1</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_185728-mtvcmlss/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:mtvcmlss). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_185745-mtvcmlss</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.214639083198879\nbt: 200  loss: 1.5688552856445312\nbt: 400  loss: 1.6359644350798235\nbt: 600  loss: 1.8313036379606829\nbt: 800  loss: 1.4217142851456352\nbt: 1000  loss: 1.628812375275985\nbt: 1200  loss: 1.0264386716096296\nbt: 1400  loss: 1.471035335374915\nbt: 0  loss: 0.4721094214397928\nbt: 20  loss: 1.4329503930133323\nbt: 40  loss: 0.5010626005089801\nbt: 60  loss: 0.4969053683073624\nbt: 80  loss: 1.4369161854619565\nbt: 100  loss: 1.3784060270889946\nbt: 120  loss: 0.495415272920028\nbt: 0  loss: 0.5696472914322562\nbt: 200  loss: 1.6212783481763757\nbt: 400  loss: 0.46434170266856317\nbt: 600  loss: 1.6546166461447012\nbt: 800  loss: 0.37611812093983527\nbt: 1000  loss: 1.40076380190642\nbt: 1200  loss: 1.4278567770253057\nbt: 1400  loss: 0.35125682664954144\nbt: 0  loss: 1.1804004337476648\nbt: 20  loss: 0.2654325443765391\nbt: 40  loss: 1.1168270940365999\nbt: 60  loss: 0.23190956530363663\nbt: 80  loss: 0.24897577451623004\nbt: 100  loss: 0.21970891952514648\nbt: 120  loss: 0.23051384220952573\nbt: 0  loss: 1.5173311648161516\nbt: 200  loss: 1.5066617882770041\nbt: 400  loss: 1.6339731631071672\nbt: 600  loss: 1.6056243233058765\nbt: 800  loss: 0.11206471401712169\nbt: 1000  loss: 1.699596239172894\nbt: 1200  loss: 1.6330762116805366\nbt: 1400  loss: 0.058343669642572815\nbt: 0  loss: 1.3941608926524287\nbt: 20  loss: 0.043572130410567574\nbt: 40  loss: 0.04669504580290421\nbt: 60  loss: 1.3224106664242952\nbt: 80  loss: 0.03296027235362841\nbt: 100  loss: 1.3771027274753735\nbt: 120  loss: 0.03977627080419789\nbt: 0  loss: 0.05796851800835651\nbt: 200  loss: 1.5179967465608015\nbt: 400  loss: 1.8014780127483865\nbt: 600  loss: 1.584142602008322\nbt: 800  loss: 1.5913737753163213\nbt: 1000  loss: 0.06433453248894733\nbt: 1200  loss: 0.0628153137538744\nbt: 1400  loss: 1.652555051057235\nbt: 0  loss: 1.1169380519701086\nbt: 20  loss: 1.2462602698284646\nbt: 40  loss: 1.3444511579430622\nbt: 60  loss: 0.032975139825240425\nbt: 80  loss: 1.3145179748535156\nbt: 100  loss: 1.2191067571225374\nbt: 120  loss: 1.2812845810599949\nbt: 0  loss: 1.448391292406165\nbt: 200  loss: 1.6080517976180366\nbt: 400  loss: 0.0368889103765073\nbt: 600  loss: 1.6334220222804858\nbt: 800  loss: 1.7837028503417969\nbt: 1000  loss: 0.04897289172462795\nbt: 1200  loss: 1.560697140900985\nbt: 1400  loss: 0.040736434252365776\nbt: 0  loss: 0.0161145497923312\nbt: 20  loss: 1.339786612469217\nbt: 40  loss: 1.3178167757780657\nbt: 60  loss: 1.2048463406770125\nbt: 80  loss: 0.026587815388389256\nbt: 100  loss: 1.2864243051280146\nbt: 120  loss: 0.03161077914030656\nbt: 0  loss: 0.04387349149455195\nbt: 200  loss: 1.7234842051630435\nbt: 400  loss: 1.6423654970915422\nbt: 600  loss: 1.6214085454526155\nbt: 800  loss: 1.641878542692765\nbt: 1000  loss: 1.4852906932001528\nbt: 1200  loss: 0.1599607985952626\nbt: 1400  loss: 1.7259611046832541\nbt: 0  loss: 0.02963842775510705\nbt: 20  loss: 0.030528490958006485\nbt: 40  loss: 1.3601529494575832\nbt: 60  loss: 0.019550166700197304\nbt: 80  loss: 0.02468887878500897\nbt: 100  loss: 0.016746612994567207\nbt: 120  loss: 1.4045277471127717\nbt: 0  loss: 1.5164526234502378\nbt: 200  loss: 0.05688826415849769\nbt: 400  loss: 1.7504051871921704\nbt: 600  loss: 1.610906518023947\nbt: 800  loss: 0.0429283328678297\nbt: 1000  loss: 0.049664844637331756\nbt: 1200  loss: 1.5704441899838655\nbt: 1400  loss: 1.6903071196182915\nbt: 0  loss: 1.2802744326384172\nbt: 20  loss: 1.3552937714949898\nbt: 40  loss: 1.2256838757058848\nbt: 60  loss: 1.406196760094684\nbt: 80  loss: 1.359404190726902\nbt: 100  loss: 1.28607409933339\nbt: 120  loss: 0.005870755599892657\nbt: 0  loss: 1.699325063954229\nbt: 200  loss: 0.02955095405163972\nbt: 400  loss: 1.719364829685377\nbt: 600  loss: 1.730665455693784\nbt: 800  loss: 0.04187164099320122\nbt: 1000  loss: 1.6960253508194634\nbt: 1200  loss: 1.6839375703231148\nbt: 1400  loss: 1.7012785206670347\nbt: 0  loss: 1.1855561629585598\nbt: 20  loss: 0.00965130847433339\nbt: 40  loss: 1.268097504325535\nbt: 60  loss: 0.002436267778925274\nbt: 80  loss: 0.005487178978712663\nbt: 100  loss: 1.4045780016028362\nbt: 120  loss: 1.3844296828560207\nbt: 0  loss: 0.029044835463814114\nbt: 200  loss: 1.6755477241847827\nbt: 400  loss: 1.5240317634914233\nbt: 600  loss: 0.04749167483785878\nbt: 800  loss: 1.7228229356848674\nbt: 1000  loss: 0.05888628441354503\nbt: 1200  loss: 0.09343547406403915\nbt: 1400  loss: 1.62811511495839\nbt: 0  loss: 1.3227492622707202\nbt: 20  loss: 0.012690142444942308\nbt: 40  loss: 0.022240879742995552\nbt: 60  loss: 1.2636172253152598\nbt: 80  loss: 1.5504722595214844\nbt: 100  loss: 0.010227281114329462\nbt: 120  loss: 0.008083395983861841\nbt: 0  loss: 0.038463361885236656\nbt: 200  loss: 1.7153982079547385\nbt: 400  loss: 0.037349576535432236\nbt: 600  loss: 0.02941534830176312\nbt: 800  loss: 1.5506537064262058\nbt: 1000  loss: 0.036340495814447815\nbt: 1200  loss: 0.028640073278675907\nbt: 1400  loss: 1.839154284933339\nbt: 0  loss: 1.163543286530868\nbt: 20  loss: 1.2538018433944038\nbt: 40  loss: 1.2346556290336277\nbt: 60  loss: 1.3175778596297554\nbt: 80  loss: 1.3027454873789912\nbt: 100  loss: 0.024010365423948868\nbt: 120  loss: 0.010203703590061354\nbt: 0  loss: 1.5642046721085259\nbt: 200  loss: 1.7855883059294329\nbt: 400  loss: 1.7263269839079485\nbt: 600  loss: 1.5449893785559612\nbt: 800  loss: 1.7421928074048914\nbt: 1000  loss: 0.05713312003923499\nbt: 1200  loss: 0.03295797627905141\nbt: 1400  loss: 0.054061874099399734\nbt: 0  loss: 1.305708014446756\nbt: 20  loss: 1.3086742732835852\nbt: 40  loss: 1.2344038590140964\nbt: 60  loss: 0.0468297004699707\nbt: 80  loss: 1.3425584046737007\nbt: 100  loss: 1.3258368450662363\nbt: 120  loss: 1.4069111036217732\nbt: 0  loss: 0.09171411265497623\nbt: 200  loss: 1.6560572748598845\nbt: 400  loss: 1.7986826689346977\nbt: 600  loss: 1.626970042353091\nbt: 800  loss: 0.04332820747209632\nbt: 1000  loss: 1.6394502390985903\nbt: 1200  loss: 1.8661772686502207\nbt: 1400  loss: 0.06455781148827594\nbt: 0  loss: 0.01757615934247556\nbt: 20  loss: 0.01166827134464098\nbt: 40  loss: 1.2485783618429434\nbt: 60  loss: 1.1716414741847827\nbt: 80  loss: 0.017917814462081245\nbt: 100  loss: 1.3503070499586023\nbt: 120  loss: 0.014406408952630085\nbt: 0  loss: 0.04821170412975809\nbt: 200  loss: 1.9176864624023438\nbt: 400  loss: 1.9960413393766985\nbt: 600  loss: 0.08281387453493864\nbt: 800  loss: 1.8150075829547385\nbt: 1000  loss: 1.623890088952106\nbt: 1200  loss: 2.1879765054453975\nbt: 1400  loss: 1.869782655135445\nbt: 0  loss: 0.02797412094862565\nbt: 20  loss: 1.266949695089589\nbt: 40  loss: 1.2419164906377378\nbt: 60  loss: 1.448860334313434\nbt: 80  loss: 1.3596251114555027\nbt: 100  loss: 1.2668150196904722\nbt: 120  loss: 1.3079506417979365\nbt: 0  loss: 0.05077258918596351\nbt: 200  loss: 1.7728546806003735\nbt: 400  loss: 1.6566656361455503\nbt: 600  loss: 1.6936232525369395\nbt: 800  loss: 0.038797223049661385\nbt: 1000  loss: 1.6146212038786516\nbt: 1200  loss: 2.1778106689453125\nbt: 1400  loss: 1.6475476803986921\nbt: 0  loss: 0.028682882371156113\nbt: 20  loss: 1.3860085528829824\nbt: 40  loss: 0.014858306750007298\nbt: 60  loss: 1.4007369331691577\nbt: 80  loss: 0.042754805606344475\nbt: 100  loss: 0.02105901811433875\nbt: 120  loss: 0.0221355764762215\nbt: 0  loss: 0.07560356285261072\nbt: 200  loss: 1.7430096501889436\nbt: 400  loss: 0.09208665723386018\nbt: 600  loss: 1.6505289492399797\nbt: 800  loss: 1.7327409827190896\nbt: 1000  loss: 0.08813499367755392\nbt: 1200  loss: 1.961535578188689\nbt: 1400  loss: 0.05673503357431163\nbt: 0  loss: 0.012281122414962105\nbt: 20  loss: 1.3145296677299168\nbt: 40  loss: 1.6460304260253906\nbt: 60  loss: 0.0244365438171055\nbt: 80  loss: 1.327863776165506\nbt: 100  loss: 1.375139568163001\nbt: 120  loss: 1.4126732867697012\nbt: 0  loss: 1.8875394074813179\nbt: 200  loss: 1.8888158383576765\nbt: 400  loss: 1.8308457084324048\nbt: 600  loss: 0.0532989501953125\nbt: 800  loss: 0.06862260466036589\nbt: 1000  loss: 0.05744723133418871\nbt: 1200  loss: 1.8009583846382473\nbt: 1400  loss: 1.85455090066661\nbt: 0  loss: 1.3924034782077954\nbt: 20  loss: 0.02152813258378402\nbt: 40  loss: 0.01960763464803281\nbt: 60  loss: 0.017911155586657318\nbt: 80  loss: 0.025702051494432533\nbt: 100  loss: 1.397253948709239\nbt: 120  loss: 0.011697017628213634\nbt: 0  loss: 0.07513990091240924\nbt: 200  loss: 0.05030460979627526\nbt: 400  loss: 1.8076052458389946\nbt: 600  loss: 1.9298518636952275\nbt: 800  loss: 0.09761088827381963\nbt: 1000  loss: 0.0697647125824638\nbt: 1200  loss: 1.8043647434400476\nbt: 1400  loss: 1.7111854553222656\nbt: 0  loss: 0.013934925846431566\nbt: 20  loss: 1.295022135195525\nbt: 40  loss: 1.3508319025454314\nbt: 60  loss: 0.018183705599411674\nbt: 80  loss: 0.020641484986180843\nbt: 100  loss: 1.3670674199643342\nbt: 120  loss: 0.025557976701985233\nbt: 0  loss: 1.81060791015625\nbt: 200  loss: 1.7551821833071501\nbt: 400  loss: 1.913968791132388\nbt: 600  loss: 1.9002294125764265\nbt: 800  loss: 1.8491824606190557\nbt: 1000  loss: 0.31665969931561017\nbt: 1200  loss: 1.6973468946373982\nbt: 1400  loss: 0.09907457102899966\nbt: 0  loss: 0.029479488082554028\nbt: 20  loss: 1.3822570469068445\nbt: 40  loss: 1.516131193741508\nbt: 60  loss: 1.2654856806216033\nbt: 80  loss: 1.380379054857337\nbt: 100  loss: 0.037787051304526954\nbt: 120  loss: 0.03266228541083958\nbt: 0  loss: 0.08303006317304529\nbt: 200  loss: 1.7463508274244226\nbt: 400  loss: 0.05504746022431747\nbt: 600  loss: 0.16247714084127676\nbt: 800  loss: 1.8121206864066746\nbt: 1000  loss: 0.05695205667744512\nbt: 1200  loss: 0.05560529750326405\nbt: 1400  loss: 1.818864739459494\nbt: 0  loss: 0.01460641622543335\nbt: 20  loss: 1.3591482742972996\nbt: 40  loss: 0.01137097374252651\nbt: 60  loss: 1.411974699600883\nbt: 80  loss: 1.3877474743386973\nbt: 100  loss: 1.3791562785273013\nbt: 120  loss: 1.4655187855596128\nbt: 0  loss: 0.05722734202509341\nbt: 200  loss: 1.6887867139733357\nbt: 400  loss: 1.6466321530549421\nbt: 600  loss: 1.8771763677182405\nbt: 800  loss: 1.8605094577955164\nbt: 1000  loss: 1.7893927200980808\nbt: 1200  loss: 0.12366168395332668\nbt: 1400  loss: 0.11537783042244289\nbt: 0  loss: 0.08679167084071947\nbt: 20  loss: 1.4647516996964165\nbt: 40  loss: 1.5828001602836277\nbt: 60  loss: 1.5035640882409138\nbt: 80  loss: 1.4697280552076257\nbt: 100  loss: 0.055387709451758346\nbt: 120  loss: 0.05262370731519616\nbt: 0  loss: 0.1268471738566523\nbt: 200  loss: 0.08958332434944484\nbt: 400  loss: 1.8430713155995244\nbt: 600  loss: 0.0807451528051625\nbt: 800  loss: 1.6632642331330671\nbt: 1000  loss: 1.8502135898755945\nbt: 1200  loss: 1.8205161716627039\nbt: 1400  loss: 0.07025759634764298\nbt: 0  loss: 1.3937510614809783\nbt: 20  loss: 1.3091467981753142\nbt: 40  loss: 1.3790909311045771\nbt: 60  loss: 0.023650705814361572\nbt: 80  loss: 0.016661391310069874\nbt: 100  loss: 0.024300419765969982\nbt: 120  loss: 1.4202069821565046\nbt: 0  loss: 0.046072099519812545\nbt: 200  loss: 1.85608606753142\nbt: 400  loss: 1.6520607989767324\nbt: 600  loss: 1.7704293624214504\nbt: 800  loss: 0.11685486461805261\nbt: 1000  loss: 0.04005614570949389\nbt: 1200  loss: 1.7306342746900476\nbt: 1400  loss: 1.7619564222252888\nbt: 0  loss: 0.029924242392830227\nbt: 20  loss: 1.5256948056428328\nbt: 40  loss: 0.016544887553090633\nbt: 60  loss: 1.5636606631071672\nbt: 80  loss: 1.5529319099757983\nbt: 100  loss: 0.004865534279657447\nbt: 120  loss: 1.464951059092646\nbt: 0  loss: 1.8779018236243206\nbt: 200  loss: 1.895556242569633\nbt: 400  loss: 1.7456434498662534\nbt: 600  loss: 0.061212327169335404\nbt: 800  loss: 1.8246078491210938\nbt: 1000  loss: 0.04779679878898289\nbt: 1200  loss: 0.1526802519093389\nbt: 1400  loss: 0.07352550133414891\nbt: 0  loss: 0.029232416463934856\nbt: 20  loss: 0.03325814267863398\nbt: 40  loss: 0.049789200658383576\nbt: 60  loss: 0.02826468581738679\nbt: 80  loss: 0.03152931254843007\nbt: 100  loss: 0.030404119387916897\nbt: 120  loss: 1.4079833652662195\nbt: 0  loss: 1.76067418637483\nbt: 200  loss: 0.10337338240250298\nbt: 400  loss: 1.6566243379012398\nbt: 600  loss: 1.842552019202191\nbt: 800  loss: 1.7856279456097146\nbt: 1000  loss: 1.734362394913383\nbt: 1200  loss: 0.057116524032924484\nbt: 1400  loss: 0.08147005412889563\nbt: 0  loss: 1.4466808153235393\nbt: 20  loss: 0.035898952380470604\nbt: 40  loss: 0.01598035382187885\nbt: 60  loss: 1.3262749547543733\nbt: 80  loss: 1.295147937277089\nbt: 100  loss: 1.479077214780061\nbt: 120  loss: 1.293415235436481\nbt: 0  loss: 1.8848047671110735\nbt: 200  loss: 1.746041836945907\nbt: 400  loss: 1.819112197212551\nbt: 600  loss: 0.08190202713012695\nbt: 800  loss: 1.9729305764903193\nbt: 1000  loss: 1.820693472157354\nbt: 1200  loss: 1.7334379113238791\nbt: 1400  loss: 0.10207309930220894\nbt: 0  loss: 0.028328768585039223\nbt: 20  loss: 1.3869834568189539\nbt: 40  loss: 0.041474254234977394\nbt: 60  loss: 0.03793691033902376\nbt: 80  loss: 1.4987255594004756\nbt: 100  loss: 1.250531818555749\nbt: 120  loss: 0.048291289288064705\nbt: 0  loss: 1.7750612341839334\nbt: 200  loss: 1.8344872516134512\nbt: 400  loss: 0.04722718570543372\nbt: 600  loss: 1.858000382133152\nbt: 800  loss: 1.9340070641559104\nbt: 1000  loss: 0.07761963554050612\nbt: 1200  loss: 1.6330772068189539\nbt: 1400  loss: 1.8180143936820652\nbt: 0  loss: 0.030404225639674976\nbt: 20  loss: 1.3830132691756538\nbt: 40  loss: 1.4217190949813179\nbt: 60  loss: 0.03649258872737055\nbt: 80  loss: 1.6213795205821162\nbt: 100  loss: 1.424344601838485\nbt: 120  loss: 0.02306311545164689\nbt: 0  loss: 0.06630002415698508\nbt: 200  loss: 0.06762625860131305\nbt: 400  loss: 0.050493053767992103\nbt: 600  loss: 0.09112631756326427\nbt: 800  loss: 1.9067381153935972\nbt: 1000  loss: 0.07369579957879108\nbt: 1200  loss: 1.8127822875976562\nbt: 1400  loss: 0.07704857121343198\nbt: 0  loss: 0.04450417083242665\nbt: 20  loss: 1.3749100229014521\nbt: 40  loss: 1.4174885957137398\nbt: 60  loss: 0.033671495707138725\nbt: 80  loss: 1.4665859056555706\nbt: 100  loss: 0.045742491017217224\nbt: 120  loss: 0.06832532779030177\nbt: 0  loss: 0.10515053375907567\nbt: 200  loss: 0.07677180870719578\nbt: 400  loss: 0.08656944917595905\nbt: 600  loss: 1.7770413937775984\nbt: 800  loss: 1.9764215220575747\nbt: 1000  loss: 1.965228039285411\nbt: 1200  loss: 0.10502967627152153\nbt: 1400  loss: 1.8637827997622283\nbt: 0  loss: 1.8847931571628735\nbt: 20  loss: 0.018258680468020233\nbt: 40  loss: 1.9834989464801291\nbt: 60  loss: 1.8021890391474185\nbt: 80  loss: 0.01967887256456458\nbt: 100  loss: 0.04183747975722603\nbt: 120  loss: 1.8958590963612432\nbt: 0  loss: 1.9453579446543818\nbt: 200  loss: 0.12030859615491785\nbt: 400  loss: 0.10393000685650369\nbt: 600  loss: 1.9849681024966033\nbt: 800  loss: 0.06410694122314453\nbt: 1000  loss: 2.1218258401621943\nbt: 1200  loss: 2.152654564898947\nbt: 1400  loss: 1.9351922740106997\nbt: 0  loss: 0.0363594941470934\nbt: 20  loss: 2.432176838750425\nbt: 40  loss: 2.459374137546705\nbt: 60  loss: 2.48270963585895\nbt: 80  loss: 2.4719007740850034\nbt: 100  loss: 2.4749502099078633\nbt: 120  loss: 2.4585758706797725\n{గట్టిపోటీదారుడిగా}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{వంటకాలో}}}}}}}}}}}}}}}   {}ా్్్్్}}}}}}}}}}}}}}}\n{ఎవరనుకుంటున్నారా}}}}}}   {సా్్్}}}}}}}}}}}}}}}}}\n{గెలుపొందాడని}}}}}}}}}}   {స్ర్}్}}}}}}}}}}}}}}}}\n{డొమినోస్తో}}}}}}}}}}}}   {తా్్్ర}}}}}}}}}}}}}}}}\n{వీడితోనే}}}}}}}}}}}}}}   {సా్్్్}రిర}}}}}}}}}}}}\n{విస్తరింపజేయడమే}}}}}}}   {వపా్్ిి్్్్}్}}}}}}}}}\n{లిబెర్టియన్}}}}}}}}}}}   {కర్్}్}}}}}}}}}}}}}}}}\n{కొరియాకే}}}}}}}}}}}}}}   {తి}్}}}}}}}}}}}}}}}}}}\n{నోరునొక్కేసి}}}}}}}}}}   {తిర}}క}}}}}}}}}}}}}}}}\n{దిగ్బంధించే}}}}}}}}}}}   {తిర్్ి్్్}}}}}}}}}}}}}\n{ఎక్కవద్దంటూ}}}}}}}}}}}   {మిర్}}}}}}}}}}}}}}}}}}\n{లొంగడమో}}}}}}}}}}}}}}}   {క్్ి}}్్}}}}}}}}}}}}}}\n{జీవంలేనివారిగా}}}}}}}}   {సిార్ి}}}్్్}}}}}}}}}}\n{తొడుతుండగా}}}}}}}}}}}}   {కిర్్్}}}}}}}}}}}}}}}}\n{ముడుచుకొనిపోతాయి}}}}}}   {సా్్}్}}}}}}}}}}}}}}}}\n{త్రిప్పివేయడానికి}}}}}   {కా్్}్ా}}}}}}}}}}}}}}}\n{రాష్ర్టాలన్నింటిపై}}}}   {సా్్ి్్్్}}}}}}}}}}}}}\n{ఉడిగిన}}}}}}}}}}}}}}}}   {నరర్్్్్ిి}్}}}}}}}}}}\n{కురంభుడు}}}}}}}}}}}}}}   {కా్్}్్్}}}}}}}}}}}}}}\n{పెళ్లిల్లే}}}}}}}}}}}}   {}ిర్}్}}}}}}}}}}}}}}}}\n{తిట్టుకోకూడదని}}}}}}}}   {క}}్ాి}}}}}}}}}}}}}}}}\n{స్థానికులతోనూ}}}}}}}}}   {క్్్}}}}}}}}}}}}}}}}}}\n{పెరిగివుంది}}}}}}}}}}}   {క్్ిి్్}}}}}}}}}}}}}}}\n{పరిపూర్ణతని}}}}}}}}}}}   {కిరి్}}}}}}}}}}}}}}}}}\n{పాడవకపోతే}}}}}}}}}}}}}   {కకయ}}}}}}}}}}}}}}}}}}}\n{జరిగిందటున్నారు}}}}}}}   {కకక్్}}}}}}}}}}}}}}}}}\n{దిగేదే}}}}}}}}}}}}}}}}   {అ}న్్్}}}}}}}}}}}}}}}}\n{అవమానకరమైనవాడు}}}}}}}}   {స్రర్}}}}}}}}}}}}}}}}}\n{చిరుధాన్యాలకే}}}}}}}}}   {సా్్్్్్్}}}}}}}}}}}}}\n{చేరనూవచ్చు}}}}}}}}}}}}   {మా్్}}ా}}}}}}}}}}}}}}}\n{దుఃఖంలోంచి}}}}}}}}}}}}   {సా్}}}}్్}}}}}}}}}}}}}\nbt: 0  loss: 2.1870216701341714\nbt: 200  loss: 0.09089020024175229\nbt: 400  loss: 2.2677293860394023\nbt: 600  loss: 0.09667348861694336\nbt: 800  loss: 1.8242733167565388\nbt: 1000  loss: 1.838044539741848\nbt: 1200  loss: 0.10016383295473845\nbt: 1400  loss: 0.163333623305611\nbt: 0  loss: 0.06640726068745488\nbt: 20  loss: 0.09322865112968114\nbt: 40  loss: 0.08333545145781143\nbt: 60  loss: 0.08916031795999278\nbt: 80  loss: 1.4631069017493206\nbt: 100  loss: 1.4791903288468071\nbt: 120  loss: 0.08445975573166557\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▄▇█▇▇█▇█▇▇▇▇▆▆▇▅▆▅▆▇▇▆▆▆▇▆▅▅</td></tr><tr><td>train_loss</td><td>█▄▂▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▅▄</td></tr><tr><td>validation_accuracy</td><td>▁▁▆▆▆▆▇▇▆▆▆▆▆▆▆█▇▆▆▆▆▇▇▇▆▆▅▅▅▅</td></tr><tr><td>validation_loss</td><td>▄▂▁▁▂▂▁▂▂▂▂▂▂▂▃▁▂▃▃▂▂▃▂▂▂▂▃▅█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>19.9707</td></tr><tr><td>train_loss</td><td>1914.99529</td></tr><tr><td>validation_accuracy</td><td>26.19629</td></tr><tr><td>validation_loss</td><td>107.23615</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/mtvcmlss</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_185745-mtvcmlss/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8tkv29ys with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_192958-8tkv29ys</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">curious-sweep-2</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:8tkv29ys) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">curious-sweep-2</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_192958-8tkv29ys/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:8tkv29ys). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_193015-8tkv29ys</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">embedding32cellTypeRNNbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.174384075662364\nbt: 200  loss: 1.698335067085598\nbt: 400  loss: 2.0839691162109375\nbt: 600  loss: 1.9025306701660156\nbt: 800  loss: 1.7292094023331352\nbt: 1000  loss: 1.6188891866932744\nbt: 1200  loss: 1.627279696257218\nbt: 1400  loss: 1.9005312712296196\nbt: 0  loss: 1.3852327595586362\nbt: 20  loss: 1.4331616940705671\nbt: 40  loss: 1.416646376900051\nbt: 60  loss: 1.4677470663319463\nbt: 80  loss: 1.4720732647439707\nbt: 100  loss: 1.2537407253099524\nbt: 120  loss: 1.3863551927649456\nbt: 0  loss: 1.6609885174295176\nbt: 200  loss: 1.6945333066193953\nbt: 400  loss: 1.2808098171068274\nbt: 600  loss: 1.260529725447945\nbt: 800  loss: 1.385702133178711\nbt: 1000  loss: 1.536957948104195\nbt: 1200  loss: 2.9544359290081523\nbt: 1400  loss: 1.2874644735585088\nbt: 0  loss: 1.5212758935016135\nbt: 20  loss: 0.9734459752621858\nbt: 40  loss: 1.5146877454674763\nbt: 60  loss: 1.4810757844344429\nbt: 80  loss: 1.5057772760805876\nbt: 100  loss: 1.5429566424825918\nbt: 120  loss: 1.479315716287364\nbt: 0  loss: 2.019368213155995\nbt: 200  loss: 1.857465826946756\nbt: 400  loss: 1.1456257364024287\nbt: 600  loss: 1.8373880800993547\nbt: 800  loss: 1.9275321960449219\nbt: 1000  loss: 1.6170670882515286\nbt: 1200  loss: 1.455755150836447\nbt: 1400  loss: 1.9332709934400476\nbt: 0  loss: 1.7107041400411855\nbt: 20  loss: 1.5765236564304517\nbt: 40  loss: 1.3878915206245754\nbt: 60  loss: 1.4662570124087126\nbt: 80  loss: 1.6686252096424932\nbt: 100  loss: 1.6308490919030232\nbt: 120  loss: 1.5866762244183084\nbt: 0  loss: 1.901442983876104\nbt: 200  loss: 2.066782744034477\nbt: 400  loss: 2.234960804814878\nbt: 600  loss: 2.076282501220703\nbt: 800  loss: 2.078303793202276\nbt: 1000  loss: 2.0530087014903193\nbt: 1200  loss: 2.1147374692170517\nbt: 1400  loss: 2.023211769435717\nbt: 0  loss: 1.600526229194973\nbt: 20  loss: 1.6994902569314707\nbt: 40  loss: 1.8097265492314878\nbt: 60  loss: 1.5866876685101052\nbt: 80  loss: 1.5736566626507302\nbt: 100  loss: 1.5773186061693274\nbt: 120  loss: 1.7636106739873472\nbt: 0  loss: 2.063719707986583\nbt: 200  loss: 2.010129182235054\nbt: 400  loss: 2.1159472258194634\nbt: 600  loss: 2.036695729131284\nbt: 800  loss: 2.063988561215608\nbt: 1000  loss: 2.2795843041461445\nbt: 1200  loss: 2.1753797116486924\nbt: 1400  loss: 2.2513117582901665\nbt: 0  loss: 1.7564725461213484\nbt: 20  loss: 1.9129792918329653\nbt: 40  loss: 1.7440036276112432\nbt: 60  loss: 1.712250916854195\nbt: 80  loss: 1.693285900613536\nbt: 100  loss: 1.709967571756114\nbt: 120  loss: 1.7950494185737942\nbt: 0  loss: 2.1816505763841714\nbt: 200  loss: 1.9905645950980808\nbt: 400  loss: 2.0672225952148438\nbt: 600  loss: 2.0029552293860395\nbt: 800  loss: 2.1211858003035835\nbt: 1000  loss: 2.1529761604640796\nbt: 1200  loss: 2.118611377218495\nbt: 1400  loss: 2.11397005164105\nbt: 0  loss: 1.6677413608716882\nbt: 20  loss: 1.6903845745584238\nbt: 40  loss: 1.8391524605129077\nbt: 60  loss: 1.5817041811735735\nbt: 80  loss: 1.7536062157672385\nbt: 100  loss: 1.8185122946034307\nbt: 120  loss: 1.780960580577021\nbt: 0  loss: 2.1979303774626358\nbt: 200  loss: 2.1010780334472656\nbt: 400  loss: 2.2245692377505093\nbt: 600  loss: 2.198399253513502\nbt: 800  loss: 2.180586275847062\nbt: 1000  loss: 2.1444086821182915\nbt: 1200  loss: 2.1014646447223164\nbt: 1400  loss: 2.049397510030995\nbt: 0  loss: 1.6937343763268513\nbt: 20  loss: 1.7516248951787534\nbt: 40  loss: 1.8485575136931047\nbt: 60  loss: 1.747768733812415\nbt: 80  loss: 1.703051525613536\nbt: 100  loss: 1.8270973537279211\nbt: 120  loss: 1.6916336391283118\nbt: 0  loss: 2.1338597173276157\nbt: 200  loss: 2.1052007260529892\nbt: 400  loss: 2.0392956941024116\nbt: 600  loss: 2.2009403394616167\nbt: 800  loss: 2.229885433031165\nbt: 1000  loss: 2.0840495565663213\nbt: 1200  loss: 2.1216765693996265\nbt: 1400  loss: 2.0855344689410664\nbt: 0  loss: 1.7439027869183084\nbt: 20  loss: 1.8652844636336616\nbt: 40  loss: 1.8516202180281929\nbt: 60  loss: 1.8024957076362942\nbt: 80  loss: 1.8359786323879077\nbt: 100  loss: 1.7852783203125\nbt: 120  loss: 1.83294677734375\nbt: 0  loss: 2.1155800197435464\nbt: 200  loss: 2.1975975036621094\nbt: 400  loss: 2.14733422320822\nbt: 600  loss: 2.1059938513714336\nbt: 800  loss: 2.200931051503057\nbt: 1000  loss: 2.1858107525369395\nbt: 1200  loss: 2.226083174995754\nbt: 1400  loss: 2.14245721568232\nbt: 0  loss: 1.967679728632388\nbt: 20  loss: 1.652802840523098\nbt: 40  loss: 1.7770586428434954\nbt: 60  loss: 1.7538422294284985\nbt: 80  loss: 1.6721516484799592\nbt: 100  loss: 1.771596328071926\nbt: 120  loss: 1.801736417024032\nbt: 0  loss: 2.099260081415591\nbt: 200  loss: 2.143079674762228\nbt: 400  loss: 2.097507974375849\nbt: 600  loss: 2.1311298867930537\nbt: 800  loss: 2.12945092242697\nbt: 1000  loss: 2.0411040264627207\nbt: 1200  loss: 2.0615511355192764\nbt: 1400  loss: 2.1457481384277344\nbt: 0  loss: 1.7404887987219768\nbt: 20  loss: 1.7922832654870076\nbt: 40  loss: 1.9403074513310972\nbt: 60  loss: 1.723390828008237\nbt: 80  loss: 1.8041791501252546\nbt: 100  loss: 1.7212585780931555\nbt: 120  loss: 1.7837486267089844\nbt: 0  loss: 2.0295585964037026\nbt: 200  loss: 2.1843943388565727\nbt: 400  loss: 2.0376819113026494\nbt: 600  loss: 1.9560473898182744\nbt: 800  loss: 2.1530478104301123\nbt: 1000  loss: 2.0286755769149116\nbt: 1200  loss: 2.097737685493801\nbt: 1400  loss: 2.1382756440535835\nbt: 0  loss: 1.7057198234226392\nbt: 20  loss: 1.6957652879797893\nbt: 40  loss: 1.6843742702318274\nbt: 60  loss: 1.9225195179814878\nbt: 80  loss: 1.898734880530316\nbt: 100  loss: 1.6634222942849863\nbt: 120  loss: 1.7946571681810461\nbt: 0  loss: 2.0283443616784136\nbt: 200  loss: 2.064693948496943\nbt: 400  loss: 2.1932300070057744\nbt: 600  loss: 2.1687920611837637\nbt: 800  loss: 2.0670860953952954\nbt: 1000  loss: 2.2043802012567935\nbt: 1200  loss: 2.119267173435377\nbt: 1400  loss: 2.182989369268003\nbt: 0  loss: 1.8433021877122961\nbt: 20  loss: 1.7834139284880266\nbt: 40  loss: 1.840116252069888\nbt: 60  loss: 1.8947503463081692\nbt: 80  loss: 1.896105558975883\nbt: 100  loss: 1.7619761591372283\nbt: 120  loss: 1.6704852892004924\nbt: 0  loss: 2.1358138374660327\nbt: 200  loss: 2.056194968845533\nbt: 400  loss: 1.9705259903617527\nbt: 600  loss: 2.1103512307871943\nbt: 800  loss: 2.186430723770805\nbt: 1000  loss: 2.0240994329037876\nbt: 1200  loss: 2.029090052065642\nbt: 1400  loss: 2.110588903012483\nbt: 0  loss: 1.7633290498153023\nbt: 20  loss: 1.7039983998174253\nbt: 40  loss: 1.836283310599949\nbt: 60  loss: 1.73900670590608\nbt: 80  loss: 1.7760888804560122\nbt: 100  loss: 1.8598433784816577\nbt: 120  loss: 1.7631267050038213\nbt: 0  loss: 2.08709484597911\nbt: 200  loss: 1.990290932033373\nbt: 400  loss: 2.1013334523076597\nbt: 600  loss: 2.1101444078528364\nbt: 800  loss: 2.066382532534392\nbt: 1000  loss: 2.1279539025348164\nbt: 1200  loss: 1.9529198356296704\nbt: 1400  loss: 2.023358220639436\nbt: 0  loss: 1.7179930313773777\nbt: 20  loss: 1.7119301505710767\nbt: 40  loss: 1.8324220076851223\nbt: 60  loss: 1.6914249917735225\nbt: 80  loss: 1.8686433875042459\nbt: 100  loss: 1.7873382568359375\nbt: 120  loss: 1.8722476129946501\nbt: 0  loss: 2.166437563688859\nbt: 200  loss: 2.1769845382027\nbt: 400  loss: 2.2060505410899287\nbt: 600  loss: 2.0777558036472485\nbt: 800  loss: 2.0395749962848164\nbt: 1000  loss: 2.1400018774944805\nbt: 1200  loss: 2.1717512711234717\nbt: 1400  loss: 2.0641462906547217\nbt: 0  loss: 1.9170426078464673\nbt: 20  loss: 1.863851961882218\nbt: 40  loss: 1.9733959695567256\nbt: 60  loss: 1.6948393116826597\nbt: 80  loss: 1.7482916790506113\nbt: 100  loss: 1.5690145077912703\nbt: 120  loss: 1.6294743081797725\nbt: 0  loss: 2.1699492413064707\nbt: 200  loss: 2.0661524897036343\nbt: 400  loss: 2.0861254153044326\nbt: 600  loss: 2.275330419125764\nbt: 800  loss: 2.207804472550102\nbt: 1000  loss: 2.0425791533096977\nbt: 1200  loss: 2.1646156311035156\nbt: 1400  loss: 2.2101659360139267\nbt: 0  loss: 1.861565631368886\nbt: 20  loss: 1.8363098476244055\nbt: 40  loss: 1.826451011326002\nbt: 60  loss: 1.714805437170941\nbt: 80  loss: 1.8653821530549421\nbt: 100  loss: 1.6855205038319463\nbt: 120  loss: 1.8514711131220278\nbt: 0  loss: 2.0799104441767153\nbt: 200  loss: 2.256614353345788\nbt: 400  loss: 2.094527866529382\nbt: 600  loss: 2.0748853268830674\nbt: 800  loss: 2.097370147705078\nbt: 1000  loss: 2.147768766983696\nbt: 1200  loss: 2.072003240170686\nbt: 1400  loss: 2.105716539465863\nbt: 0  loss: 1.6636384051779043\nbt: 20  loss: 1.7226759869119395\nbt: 40  loss: 1.7783710645592732\nbt: 60  loss: 1.7559096294900645\nbt: 80  loss: 1.7744341311247454\nbt: 100  loss: 1.7212831248407778\nbt: 120  loss: 1.7746951891028362\nbt: 0  loss: 2.1607652747112773\nbt: 200  loss: 2.216641799263332\nbt: 400  loss: 2.0645125015922217\nbt: 600  loss: 2.1895169797150986\nbt: 800  loss: 2.0450454380201255\nbt: 1000  loss: 2.1181373596191406\nbt: 1200  loss: 2.1779269342837124\nbt: 1400  loss: 2.0659907797108525\nbt: 0  loss: 1.8048810544221296\nbt: 20  loss: 1.654883674953295\nbt: 40  loss: 1.746081476626189\nbt: 60  loss: 1.728417438009511\nbt: 80  loss: 1.833031695822011\nbt: 100  loss: 1.7355150969132134\nbt: 120  loss: 1.8171603990637737\nbt: 0  loss: 2.150764631188434\nbt: 200  loss: 2.0875589121942935\nbt: 400  loss: 1.958353623099949\nbt: 600  loss: 2.0153709079908286\nbt: 800  loss: 2.2156143188476562\nbt: 1000  loss: 2.1520914824112602\nbt: 1200  loss: 2.058810856031335\nbt: 1400  loss: 2.0001608807107676\nbt: 0  loss: 1.8305965921153193\nbt: 20  loss: 1.6552472321883491\nbt: 40  loss: 1.6662577753481658\nbt: 60  loss: 1.86151355245839\nbt: 80  loss: 1.741259699282439\nbt: 100  loss: 1.7601596998131794\nbt: 120  loss: 1.7336920033330503\nbt: 0  loss: 2.006298065185547\nbt: 200  loss: 2.1103273474651836\nbt: 400  loss: 2.0397536236306895\nbt: 600  loss: 2.183038794476053\nbt: 800  loss: 2.12811279296875\nbt: 1000  loss: 2.173223744268003\nbt: 1200  loss: 1.9652141073475713\nbt: 1400  loss: 2.1244407322095786\nbt: 0  loss: 1.7589030058487602\nbt: 20  loss: 1.7706497855808423\nbt: 40  loss: 1.7394507034965183\nbt: 60  loss: 1.7227511198624321\nbt: 80  loss: 1.7948870451554009\nbt: 100  loss: 1.681368288786515\nbt: 120  loss: 1.8283719601838484\nbt: 0  loss: 2.154712677001953\nbt: 200  loss: 2.195137189782184\nbt: 400  loss: 2.0635608175526494\nbt: 600  loss: 2.007591910984205\nbt: 800  loss: 2.144812874172045\nbt: 1000  loss: 2.1773547296938687\nbt: 1200  loss: 2.060076837954314\nbt: 1400  loss: 2.006579689357592\nbt: 0  loss: 1.815107594365659\nbt: 20  loss: 1.8133792047915251\nbt: 40  loss: 1.8001636007557744\nbt: 60  loss: 1.7051315307617188\nbt: 80  loss: 1.7463247879691746\nbt: 100  loss: 1.8151898591414741\nbt: 120  loss: 1.757927936056386\nbt: 0  loss: 2.255254496698794\nbt: 200  loss: 2.3230449842370073\nbt: 400  loss: 2.0395681961723\nbt: 600  loss: 1.9883737978727922\nbt: 800  loss: 2.1741011246390967\nbt: 1000  loss: 2.081188865329908\nbt: 1200  loss: 2.0750160217285156\nbt: 1400  loss: 2.0407359911047895\nbt: 0  loss: 1.771714915399966\nbt: 20  loss: 1.7706662053647249\nbt: 40  loss: 1.759911412778108\nbt: 60  loss: 1.7607396996539573\nbt: 80  loss: 1.764663198719854\nbt: 100  loss: 1.6449254906695823\nbt: 120  loss: 1.8081028150475544\nbt: 0  loss: 2.0896545078443443\nbt: 200  loss: 2.2143786886463994\nbt: 400  loss: 2.043594857920771\nbt: 600  loss: 1.9591907003651494\nbt: 800  loss: 2.1062547434931216\nbt: 1000  loss: 2.213011866030486\nbt: 1200  loss: 2.1471856158712637\nbt: 1400  loss: 2.2242050170898438\nbt: 0  loss: 1.7425625013268513\nbt: 20  loss: 1.7082834658415422\nbt: 40  loss: 1.6277459186056387\nbt: 60  loss: 1.7278075840162195\nbt: 80  loss: 1.8213517562202786\nbt: 100  loss: 1.7821379951808765\nbt: 120  loss: 1.6343863114066746\nbt: 0  loss: 2.126134457795516\nbt: 200  loss: 2.1876476121985395\nbt: 400  loss: 2.0179677216903023\nbt: 600  loss: 2.057988705842391\nbt: 800  loss: 2.165537460990574\nbt: 1000  loss: 2.1243045641028364\nbt: 1200  loss: 2.1025000862453296\nbt: 1400  loss: 2.1290686234183935\nbt: 0  loss: 1.9022765781568445\nbt: 20  loss: 1.692665265954059\nbt: 40  loss: 1.8206977844238281\nbt: 60  loss: 1.7476372096849524\nbt: 80  loss: 1.8280485401982847\nbt: 100  loss: 1.873831209929093\nbt: 120  loss: 1.6875479325004246\nbt: 0  loss: 2.119190381920856\nbt: 200  loss: 1.9570791825004246\nbt: 400  loss: 2.1176414489746094\nbt: 600  loss: 2.10974004994268\nbt: 800  loss: 2.155408610468325\nbt: 1000  loss: 2.1926291092582373\nbt: 1200  loss: 2.1347628054411514\nbt: 1400  loss: 2.1051677206288213\nbt: 0  loss: 1.7927418584408967\nbt: 20  loss: 1.7049364836319634\nbt: 40  loss: 1.950048363727072\nbt: 60  loss: 1.7764025149138079\nbt: 80  loss: 1.7564138329547385\nbt: 100  loss: 1.7829128762950068\nbt: 120  loss: 1.7647938935653023\nbt: 0  loss: 1.9538897638735564\nbt: 200  loss: 2.0644649008046025\nbt: 400  loss: 2.0858169223951255\nbt: 600  loss: 2.212045089058254\nbt: 800  loss: 2.194782422936481\nbt: 1000  loss: 2.1100357719089673\nbt: 1200  loss: 2.232692055080248\nbt: 1400  loss: 2.206206446108611\nbt: 0  loss: 1.7094452899435293\nbt: 20  loss: 1.8128486301587976\nbt: 40  loss: 1.8523970894191577\nbt: 60  loss: 1.6689703568168308\nbt: 80  loss: 1.6766242980957031\nbt: 100  loss: 1.7153567438540251\nbt: 120  loss: 1.8396647909413213\nbt: 0  loss: 2.010112596594769\nbt: 200  loss: 2.1800324813179346\nbt: 400  loss: 2.207490008810292\nbt: 600  loss: 2.083537060281505\nbt: 800  loss: 2.3231920988663384\nbt: 1000  loss: 2.137499933657439\nbt: 1200  loss: 2.260277457859205\nbt: 1400  loss: 2.1011258000912876\nbt: 0  loss: 1.659706281579059\nbt: 20  loss: 1.6865627454674763\nbt: 40  loss: 1.8089992689049763\nbt: 60  loss: 1.8222888448963994\nbt: 80  loss: 1.6341882788616677\nbt: 100  loss: 1.8317343670388926\nbt: 120  loss: 1.7298283784285835\nbt: 0  loss: 2.157209313434103\nbt: 200  loss: 2.058826612389606\nbt: 400  loss: 2.0937347412109375\nbt: 600  loss: 2.1131918533988623\nbt: 800  loss: 2.0386384051779043\nbt: 1000  loss: 2.050214684527853\nbt: 1200  loss: 2.0152130126953125\nbt: 1400  loss: 2.0944006546683935\nbt: 0  loss: 1.6320001353388247\nbt: 20  loss: 1.7200808317764946\nbt: 40  loss: 1.5682795980702275\nbt: 60  loss: 1.730365919030231\nbt: 80  loss: 1.6008804984714673\nbt: 100  loss: 1.706024169921875\nbt: 120  loss: 1.675086145815642\nbt: 0  loss: 2.0237240998641304\nbt: 200  loss: 2.137994849163553\nbt: 400  loss: 2.1123068436332373\nbt: 600  loss: 2.100504833719005\nbt: 800  loss: 2.207197603972062\nbt: 1000  loss: 1.9837067645529043\nbt: 1200  loss: 2.04693023018215\nbt: 1400  loss: 2.0659060270889946\nbt: 0  loss: 1.7223452692446501\nbt: 20  loss: 1.8326931829037874\nbt: 40  loss: 1.7865802930748982\nbt: 60  loss: 1.7455178965692935\nbt: 80  loss: 1.6546761885933254\nbt: 100  loss: 1.4997611667798914\nbt: 120  loss: 1.8027882783309273\n{కార్డుద్వారానే}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{పరిదృశ్యాలు}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{కురబలకోట}}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{నిరిస్తున్నారు}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{కుదుర్చుకోడంలో}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{రాఘవేంద్రరావుగారిని}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{లభిస్తుండవచ్చు}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{చార్జిషిట్}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{అనురాగబద్దులవుతారు}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{మార్చుకుంటామా}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{పెట్టుకోవడాన్ని}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{క్షమించిందని}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{ఎస్కవేటర్లు}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{చింతమ్మ}}}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{నిర్లక్షనికి}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{తరువాతమారిన}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{స్టువర్టు}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{అరెనాస్}}}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{కౌన్సెలింగ్కి}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{అభియోగంలో}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{నేర్చుకుంటారు}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{రిపీటవుతుందా}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{కూడగట్టారని}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{దాచవచ్చని}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{సమర్థించబడ్డాడు}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{వేట్టైకారన్}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{తరుముతాడు}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{ఇదేపరిస్థితి}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{వచ్చిరాని}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{చతుష}}}}}}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{ఉంటడంలో}}}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\n{కొడ్తోంది}}}}}}}}}}}}}   {వి}}}}}}}}}}}}}}}}}}}}\nbt: 0  loss: 2.1712493896484375\nbt: 200  loss: 2.2151336669921875\nbt: 400  loss: 2.0922237893809443\nbt: 600  loss: 2.113476794698964\nbt: 800  loss: 2.124476723048998\nbt: 1000  loss: 2.1864751732867695\nbt: 1200  loss: 2.045676024063774\nbt: 1400  loss: 2.2930518440578296\nbt: 0  loss: 1.8163830301036006\nbt: 20  loss: 1.6707914601201597\nbt: 40  loss: 1.6555081243100374\nbt: 60  loss: 1.6646103236986243\nbt: 80  loss: 1.7294168886931047\nbt: 100  loss: 1.8230154617972996\nbt: 120  loss: 1.7227448173191235\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▄▁▃▇▇██████████████████████▇▇▇</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▂▁▅▆▇▇▇███████▇██▇█▇██████▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>3318.98571</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>219.27097</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeRNNbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/8tkv29ys</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_193015-8tkv29ys/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v90jjsmz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_200030-v90jjsmz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">giddy-sweep-3</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:v90jjsmz) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">giddy-sweep-3</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_200030-v90jjsmz/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:v90jjsmz). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_200046-v90jjsmz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.163194407587466\nbt: 200  loss: 1.6920272163722827\nbt: 400  loss: 1.4615438710088315\nbt: 600  loss: 1.597135129182235\nbt: 800  loss: 1.3781523497208306\nbt: 1000  loss: 1.4792289733886719\nbt: 1200  loss: 1.4172378208326257\nbt: 1400  loss: 1.5613207609757134\nbt: 0  loss: 1.2321562559708306\nbt: 20  loss: 1.2564548824144446\nbt: 40  loss: 1.147334969562033\nbt: 60  loss: 1.2154455599577532\nbt: 80  loss: 1.2766868757164997\nbt: 100  loss: 1.06817510853643\nbt: 120  loss: 1.2863540649414062\nbt: 0  loss: 1.3453754756761633\nbt: 200  loss: 1.1820356949515964\nbt: 400  loss: 1.534071217412534\nbt: 600  loss: 1.4699904400369395\nbt: 800  loss: 1.0384518167246943\nbt: 1000  loss: 1.0996597124182659\nbt: 1200  loss: 1.0901199838389521\nbt: 1400  loss: 1.1262148981509001\nbt: 0  loss: 1.19091274427331\nbt: 20  loss: 0.7594254535177479\nbt: 40  loss: 1.1605759496274202\nbt: 60  loss: 0.6894342588341754\nbt: 80  loss: 0.7080376666525136\nbt: 100  loss: 1.207737051922342\nbt: 120  loss: 1.159313036047894\nbt: 0  loss: 1.591905345087466\nbt: 200  loss: 1.5095461969790251\nbt: 400  loss: 0.9100426383640455\nbt: 600  loss: 1.8015896341075068\nbt: 800  loss: 1.3731574182925017\nbt: 1000  loss: 1.4824480803116509\nbt: 1200  loss: 1.720074860945992\nbt: 1400  loss: 0.7875252599301545\nbt: 0  loss: 0.5520243022752844\nbt: 20  loss: 1.3617902838665505\nbt: 40  loss: 1.3379233816395635\nbt: 60  loss: 0.5683982268623684\nbt: 80  loss: 0.5594209588092306\nbt: 100  loss: 0.5890276121056598\nbt: 120  loss: 1.335873728213103\nbt: 0  loss: 1.617657537045686\nbt: 200  loss: 0.7831547778585682\nbt: 400  loss: 0.7306399138077445\nbt: 600  loss: 1.5616902890412703\nbt: 800  loss: 1.7125146285347317\nbt: 1000  loss: 1.6522167039954143\nbt: 1200  loss: 1.5897244992463484\nbt: 1400  loss: 1.4906121958856997\nbt: 0  loss: 0.42974463753078296\nbt: 20  loss: 1.2445108994193699\nbt: 40  loss: 0.4247944044030231\nbt: 60  loss: 1.4671945986540422\nbt: 80  loss: 1.133898693582286\nbt: 100  loss: 0.40069032751995587\nbt: 120  loss: 1.2499640920887822\nbt: 0  loss: 1.5901840873386548\nbt: 200  loss: 1.7380225140115488\nbt: 400  loss: 1.7965072963548743\nbt: 600  loss: 0.5772311583809231\nbt: 800  loss: 1.6310011822244395\nbt: 1000  loss: 0.5444554453310759\nbt: 1200  loss: 1.6547236235245415\nbt: 1400  loss: 1.3765256301216457\nbt: 0  loss: 0.4161522492118504\nbt: 20  loss: 0.41673162709111755\nbt: 40  loss: 1.1870962225872537\nbt: 60  loss: 1.1679243004840354\nbt: 80  loss: 1.343226142551588\nbt: 100  loss: 1.247403269228728\nbt: 120  loss: 1.219290194304093\nbt: 0  loss: 1.765605760657269\nbt: 200  loss: 1.6890323473059612\nbt: 400  loss: 0.471772981726605\nbt: 600  loss: 1.6042226708453635\nbt: 800  loss: 1.780676800271739\nbt: 1000  loss: 1.5414571347443953\nbt: 1200  loss: 1.7792695086935293\nbt: 1400  loss: 0.47601919588835345\nbt: 0  loss: 1.6077093041461448\nbt: 20  loss: 1.686986840289572\nbt: 40  loss: 1.8661955128545347\nbt: 60  loss: 0.4304479516070822\nbt: 80  loss: 1.6348971491274626\nbt: 100  loss: 0.3888098260630732\nbt: 120  loss: 1.5116243777067766\nbt: 0  loss: 2.011576611062755\nbt: 200  loss: 0.4654634309851605\nbt: 400  loss: 1.6013666235882302\nbt: 600  loss: 1.6759845899498982\nbt: 800  loss: 0.4839336975761082\nbt: 1000  loss: 1.5811505525008491\nbt: 1200  loss: 0.3787814015927522\nbt: 1400  loss: 0.40840016240658966\nbt: 0  loss: 1.1479819753895635\nbt: 20  loss: 1.3316540925399116\nbt: 40  loss: 1.166936791461447\nbt: 60  loss: 0.3026883083841075\nbt: 80  loss: 1.2387036033298657\nbt: 100  loss: 1.154150506724482\nbt: 120  loss: 1.2761678281037703\nbt: 0  loss: 1.593163531759511\nbt: 200  loss: 0.4529695096223251\nbt: 400  loss: 0.4351243558137313\nbt: 600  loss: 0.38571399191151495\nbt: 800  loss: 0.4552045075789742\nbt: 1000  loss: 0.3385325307431428\nbt: 1200  loss: 1.7789346446161685\nbt: 1400  loss: 1.812310260275136\nbt: 0  loss: 0.26083309754081396\nbt: 20  loss: 1.188696239305579\nbt: 40  loss: 1.1916588493015454\nbt: 60  loss: 1.2530792899753735\nbt: 80  loss: 1.3088292660920515\nbt: 100  loss: 1.189730105192765\nbt: 120  loss: 1.2091491533362346\nbt: 0  loss: 1.7355013308317766\nbt: 200  loss: 1.4299797389818274\nbt: 400  loss: 1.6346093882685122\nbt: 600  loss: 1.5254871534264607\nbt: 800  loss: 1.6399318860924763\nbt: 1000  loss: 1.7507971058721128\nbt: 1200  loss: 1.5650021096934443\nbt: 1400  loss: 0.36545645672342053\nbt: 0  loss: 1.2901891625445823\nbt: 20  loss: 0.28648220974466077\nbt: 40  loss: 0.25110143163929816\nbt: 60  loss: 0.3247925924218219\nbt: 80  loss: 1.3014931056810461\nbt: 100  loss: 1.2996305382770041\nbt: 120  loss: 0.2514472007751465\nbt: 0  loss: 0.3700866284577743\nbt: 200  loss: 1.6935338559358015\nbt: 400  loss: 0.3806469544120457\nbt: 600  loss: 1.6304994666058084\nbt: 800  loss: 0.3138290280881135\nbt: 1000  loss: 1.6759356623110564\nbt: 1200  loss: 0.35098473922066065\nbt: 1400  loss: 0.4397876159004543\nbt: 0  loss: 1.3313537265943445\nbt: 20  loss: 1.2775886369788128\nbt: 40  loss: 1.4001982315726902\nbt: 60  loss: 0.29773612644361414\nbt: 80  loss: 1.4843020231827446\nbt: 100  loss: 0.27061665576437244\nbt: 120  loss: 0.25427683540012525\nbt: 0  loss: 1.8203682277513586\nbt: 200  loss: 1.7716379580290422\nbt: 400  loss: 1.7790432805600374\nbt: 600  loss: 1.6433931433636209\nbt: 800  loss: 0.378226902173913\nbt: 1000  loss: 1.839327273161515\nbt: 1200  loss: 0.38552217898161517\nbt: 1400  loss: 0.3294912421185037\nbt: 0  loss: 1.3476623866869055\nbt: 20  loss: 0.27099453884622327\nbt: 40  loss: 1.3767385068147078\nbt: 60  loss: 0.2680618866630223\nbt: 80  loss: 1.5022534909455671\nbt: 100  loss: 1.3797920061194378\nbt: 120  loss: 1.3103169980256453\nbt: 0  loss: 1.9280072087826936\nbt: 200  loss: 0.3820065622744353\nbt: 400  loss: 1.8136536971382473\nbt: 600  loss: 0.3798930955969769\nbt: 800  loss: 1.8183238817297893\nbt: 1000  loss: 0.3582184418388035\nbt: 1200  loss: 1.6474017267641814\nbt: 1400  loss: 0.3611586612203847\nbt: 0  loss: 0.2560511671978494\nbt: 20  loss: 0.21603497214939282\nbt: 40  loss: 0.23485281156456989\nbt: 60  loss: 1.1805344457211702\nbt: 80  loss: 0.23464540813280188\nbt: 100  loss: 1.249266251273777\nbt: 120  loss: 1.1813770791758662\nbt: 0  loss: 0.3356692480004352\nbt: 200  loss: 1.7640556667162024\nbt: 400  loss: 1.6565493708071501\nbt: 600  loss: 0.34861332437266473\nbt: 800  loss: 0.3710570957349694\nbt: 1000  loss: 1.7908870862877888\nbt: 1200  loss: 1.7962953318720278\nbt: 1400  loss: 0.35156212682309357\nbt: 0  loss: 1.4886977154275645\nbt: 20  loss: 1.3949692767599355\nbt: 40  loss: 0.2001760316931683\nbt: 60  loss: 1.5419588503630266\nbt: 80  loss: 1.2869829094928245\nbt: 100  loss: 1.360378182452658\nbt: 120  loss: 0.22183716815450918\nbt: 0  loss: 1.7874148824940557\nbt: 200  loss: 1.713383384372877\nbt: 400  loss: 1.7529860786769702\nbt: 600  loss: 1.708132038945737\nbt: 800  loss: 1.2733138540516729\nbt: 1000  loss: 1.6767437147057576\nbt: 1200  loss: 1.8907999785050102\nbt: 1400  loss: 1.660812875498896\nbt: 0  loss: 2.130078191342561\nbt: 20  loss: 2.1613479282545005\nbt: 40  loss: 1.1732318712317424\nbt: 60  loss: 2.1249359794284985\nbt: 80  loss: 1.0318370487378992\nbt: 100  loss: 1.0960791214652683\nbt: 120  loss: 1.0071431864862856\nbt: 0  loss: 1.7872277964716372\nbt: 200  loss: 1.6988304801609204\nbt: 400  loss: 1.2440377111020295\nbt: 600  loss: 1.3966344750445823\nbt: 800  loss: 1.6790753240170686\nbt: 1000  loss: 1.8261572796365488\nbt: 1200  loss: 1.3368007825768513\nbt: 1400  loss: 1.7050155971361243\nbt: 0  loss: 1.27417688784392\nbt: 20  loss: 1.06256800112517\nbt: 40  loss: 1.3670886495838994\nbt: 60  loss: 1.4876964403235393\nbt: 80  loss: 1.1186665244724439\nbt: 100  loss: 0.952675777932872\nbt: 120  loss: 0.9849315311597742\nbt: 0  loss: 1.7212147920028023\nbt: 200  loss: 1.7942897962487263\nbt: 400  loss: 1.8714763807213826\nbt: 600  loss: 1.7640122123386548\nbt: 800  loss: 1.2220344543457031\nbt: 1000  loss: 1.6841180220894192\nbt: 1200  loss: 1.3461629618769106\nbt: 1400  loss: 1.3408437811810037\nbt: 0  loss: 1.4035092229428499\nbt: 20  loss: 0.800302090852157\nbt: 40  loss: 0.8482377425484036\nbt: 60  loss: 0.8653035371199899\nbt: 80  loss: 1.3076513539189878\nbt: 100  loss: 1.4415507109268852\nbt: 120  loss: 1.4092048976732336\nbt: 0  loss: 1.2015780573305876\nbt: 200  loss: 1.1344539808190388\nbt: 400  loss: 1.0279059202774712\nbt: 600  loss: 1.7180227196734885\nbt: 800  loss: 2.0289066148840864\nbt: 1000  loss: 1.173882360043733\nbt: 1200  loss: 1.2686007126517918\nbt: 1400  loss: 1.89556652566661\nbt: 0  loss: 0.8383434959079908\nbt: 20  loss: 1.0242068249246348\nbt: 40  loss: 0.8945376354715099\nbt: 60  loss: 0.9478457906971807\nbt: 80  loss: 0.8443825763204823\nbt: 100  loss: 0.9490077806555707\nbt: 120  loss: 1.4214731299358865\nbt: 0  loss: 1.1176394586977751\nbt: 200  loss: 1.1912664330523948\nbt: 400  loss: 1.886440608812415\nbt: 600  loss: 1.3552756102188774\nbt: 800  loss: 1.6109872900921365\nbt: 1000  loss: 1.6744857456373132\nbt: 1200  loss: 1.4237929634425952\nbt: 1400  loss: 1.922504590905231\nbt: 0  loss: 1.2855024752409563\nbt: 20  loss: 1.298412157141644\nbt: 40  loss: 1.3878755984099016\nbt: 60  loss: 1.2699502032736074\nbt: 80  loss: 1.3969716611115828\nbt: 100  loss: 1.1754176927649456\nbt: 120  loss: 1.443235977836277\nbt: 0  loss: 1.4421632186226223\nbt: 200  loss: 1.3618144159731658\nbt: 400  loss: 1.4081686268682065\nbt: 600  loss: 1.248453306115192\nbt: 800  loss: 1.7433081917140796\nbt: 1000  loss: 1.3201715220575747\nbt: 1200  loss: 1.3633044698963994\nbt: 1400  loss: 1.2416430763576343\nbt: 0  loss: 1.0006640890370244\nbt: 20  loss: 1.5434119183084238\nbt: 40  loss: 1.5144973423170007\nbt: 60  loss: 1.2427652607793394\nbt: 80  loss: 0.9098892211914062\nbt: 100  loss: 1.4485251385232676\nbt: 120  loss: 1.0023390728494395\n{సింప్లిసియస్}}}}}}}}}}   {అ్్్}}}}}}}}}}}}}}}}}}\n{మిత్రమండలిని}}}}}}}}}}   {అ్్కా}}}}}}}}}}}}}}}}}\n{కరస్టు}}}}}}}}}}}}}}}}   {వారర}}్}}}}}}}}}}}}}}}\n{రిక్వెస్టే}}}}}}}}}}}}   {తరరరర}}}}}}}}}}}}}}}}}\n{ముందుకెళ్లిపోతోంది}}}}   {వరర్్త}}}}}}}}}}}}}}}}\n{చీరకట్టుకుంటే}}}}}}}}}   {అర్తకాా}}}}}}}}}}}}}}}\n{సూచీలోని}}}}}}}}}}}}}}   {వ్్్త}ా}}}}}}}}}}}}}}}\n{కటారియాకు}}}}}}}}}}}}}   {వరరుు్}}}}}}}}}}}}}}}}\n{మాసిజానికి}}}}}}}}}}}}   {వరరర్}}}}}}}}}}}}}}}}}\n{ఉత్సాహపడిన}}}}}}}}}}}}   {అరర్తతాా}}}}}}}}}}}}}}\n{దేవానిక్}}}}}}}}}}}}}}   {అ్రరరర}}}}}}}}}}}}}}}}\n{షట్టర్లుతో}}}}}}}}}}}}   {వత్్తా}}}}}}}}}}}}}}}}\n{కాపులంటే}}}}}}}}}}}}}}   {అ్్్ాాా}}}}}}}}}}}}}}}\n{నర్మదపై}}}}}}}}}}}}}}}   {కెరుుర}}}}}}}}}}}}}}}}\n{చెయించి}}}}}}}}}}}}}}}   {సరరరుు}}}}}}}}}}}}}}}}\n{నంబియాత్}}}}}}}}}}}}}}   {అె్్్్}}}}}}}}}}}}}}}}\n{చలరేగిపోతున్నారు}}}}}}   {వదక్ాం}}}}}}}}}}}}}}}}\n{టోకుని}}}}}}}}}}}}}}}}   {వె్}}్}}}}}}}}}}}}}}}}\n{ఆనందాన్నందిస్తాయి}}}}}   {అరర్ాా}}}}}}}}}}}}}}}}\n{హపెండ్}}}}}}}}}}}}}}}}   {వ}్్}ా}}}}}}}}}}}}}}}}\n{బెర్గమాస్క్యూ}}}}}}}}}   {వ}్్}}}}}}}}}}}}}}}}}}\n{స్క్వార్ట్}}}}}}}}}}}}   {ద్్్్}}}}}}}}}}}}}}}}}\n{చిత్రవిచిత్రాలుగా}}}}}   {అుర్్త}}}}}}}}}}}}}}}}\n{కుక్కతోను}}}}}}}}}}}}}   {సరరుుు}}}}}}}}}}}}}}}}\n{నిగ్రహించిన}}}}}}}}}}}   {వార్త}}}}}}}}}}}}}}}}}\n{వచ్చిందిప్పుడు}}}}}}}}   {అరరరకక}}}}}}}}}}}}}}}}\n{గుర్తించవద్దని}}}}}}}}   {కరరుుుు}}}}}}}}}}}}}}}\n{సిపెల్లి}}}}}}}}}}}}}}   {అా్్ా}}}}}}}}}}}}}}}}}\n{కొన్నింటిలోనే}}}}}}}}}   {సా్్్్}}}}}}}}}}}}}}}}\n{రిఫ్కిన్స్}}}}}}}}}}}}   {సరరరరు}}}}}}}}}}}}}}}}\n{తోని}}}}}}}}}}}}}}}}}}   {త్ర్్}}}}}}}}}}}}}}}}}\n{రూపొందిచాలన్నారు}}}}}}   {వరరుుు}}}}}}}}}}}}}}}}\nbt: 0  loss: 1.9702325903851052\nbt: 200  loss: 1.7506747038468071\nbt: 400  loss: 1.2199974889340608\nbt: 600  loss: 1.134467083474864\nbt: 800  loss: 1.6572665338930876\nbt: 1000  loss: 1.3281479711117952\nbt: 1200  loss: 1.3119816987410835\nbt: 1400  loss: 1.2540964043658713\nbt: 0  loss: 1.332580981047257\nbt: 20  loss: 1.3206760572350544\nbt: 40  loss: 0.9892463684082031\nbt: 60  loss: 1.2522930476976477\nbt: 80  loss: 1.5394044959026834\nbt: 100  loss: 1.3750579668127971\nbt: 120  loss: 1.3636407437531843\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.030 MB uploaded\\r'), FloatProgress(value=0.04640541662674459, max=1.…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▂▂▃▅▆▆▇▇█▂▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▇▄▃▂▂▂▁▁▁▁▂▂▂▇█▇▇███</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▂▃▂▃▅▄▄▅▆█▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▃▂▂▁▁▄▂▁▁▂▂▁▂█▄▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>2572.34848</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>153.81995</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/v90jjsmz</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_200046-v90jjsmz/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9j0c7r51 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_202211-9j0c7r51</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:9j0c7r51) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">winter-sweep-4</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_202211-9j0c7r51/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:9j0c7r51). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_202228-9j0c7r51</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">embedding32cellTypeRNNbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.123605811077615\nbt: 200  loss: 2.048968605373217\nbt: 400  loss: 2.076866979184358\nbt: 600  loss: 1.6777944150178328\nbt: 800  loss: 1.7829699308975884\nbt: 1000  loss: 1.8802588089652683\nbt: 1200  loss: 1.683289901069973\nbt: 1400  loss: 1.8315088023310122\nbt: 0  loss: 1.447929050611413\nbt: 20  loss: 1.4341271441915762\nbt: 40  loss: 1.5406011498492698\nbt: 60  loss: 1.4378754988960598\nbt: 80  loss: 1.4779354593028193\nbt: 100  loss: 1.4707883751910666\nbt: 120  loss: 1.4166964655337126\nbt: 0  loss: 1.7247498553732168\nbt: 200  loss: 1.7825800024944802\nbt: 400  loss: 1.78882068136464\nbt: 600  loss: 1.714500095533288\nbt: 800  loss: 2.0737963137419326\nbt: 1000  loss: 2.0483823029891304\nbt: 1200  loss: 2.2482090825619907\nbt: 1400  loss: 1.934849448826002\nbt: 0  loss: 1.7102654498556387\nbt: 20  loss: 1.8149586553158967\nbt: 40  loss: 1.7733953724736753\nbt: 60  loss: 1.8148559902025305\nbt: 80  loss: 1.7945249806279722\nbt: 100  loss: 1.7219541798467222\nbt: 120  loss: 1.6578014207922893\nbt: 0  loss: 2.151415949282439\nbt: 200  loss: 2.1820534415867017\nbt: 400  loss: 2.0715708525284477\nbt: 600  loss: 2.0505910127059273\nbt: 800  loss: 2.0843656788701597\nbt: 1000  loss: 2.229156328284222\nbt: 1200  loss: 2.2462013908054517\nbt: 1400  loss: 2.1248321533203125\nbt: 0  loss: 1.7008844458538552\nbt: 20  loss: 1.7273338981296704\nbt: 40  loss: 1.8064873736837637\nbt: 60  loss: 1.9086988697881284\nbt: 80  loss: 1.7555276621942935\nbt: 100  loss: 1.8334727079971977\nbt: 120  loss: 1.7482614931852922\nbt: 0  loss: 2.1910534734311313\nbt: 200  loss: 2.0324116582455845\nbt: 400  loss: 2.175641101339589\nbt: 600  loss: 2.08057337221892\nbt: 800  loss: 2.1569278551184614\nbt: 1000  loss: 2.1838417053222656\nbt: 1200  loss: 2.222487905751104\nbt: 1400  loss: 2.17102399079696\nbt: 0  loss: 1.7664680480957031\nbt: 20  loss: 1.7347990948220957\nbt: 40  loss: 1.8795831099800442\nbt: 60  loss: 1.7606849670410156\nbt: 80  loss: 1.7916516843049421\nbt: 100  loss: 1.7762976936672046\nbt: 120  loss: 1.543458358101223\nbt: 0  loss: 2.1620277736497964\nbt: 200  loss: 2.1505675937818443\nbt: 400  loss: 2.303716410761294\nbt: 600  loss: 2.0395068293032437\nbt: 800  loss: 2.1515577565068784\nbt: 1000  loss: 2.2309790901515796\nbt: 1200  loss: 2.0073263748832373\nbt: 1400  loss: 2.12861152317213\nbt: 0  loss: 1.7985824916673743\nbt: 20  loss: 1.742266779360564\nbt: 40  loss: 1.7290979468304177\nbt: 60  loss: 1.7235551917034646\nbt: 80  loss: 1.6817736418350884\nbt: 100  loss: 1.686596911886464\nbt: 120  loss: 1.7960301274838655\nbt: 0  loss: 2.126769024392833\nbt: 200  loss: 2.1247187075407608\nbt: 400  loss: 2.1112327575683594\nbt: 600  loss: 2.0457168247388755\nbt: 800  loss: 1.9926598590353262\nbt: 1000  loss: 2.161258199940557\nbt: 1200  loss: 2.113743491794752\nbt: 1400  loss: 2.014798703400985\nbt: 0  loss: 1.6682425789211108\nbt: 20  loss: 1.7312494360882302\nbt: 40  loss: 1.8152766020401665\nbt: 60  loss: 1.7709657420282778\nbt: 80  loss: 1.7539314601732336\nbt: 100  loss: 1.7256655485733696\nbt: 120  loss: 1.798405357029127\nbt: 0  loss: 2.068573827328889\nbt: 200  loss: 2.048650326936141\nbt: 400  loss: 1.9183250095533289\nbt: 600  loss: 2.197271595830503\nbt: 800  loss: 2.1561904575513755\nbt: 1000  loss: 2.176967786706012\nbt: 1200  loss: 2.2293706147567085\nbt: 1400  loss: 2.2146525175675102\nbt: 0  loss: 1.7970997354258662\nbt: 20  loss: 1.7544207365616509\nbt: 40  loss: 1.6961333233377207\nbt: 60  loss: 1.8564507857612942\nbt: 80  loss: 1.6272136854088826\nbt: 100  loss: 1.7957455178965693\nbt: 120  loss: 1.6047749726668648\nbt: 0  loss: 2.0443382263183594\nbt: 200  loss: 2.056058303169582\nbt: 400  loss: 2.061481641686481\nbt: 600  loss: 2.0494127688200576\nbt: 800  loss: 2.110720427139946\nbt: 1000  loss: 2.1102052771526836\nbt: 1200  loss: 2.3296643132748813\nbt: 1400  loss: 2.1271358987559443\nbt: 0  loss: 1.612241496210513\nbt: 20  loss: 1.7630583721658457\nbt: 40  loss: 1.6988216897715693\nbt: 60  loss: 1.774847942849864\nbt: 80  loss: 1.7249366096828296\nbt: 100  loss: 1.6731089716372283\nbt: 120  loss: 1.86023181417714\nbt: 0  loss: 2.1235014874002207\nbt: 200  loss: 2.1802738023840864\nbt: 400  loss: 2.0219452899435293\nbt: 600  loss: 2.3395870042883833\nbt: 800  loss: 2.1251817786175273\nbt: 1000  loss: 2.157670725946841\nbt: 1200  loss: 2.053242724874745\nbt: 1400  loss: 2.1340511156165083\nbt: 0  loss: 1.7119697902513586\nbt: 20  loss: 1.6898037454356318\nbt: 40  loss: 1.8522189596424932\nbt: 60  loss: 1.6200823576554009\nbt: 80  loss: 1.774315543796705\nbt: 100  loss: 1.6597260184909985\nbt: 120  loss: 1.6038732114045515\nbt: 0  loss: 2.158439304517663\nbt: 200  loss: 1.9287091130795686\nbt: 400  loss: 2.20801245647928\nbt: 600  loss: 2.1228319251019023\nbt: 800  loss: 2.0500413645868716\nbt: 1000  loss: 2.178160625955333\nbt: 1200  loss: 2.2116413945737095\nbt: 1400  loss: 1.9677613299825918\nbt: 0  loss: 1.79058721791143\nbt: 20  loss: 1.6921716772991677\nbt: 40  loss: 1.7272065204122793\nbt: 60  loss: 1.8854207577912703\nbt: 80  loss: 1.7155556056810461\nbt: 100  loss: 1.6289261527683423\nbt: 120  loss: 1.6451213670813518\nbt: 0  loss: 2.1116769210152\nbt: 200  loss: 2.066356493079144\nbt: 400  loss: 2.099847544794497\nbt: 600  loss: 2.0511083188264267\nbt: 800  loss: 2.1066018809442935\nbt: 1000  loss: 2.0839521988578467\nbt: 1200  loss: 2.214448016622792\nbt: 1400  loss: 2.10608258454696\nbt: 0  loss: 1.8315975355065388\nbt: 20  loss: 1.7233316172724185\nbt: 40  loss: 1.6445818362028704\nbt: 60  loss: 1.874238221541695\nbt: 80  loss: 1.669170213782269\nbt: 100  loss: 1.7369069638459578\nbt: 120  loss: 1.7187108578889265\nbt: 0  loss: 2.1274160302203633\nbt: 200  loss: 2.219057829483696\nbt: 400  loss: 2.0779211624808935\nbt: 600  loss: 2.0738925104555874\nbt: 800  loss: 2.2698720849078633\nbt: 1000  loss: 2.026320913563604\nbt: 1200  loss: 2.246051788330078\nbt: 1400  loss: 2.0937675807787026\nbt: 0  loss: 1.7568445620329485\nbt: 20  loss: 1.843171492866848\nbt: 40  loss: 1.7734122898267664\nbt: 60  loss: 1.8398623259171196\nbt: 80  loss: 1.7990536897078804\nbt: 100  loss: 1.6999461961829143\nbt: 120  loss: 1.8723172726838484\nbt: 0  loss: 2.1882274461829145\nbt: 200  loss: 1.9267463684082031\nbt: 400  loss: 2.03856725278108\nbt: 600  loss: 2.133568639340608\nbt: 800  loss: 2.032510011092476\nbt: 1000  loss: 2.0804814877717392\nbt: 1200  loss: 2.26093574192213\nbt: 1400  loss: 2.1781982753587807\nbt: 0  loss: 1.8046881634256113\nbt: 20  loss: 1.6876860908840015\nbt: 40  loss: 1.7523286238960598\nbt: 60  loss: 1.8045939569887908\nbt: 80  loss: 1.6460352358610735\nbt: 100  loss: 1.7948634935461956\nbt: 120  loss: 1.8258197618567424\nbt: 0  loss: 1.9993510038956352\nbt: 200  loss: 2.1265917238981826\nbt: 400  loss: 2.216776640518852\nbt: 600  loss: 2.096608369246773\nbt: 800  loss: 2.127249510391899\nbt: 1000  loss: 2.0247648487920347\nbt: 1200  loss: 2.0994451771611753\nbt: 1400  loss: 2.231764254362687\nbt: 0  loss: 1.662273241126019\nbt: 20  loss: 1.8464972454568613\nbt: 40  loss: 1.8841136434803838\nbt: 60  loss: 1.877546559209409\nbt: 80  loss: 1.8504766381305198\nbt: 100  loss: 1.638539687446926\nbt: 120  loss: 1.792167497717816\nbt: 0  loss: 2.19817999134893\nbt: 200  loss: 1.9862417138141135\nbt: 400  loss: 2.054010142450747\nbt: 600  loss: 1.958212313444718\nbt: 800  loss: 1.8712511477263079\nbt: 1000  loss: 1.968370188837466\nbt: 1200  loss: 1.9010240306024966\nbt: 1400  loss: 1.9733627982761548\nbt: 0  loss: 1.5861230933147927\nbt: 20  loss: 1.5395766548488452\nbt: 40  loss: 1.5110503486965015\nbt: 60  loss: 1.5698406385338826\nbt: 80  loss: 1.6571638687797214\nbt: 100  loss: 1.5076061746348506\nbt: 120  loss: 1.5819942640221638\nbt: 0  loss: 2.0114653214164404\nbt: 200  loss: 1.9010659922724185\nbt: 400  loss: 2.13800513226053\nbt: 600  loss: 2.046504476796026\nbt: 800  loss: 1.973822552224864\nbt: 1000  loss: 2.1197469960088315\nbt: 1200  loss: 2.1692214634107505\nbt: 1400  loss: 2.07965784487517\nbt: 0  loss: 1.5107753587805706\nbt: 20  loss: 1.6162543918775476\nbt: 40  loss: 1.6239031916079314\nbt: 60  loss: 1.534094934878142\nbt: 80  loss: 1.4390187470809273\nbt: 100  loss: 1.6424789428710938\nbt: 120  loss: 1.6535969609799592\nbt: 0  loss: 1.9765157284943953\nbt: 200  loss: 1.9993646041206692\nbt: 400  loss: 2.1303427323051123\nbt: 600  loss: 2.014986618705418\nbt: 800  loss: 2.0630894536557407\nbt: 1000  loss: 2.1432070524796196\nbt: 1200  loss: 2.0792198181152344\nbt: 1400  loss: 2.0657582490340523\nbt: 0  loss: 1.673528588336447\nbt: 20  loss: 1.6453104433806047\nbt: 40  loss: 1.5213064110797385\nbt: 60  loss: 1.7236658179241677\nbt: 80  loss: 1.4880815588909646\nbt: 100  loss: 1.6304951543393342\nbt: 120  loss: 1.6134685018788213\nbt: 0  loss: 2.1078511113705845\nbt: 200  loss: 2.0465172477390454\nbt: 400  loss: 2.20782006305197\nbt: 600  loss: 2.1093615656313687\nbt: 800  loss: 2.0988265327785327\nbt: 1000  loss: 2.119730576224949\nbt: 1200  loss: 1.9898754617442256\nbt: 1400  loss: 2.1532428575598677\nbt: 0  loss: 1.6637103868567424\nbt: 20  loss: 1.6671557219132134\nbt: 40  loss: 1.6614330125891643\nbt: 60  loss: 1.6386022153108015\nbt: 80  loss: 1.7859649658203125\nbt: 100  loss: 1.8609408502993376\nbt: 120  loss: 1.6515688688858696\nbt: 0  loss: 2.175345213516899\nbt: 200  loss: 2.1940017368482505\nbt: 400  loss: 2.1280917292055874\nbt: 600  loss: 1.9731516630753227\nbt: 800  loss: 1.982873999554178\nbt: 1000  loss: 2.2068826426630435\nbt: 1200  loss: 2.1574658932893174\nbt: 1400  loss: 2.123153354810632\nbt: 0  loss: 1.6566339575726052\nbt: 20  loss: 1.8733125769573709\nbt: 40  loss: 1.8737857652747112\nbt: 60  loss: 1.7429618835449219\nbt: 80  loss: 1.8765759675399116\nbt: 100  loss: 1.7412713092306387\nbt: 120  loss: 1.7398598712423574\nbt: 0  loss: 2.1773547296938687\nbt: 200  loss: 2.1864174552585767\nbt: 400  loss: 2.205449643342391\nbt: 600  loss: 2.0959072942319126\nbt: 800  loss: 2.1456754933232847\nbt: 1000  loss: 2.119188391644022\nbt: 1200  loss: 2.1724151943040932\nbt: 1400  loss: 1.9898159192956013\nbt: 0  loss: 1.6659849415654722\nbt: 20  loss: 1.7600802545962126\nbt: 40  loss: 1.7175583217454993\nbt: 60  loss: 1.7678866179093071\nbt: 80  loss: 1.705598084822945\nbt: 100  loss: 1.897444020146909\nbt: 120  loss: 1.690525718357252\nbt: 0  loss: 2.291646045187245\nbt: 200  loss: 2.0666192096212637\nbt: 400  loss: 2.0810332920240318\nbt: 600  loss: 2.0378794462784477\nbt: 800  loss: 2.0946864252505093\nbt: 1000  loss: 2.1335139067276665\nbt: 1200  loss: 2.2143831667692764\nbt: 1400  loss: 2.1863005264945654\nbt: 0  loss: 1.709855950396994\nbt: 20  loss: 1.9112416143002717\nbt: 40  loss: 1.7473844445270041\nbt: 60  loss: 1.6620387201723845\nbt: 80  loss: 1.9075675632642664\nbt: 100  loss: 1.6576536427373472\nbt: 120  loss: 1.6962920479152515\nbt: 0  loss: 2.242566979449728\nbt: 200  loss: 2.1026369177776836\nbt: 400  loss: 2.124277695365574\nbt: 600  loss: 2.127196270486583\nbt: 800  loss: 2.065428692361583\nbt: 1000  loss: 2.0005406918733017\nbt: 1200  loss: 1.9939162212869395\nbt: 1400  loss: 2.1080839737601904\nbt: 0  loss: 1.6565143751061482\nbt: 20  loss: 1.8655838344408118\nbt: 40  loss: 1.653956703517748\nbt: 60  loss: 1.8469535164211108\nbt: 80  loss: 1.6259286299995754\nbt: 100  loss: 1.798265374225119\nbt: 120  loss: 1.7665171415909477\nbt: 0  loss: 1.9376034943953804\nbt: 200  loss: 2.2599515500275986\nbt: 400  loss: 2.1235119363536006\nbt: 600  loss: 2.0521517214567764\nbt: 800  loss: 1.925243211829144\nbt: 1000  loss: 2.1305455746858017\nbt: 1200  loss: 2.0867992898692256\nbt: 1400  loss: 2.0743822844132134\nbt: 0  loss: 1.6718164526897927\nbt: 20  loss: 1.5798024716584578\nbt: 40  loss: 1.80761486551036\nbt: 60  loss: 1.775050453517748\nbt: 80  loss: 1.7215198019276494\nbt: 100  loss: 1.8024988589079485\nbt: 120  loss: 1.8539320904275645\nbt: 0  loss: 2.264650261920431\nbt: 200  loss: 2.1971642867378565\nbt: 400  loss: 1.9275514353876528\nbt: 600  loss: 2.0767148888629414\nbt: 800  loss: 2.01581274944803\nbt: 1000  loss: 2.1607513427734375\nbt: 1200  loss: 2.1961230402407437\nbt: 1400  loss: 2.1257372317106826\nbt: 0  loss: 1.628271019977072\nbt: 20  loss: 1.7217811916185461\nbt: 40  loss: 1.7777132780655571\nbt: 60  loss: 1.7293691220490828\nbt: 80  loss: 1.6399323836616848\nbt: 100  loss: 1.8011202604874321\nbt: 120  loss: 1.668608458145805\nbt: 0  loss: 2.1249470918074898\nbt: 200  loss: 2.138645006262738\nbt: 400  loss: 2.072296971860139\nbt: 600  loss: 2.0946879179581352\nbt: 800  loss: 2.0719427025836445\nbt: 1000  loss: 2.1900629789932915\nbt: 1200  loss: 2.2753745369289233\nbt: 1400  loss: 2.1518818399180537\nbt: 0  loss: 1.6469034941300102\nbt: 20  loss: 1.729669653851053\nbt: 40  loss: 1.5576855203379756\nbt: 60  loss: 1.7137771274732507\nbt: 80  loss: 1.8020034458326257\nbt: 100  loss: 1.6789902396824048\nbt: 120  loss: 1.7518269082774287\nbt: 0  loss: 2.1033219047214673\nbt: 200  loss: 2.140172709589419\nbt: 400  loss: 2.045941062595533\nbt: 600  loss: 2.274438775104025\nbt: 800  loss: 2.1046582097592563\nbt: 1000  loss: 2.0567227239194126\nbt: 1200  loss: 2.1381885694420855\nbt: 1400  loss: 1.9525469904360564\nbt: 0  loss: 1.77562779965608\nbt: 20  loss: 1.6602859497070312\nbt: 40  loss: 1.866325046705163\nbt: 60  loss: 1.7440275109332541\nbt: 80  loss: 1.8381924836531929\nbt: 100  loss: 1.753793301789657\nbt: 120  loss: 1.6712920147439707\nbt: 0  loss: 2.329014487888502\nbt: 200  loss: 2.1037985760232676\nbt: 400  loss: 2.2457663494607676\nbt: 600  loss: 2.2293157162873642\nbt: 800  loss: 2.2164334836213486\nbt: 1000  loss: 2.201691668966542\nbt: 1200  loss: 2.304297571596892\nbt: 1400  loss: 1.9200102764627207\nbt: 0  loss: 1.5970046001931895\nbt: 20  loss: 1.9166153617527173\nbt: 40  loss: 1.7861434273097827\nbt: 60  loss: 1.8065135789954143\nbt: 80  loss: 1.6714696469514265\nbt: 100  loss: 1.8618961831797725\nbt: 120  loss: 1.7838831362516985\nbt: 0  loss: 2.1456010237984033\nbt: 200  loss: 2.119046584419582\nbt: 400  loss: 2.061236505923064\nbt: 600  loss: 1.9909269913383152\nbt: 800  loss: 2.27593297543733\nbt: 1000  loss: 2.0384176503057065\nbt: 1200  loss: 2.1143624678902\nbt: 1400  loss: 2.2894316963527515\nbt: 0  loss: 1.687328172766644\nbt: 20  loss: 1.90899890402089\nbt: 40  loss: 1.7949522267217222\nbt: 60  loss: 1.8930882992951765\nbt: 80  loss: 1.9220279196034307\nbt: 100  loss: 1.7726649408755095\nbt: 120  loss: 1.7472988626231318\nbt: 0  loss: 2.0495139412257983\nbt: 200  loss: 2.11817102846892\nbt: 400  loss: 2.1621889860733696\nbt: 600  loss: 2.073283817457116\nbt: 800  loss: 1.8601114024286685\nbt: 1000  loss: 2.186253257419752\nbt: 1200  loss: 2.072571795919667\nbt: 1400  loss: 2.071614638618801\nbt: 0  loss: 1.8725217736285666\nbt: 20  loss: 1.7831346263056216\nbt: 40  loss: 1.6745290341584578\nbt: 60  loss: 1.644049768862517\nbt: 80  loss: 1.5547140370244565\nbt: 100  loss: 1.858615543531335\nbt: 120  loss: 1.75427942690642\n{కాల్వేట్}}}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{బిహారీలాల్}}}}}}}}}}}}   {}ా}}}}}}}}}}}}}}}}}}}}\n{అడ్జబుల్}}}}}}}}}}}}}}   {}ా}}}}}}}}}}}}}}}}}}}}\n{పెంపొందించడంతోబాటు}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{రైలుమార్గాన్ని}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{సంగ్రహించబడదు}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{చకడనక}}}}}}}}}}}}}}}}}   {క}}}}}}}}}}}}}}}}}}}}}\n{చేస్తావోనని}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{తెచ్చికోవడం}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{తట్టిగా}}}}}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{సాగుతున్నారాయన}}}}}}}}   {క}}}}}}}}}}}}}}}}}}}}}\n{త్రువా}}}}}}}}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{ఉద్యోగానుభవంతో}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{వాతావరణంపైనే}}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{కొనుక్కనే}}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{ఖుషీనగర్}}}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{నీదనే}}}}}}}}}}}}}}}}}   {క}}}}}}}}}}}}}}}}}}}}}\n{దాడిగానే}}}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{నిన్నుకోరి}}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{లీనమయ్యాయి}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{పరాజయమేనన్న}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{టైరెంట్లచే}}}}}}}}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{యుద్దవీరుల}}}}}}}}}}}}   {క}}}}}}}}}}}}}}}}}}}}}\n{భువనగిరిచౌటుప్పల్}}}}}   {అ}}}}}}}}}}}}}}}}}}}}}\n{క్రానియోసెరెబ్రల్}}}}}   {కా}}}}}}}}}}}}}}}}}}}}\n{దాచిపెడతారు}}}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{తాబేళ్లతో}}}}}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\n{సాక్ష్యాలా}}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{తిరిగొస్తున్నప్పుడు}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{రోజులన్నారు}}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{అత్తగారితోనూ}}}}}}}}}}   {అా}}}}}}}}}}}}}}}}}}}}\n{హైవేలపై}}}}}}}}}}}}}}}   {}}}}}}}}}}}}}}}}}}}}}}\nbt: 0  loss: 2.150645878003991\nbt: 200  loss: 2.0964786695397417\nbt: 400  loss: 2.188372902248217\nbt: 600  loss: 1.9464141182277515\nbt: 800  loss: 2.0130958557128906\nbt: 1000  loss: 2.1710006050441577\nbt: 1200  loss: 2.0149983945100205\nbt: 1400  loss: 2.2552624578061313\nbt: 0  loss: 1.7565498352050781\nbt: 20  loss: 1.6733199409816577\nbt: 40  loss: 1.677104784094769\nbt: 60  loss: 1.6779259391452954\nbt: 80  loss: 1.7520758587381113\nbt: 100  loss: 1.6645710157311482\nbt: 120  loss: 1.6882879837699558\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.034 MB of 0.034 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁▃███▇▇▇▇▇▇▇██▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▁██▇▇▇▇▇▇▇▇▇▇▇▄▄▅▇▇▇▇▇▇▇▆▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>3373.43612</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>221.83363</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeRNNbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/9j0c7r51</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_202228-9j0c7r51/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p2udy4f9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_205403-p2udy4f9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">glowing-sweep-5</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:p2udy4f9) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glowing-sweep-5</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_205403-p2udy4f9/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:p2udy4f9). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_205420-p2udy4f9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">embedding32cellTypeLSTMbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9</a>"},"metadata":{}},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_33/691801158.py\", line 5, in main_fun\n    train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n  File \"/tmp/ipykernel_33/4090218141.py\", line 33, in train\n    encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/tmp/ipykernel_33/3947759463.py\", line 19, in forward\n    output, prev_state = self.rnn(embdInput, prevState)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py\", line 866, in forward\n    raise RuntimeError(msg)\nRuntimeError: For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeLSTMbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/p2udy4f9</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_205420-p2udy4f9/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run p2udy4f9 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 308, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_33/691801158.py\", line 5, in main_fun\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_33/4090218141.py\", line 33, in train\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     encoder_output, encoder_current_state = encoder(source_batch,encoder_initial_state)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_33/3947759463.py\", line 19, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output, prev_state = self.rnn(embdInput, prevState)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py\", line 866, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise RuntimeError(msg)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: For batched 3-D input, hx and cx should also be 3-D but got (2-D, 2-D) tensors\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yfdfnuus with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_205500-yfdfnuus</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">warm-sweep-6</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:yfdfnuus) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-sweep-6</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_205500-yfdfnuus/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:yfdfnuus). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_205517-yfdfnuus</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.195771590523098\nbt: 200  loss: 1.5283286053201426\nbt: 400  loss: 1.6617038560950237\nbt: 600  loss: 1.711131883704144\nbt: 800  loss: 1.7106596905252207\nbt: 1000  loss: 0.9761501809825068\nbt: 1200  loss: 0.9747267184050187\nbt: 1400  loss: 0.811873311581819\nbt: 0  loss: 0.6222277516904084\nbt: 20  loss: 0.6596950862718665\nbt: 40  loss: 1.1852990026059358\nbt: 60  loss: 1.3563304569410242\nbt: 80  loss: 1.2049490057903787\nbt: 100  loss: 0.6382933492245881\nbt: 120  loss: 0.5817817190419072\nbt: 0  loss: 0.7376999233079993\nbt: 200  loss: 1.4047339066215183\nbt: 400  loss: 0.8530288364576257\nbt: 600  loss: 1.4096347974694294\nbt: 800  loss: 0.49260085562001105\nbt: 1000  loss: 0.44865840414296027\nbt: 1200  loss: 0.40660294242527173\nbt: 1400  loss: 0.48013823965321417\nbt: 0  loss: 1.1975672348685886\nbt: 20  loss: 0.31927459136299463\nbt: 40  loss: 0.2713200113047724\nbt: 60  loss: 1.2513302512790845\nbt: 80  loss: 0.36707940308944037\nbt: 100  loss: 0.2901872551959494\nbt: 120  loss: 0.29684680441151495\nbt: 0  loss: 0.40169338558031165\nbt: 200  loss: 1.524590533712636\nbt: 400  loss: 0.23002786221711533\nbt: 600  loss: 0.3192675839299741\nbt: 800  loss: 1.374259617017663\nbt: 1000  loss: 0.4713854582413383\nbt: 1200  loss: 1.3761559361996858\nbt: 1400  loss: 1.3535904262376868\nbt: 0  loss: 0.1607241319573444\nbt: 20  loss: 1.215111608090608\nbt: 40  loss: 1.1997973400613535\nbt: 60  loss: 1.15551990011464\nbt: 80  loss: 0.1846086253290591\nbt: 100  loss: 0.18162325154180112\nbt: 120  loss: 1.0273003785506538\nbt: 0  loss: 1.3100843014924421\nbt: 200  loss: 0.19603084481280783\nbt: 400  loss: 1.3242550725522249\nbt: 600  loss: 1.5171369469684104\nbt: 800  loss: 1.4539232668669329\nbt: 1000  loss: 1.6140718874724016\nbt: 1200  loss: 0.20825164214424466\nbt: 1400  loss: 1.393377221148947\nbt: 0  loss: 1.0977776568868887\nbt: 20  loss: 0.09459982747616975\nbt: 40  loss: 1.1027175239894702\nbt: 60  loss: 1.284767316735309\nbt: 80  loss: 1.173073146654212\nbt: 100  loss: 1.1331467835799507\nbt: 120  loss: 0.11790820826654849\nbt: 0  loss: 0.10839517220206883\nbt: 200  loss: 1.4261013528575068\nbt: 400  loss: 0.0938571950663691\nbt: 600  loss: 1.352579697318699\nbt: 800  loss: 0.07317876815795898\nbt: 1000  loss: 1.4022900125254756\nbt: 1200  loss: 1.372838310573412\nbt: 1400  loss: 1.5696266837742017\nbt: 0  loss: 1.185551353122877\nbt: 20  loss: 1.0977196900740913\nbt: 40  loss: 0.9677736862846043\nbt: 60  loss: 1.0705087910527769\nbt: 80  loss: 0.11832167791283649\nbt: 100  loss: 1.068946009096892\nbt: 120  loss: 1.1100874361784563\nbt: 0  loss: 1.4285117439601733\nbt: 200  loss: 0.1006554831629214\nbt: 400  loss: 0.08472623514092487\nbt: 600  loss: 1.4397427102793818\nbt: 800  loss: 1.4015652200450068\nbt: 1000  loss: 1.3445112808890964\nbt: 1200  loss: 1.5045690121858015\nbt: 1400  loss: 0.10486666015956712\nbt: 0  loss: 1.5362963469132134\nbt: 20  loss: 0.1127300677092179\nbt: 40  loss: 1.254596876061481\nbt: 60  loss: 1.1552634861158289\nbt: 80  loss: 1.3964024419369905\nbt: 100  loss: 1.3356248606806216\nbt: 120  loss: 0.1591363471487294\nbt: 0  loss: 0.16242817173833432\nbt: 200  loss: 0.06440028418665347\nbt: 400  loss: 1.4249919393788213\nbt: 600  loss: 1.5044776253078296\nbt: 800  loss: 1.733461628789487\nbt: 1000  loss: 1.5041318147078804\nbt: 1200  loss: 1.494253573210343\nbt: 1400  loss: 1.4405751435653023\nbt: 0  loss: 0.06774091202279796\nbt: 20  loss: 0.05755563404249108\nbt: 40  loss: 1.1489306740138843\nbt: 60  loss: 1.0959464363429858\nbt: 80  loss: 0.06425766841225002\nbt: 100  loss: 1.1382575657056726\nbt: 120  loss: 1.1304064211638079\nbt: 0  loss: 0.06095986262611721\nbt: 200  loss: 0.048571964968805725\nbt: 400  loss: 0.061028055522752846\nbt: 600  loss: 1.5221177806024966\nbt: 800  loss: 1.4822284864342732\nbt: 1000  loss: 0.06886925904647163\nbt: 1200  loss: 0.040441342022107994\nbt: 1400  loss: 0.06947043667668881\nbt: 0  loss: 0.0328140984410825\nbt: 20  loss: 1.0288792485776155\nbt: 40  loss: 0.03795561583145805\nbt: 60  loss: 0.04163090042445971\nbt: 80  loss: 0.052162191142206604\nbt: 100  loss: 0.030368250349293583\nbt: 120  loss: 0.04404352022253949\nbt: 0  loss: 1.3798312311587126\nbt: 200  loss: 1.2181975323220957\nbt: 400  loss: 1.3683412800664487\nbt: 600  loss: 0.08891792919324792\nbt: 800  loss: 1.4223029095193613\nbt: 1000  loss: 0.08961766699086064\nbt: 1200  loss: 0.05150349762128747\nbt: 1400  loss: 1.4653280506963315\nbt: 0  loss: 1.1204446709674338\nbt: 20  loss: 0.06234139463175898\nbt: 40  loss: 0.05934440053027609\nbt: 60  loss: 1.1111334095830503\nbt: 80  loss: 1.1580636397652004\nbt: 100  loss: 0.06889789519102676\nbt: 120  loss: 1.221978809522546\n{సెలవిచ్చాయి}}}}}}}}}}}   {సుర్కిిలున}}}}}}}}}}}}\n{ట్యూనర్లకు}}}}}}}}}}}}   {తెర్్ల}}}}}}}}}}}}}}}}\n{రుగ్మతతోపాటు}}}}}}}}}}   {రుత్తతత్త్్}}}}}}}}}}}\n{వెనుకాడుతూనే}}}}}}}}}}   {వెల్్కిత్ట్టున}}}}}}}}\n{తప్పించుకోవాల}}}}}}}}}   {తా్్రిిలినన}}}}}}}}}}}\n{త్రివేణిసంగమం}}}}}}}}}   {తిర్్రిిరినిన}}}}}}}}}\n{పోలిటన్}}}}}}}}}}}}}}}   {పెట్ట}}}}}}}}}}}}}}}}}\n{స్టైల్}}}}}}}}}}}}}}}}   {స్ట్్}}}}}}}}}}}}}}}}}\n{ఎదుర్కొన్నాడట}}}}}}}}}   {ఎక్్కి్త్త్త}}}}}}}}}}\n{గొడ్డలివేటు}}}}}}}}}}}   {గుల్్క్త్ట}}}}}}}}}}}}\n{తగలబెట్టేసేవారు}}}}}}}   {తా్్తతతతతతిన}}}}}}}}}}\n{జైనన్}}}}}}}}}}}}}}}}}   {జా్్ల}}}}}}}}}}}}}}}}}\n{మారుస్తున్నట్లయితే}}}}   {మా్తతతతతత్}}}}}}}}}}}}\n{సూచించించిన}}}}}}}}}}}   {సుర్కిిలునున}}}}}}}}}}\n{గ్రాఫిక్స్లను}}}}}}}}}   {గ్ర్్రిిర్నన}}}}}}}}}}\n{చండాలుడు}}}}}}}}}}}}}}   {చి్్లిల}}}}}}}}}}}}}}}\n{నడుస్తాడు}}}}}}}}}}}}}   {నా్్తత్}}}}}}}}}}}}}}}\n{హల్దా}}}}}}}}}}}}}}}}}   {జా్్ల}}}}}}}}}}}}}}}}}\n{తెలుసుకున్నవారు}}}}}}}   {తెల్్కిిలునున}}}}}}}}}\n{ఈతచెట్లను}}}}}}}}}}}}}   {ఎత్్తతత్త్్}}}}}}}}}}}\n{ఎదుర్కోబోతున్నాయని}}}}   {ఎక్్కి్త్త్టున}}}}}}}}\n{డోలోమిట్}}}}}}}}}}}}}}   {దొర్్త్}}}}}}}}}}}}}}}\n{కొడుకునూ}}}}}}}}}}}}}}   {కొర్్లిల}}}}}}}}}}}}}}\n{ప్రదేశములోనే}}}}}}}}}}   {ప్ర్్రిిరరనిన}}}}}}}}}\n{హైల్డ్}}}}}}}}}}}}}}}}   {లిర్ల}}}}}}}}}}}}}}}}}\n{నాశిరెడ్డి}}}}}}}}}}}}   {నా్్కిలి}}}}}}}}}}}}}}\n{పారట్టు}}}}}}}}}}}}}}}   {పట్్త}}}}}}}}}}}}}}}}}\n{తగ్గిపోతున్నాయనో}}}}}}   {తా్్తతతత్ని}}}}}}}}}}}\n{వెడెల్పుతో}}}}}}}}}}}}   {వెర్్క్త్త}}}}}}}}}}}}\n{వేగానర్}}}}}}}}}}}}}}}   {వెర్్ల}}}}}}}}}}}}}}}}\n{ఎక్కువనిపించినా}}}}}}}   {ఎక్్కిిలునున}}}}}}}}}}\n{స్వీకర్త}}}}}}}}}}}}}}   {స్ర్్త్్}}}}}}}}}}}}}}\nbt: 0  loss: 1.3704347195832625\nbt: 200  loss: 0.04630823757337487\nbt: 400  loss: 1.2759030383566152\nbt: 600  loss: 1.3528253306513247\nbt: 800  loss: 0.02300989109536876\nbt: 1000  loss: 0.05311420171157173\nbt: 1200  loss: 0.04754277415897535\nbt: 1400  loss: 1.6002961863642153\nbt: 0  loss: 0.0703987401464711\nbt: 20  loss: 0.0920825315558392\nbt: 40  loss: 1.383178296296493\nbt: 60  loss: 1.2858319489852241\nbt: 80  loss: 0.08063383724378503\nbt: 100  loss: 1.3708385799242102\nbt: 120  loss: 0.1343517718107804\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▂▃▆▆▆▇▇█</td></tr><tr><td>train_loss</td><td>█▄▂▂▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▃▅▄▆▇█▆▆</td></tr><tr><td>validation_loss</td><td>█▅▄▃▄▄▂▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>28.96094</td></tr><tr><td>train_loss</td><td>1428.3447</td></tr><tr><td>validation_accuracy</td><td>24.90234</td></tr><tr><td>validation_loss</td><td>101.23198</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/yfdfnuus</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_205517-yfdfnuus/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4zh4esf1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_210615-4zh4esf1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">sparkling-sweep-7</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:4zh4esf1) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sparkling-sweep-7</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_210615-4zh4esf1/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:4zh4esf1). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_210632-4zh4esf1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.160424273947011\nbt: 200  loss: 1.567598591680112\nbt: 400  loss: 1.5231688126273777\nbt: 600  loss: 1.3202317279318105\nbt: 800  loss: 1.108181911966075\nbt: 1000  loss: 1.6414892777152683\nbt: 1200  loss: 0.946263603542162\nbt: 1400  loss: 1.2285703576129416\nbt: 0  loss: 0.6587431949117909\nbt: 20  loss: 1.1004975360372793\nbt: 40  loss: 0.6145224778548531\nbt: 60  loss: 0.9484217270560886\nbt: 80  loss: 0.6069373669831649\nbt: 100  loss: 0.5390402752420177\nbt: 120  loss: 1.0839779066002888\nbt: 0  loss: 1.3114926711372707\nbt: 200  loss: 1.2983241703199304\nbt: 400  loss: 1.52697405607804\nbt: 600  loss: 0.5145955293074899\nbt: 800  loss: 1.443372975225034\nbt: 1000  loss: 1.4071917326554009\nbt: 1200  loss: 1.3278140192446501\nbt: 1400  loss: 0.30498048533564026\nbt: 0  loss: 0.1908861035886018\nbt: 20  loss: 1.0982128640879756\nbt: 40  loss: 1.0591297149658203\nbt: 60  loss: 1.1027018505594004\nbt: 80  loss: 1.0629179581351902\nbt: 100  loss: 0.2277050432951554\nbt: 120  loss: 0.1608653275862984\nbt: 0  loss: 0.2336631028548531\nbt: 200  loss: 1.2891183936077615\nbt: 400  loss: 1.4750304844068445\nbt: 600  loss: 0.10041401697241742\nbt: 800  loss: 0.16894165329311206\nbt: 1000  loss: 0.10110400034033734\nbt: 1200  loss: 1.2733313519021738\nbt: 1400  loss: 0.07292671825574792\nbt: 0  loss: 1.0128888669221296\nbt: 20  loss: 0.05962818083555802\nbt: 40  loss: 0.04823498103929603\nbt: 60  loss: 1.0425648896590523\nbt: 80  loss: 1.1297614056131113\nbt: 100  loss: 0.04593624239382536\nbt: 120  loss: 1.0907743702764097\nbt: 0  loss: 1.3899779941724695\nbt: 200  loss: 1.6622637873110564\nbt: 400  loss: 1.4415195299231487\nbt: 600  loss: 0.07915888143622357\nbt: 800  loss: 1.38402797864831\nbt: 1000  loss: 1.5420382955799932\nbt: 1200  loss: 0.04334676265716553\nbt: 1400  loss: 1.8307889855426291\nbt: 0  loss: 0.045464888862941574\nbt: 20  loss: 1.1784027763034985\nbt: 40  loss: 1.0868253293244734\nbt: 60  loss: 0.05995062641475512\nbt: 80  loss: 1.05297967661982\nbt: 100  loss: 1.0709470665973166\nbt: 120  loss: 1.2536692412003227\nbt: 0  loss: 1.633386694866678\nbt: 200  loss: 1.3763722129490064\nbt: 400  loss: 0.0302585130152495\nbt: 600  loss: 1.4980692656143852\nbt: 800  loss: 1.527966374936311\nbt: 1000  loss: 1.4006513512652854\nbt: 1200  loss: 1.157986765322478\nbt: 1400  loss: 0.04923415184020996\nbt: 0  loss: 1.0771376568338145\nbt: 20  loss: 0.9753837585449219\nbt: 40  loss: 1.1246206034784731\nbt: 60  loss: 0.05396493621494459\nbt: 80  loss: 1.1694602966308594\nbt: 100  loss: 0.023294179335884426\nbt: 120  loss: 1.0904260718304177\nbt: 0  loss: 1.3767664536185886\nbt: 200  loss: 0.04966219611789869\nbt: 400  loss: 0.026265719662541927\nbt: 600  loss: 1.4089083464249321\nbt: 800  loss: 0.03773297175117161\nbt: 1000  loss: 0.046652213386867356\nbt: 1200  loss: 1.4070668427840523\nbt: 1400  loss: 1.5361432614533796\nbt: 0  loss: 1.1468106145444124\nbt: 20  loss: 1.0906784223473591\nbt: 40  loss: 0.04917249990546185\nbt: 60  loss: 1.2318228846010955\nbt: 80  loss: 1.2117654551630435\nbt: 100  loss: 0.049913950588392174\nbt: 120  loss: 1.1640147333559783\nbt: 0  loss: 0.028974165087160858\nbt: 200  loss: 1.378524697345236\nbt: 400  loss: 0.016528263040210888\nbt: 600  loss: 1.613161335820737\nbt: 800  loss: 0.0808592464612878\nbt: 1000  loss: 1.501844489056131\nbt: 1200  loss: 0.014443882133649744\nbt: 1400  loss: 1.5876446599545686\nbt: 0  loss: 1.201416430266007\nbt: 20  loss: 1.178025535915209\nbt: 40  loss: 1.2029559923254924\nbt: 60  loss: 1.181092635444973\nbt: 80  loss: 0.03698887254880822\nbt: 100  loss: 1.0863189697265625\nbt: 120  loss: 1.098534293796705\nbt: 0  loss: 1.5654427901558254\nbt: 200  loss: 0.05258574693099312\nbt: 400  loss: 1.5816230773925781\nbt: 600  loss: 1.7175843612007473\nbt: 800  loss: 1.4564545672872793\nbt: 1000  loss: 0.009424592489781588\nbt: 1200  loss: 1.6607853433360225\nbt: 1400  loss: 1.6908368649690046\nbt: 0  loss: 0.019004378629767376\nbt: 20  loss: 0.04065868906352831\nbt: 40  loss: 1.1369272314983865\nbt: 60  loss: 0.0413078354752582\nbt: 80  loss: 1.0642046721085259\nbt: 100  loss: 0.02541740303454192\nbt: 120  loss: 0.029377102851867676\nbt: 0  loss: 1.592930503513502\nbt: 200  loss: 1.5905366980511209\nbt: 400  loss: 1.4750687972359036\nbt: 600  loss: 1.4192800107209578\nbt: 800  loss: 1.5170055886973506\nbt: 1000  loss: 1.2895344443943189\nbt: 1200  loss: 1.605650528617527\nbt: 1400  loss: 1.6506299557893171\nbt: 0  loss: 1.2365868609884512\nbt: 20  loss: 0.022581312967383343\nbt: 40  loss: 1.1036076753035835\nbt: 60  loss: 1.2674899723218835\nbt: 80  loss: 1.2370666835619055\nbt: 100  loss: 1.2032772561778193\nbt: 120  loss: 1.1874047984247622\nbt: 0  loss: 1.472640493641729\nbt: 200  loss: 0.02012421514676965\nbt: 400  loss: 0.021635392437810482\nbt: 600  loss: 1.5074141129203464\nbt: 800  loss: 1.4070250469705332\nbt: 1000  loss: 0.009706525698952053\nbt: 1200  loss: 0.008680243207060772\nbt: 1400  loss: 0.01020255296126656\nbt: 0  loss: 1.2882459889287534\nbt: 20  loss: 0.02030606503071992\nbt: 40  loss: 1.1952089226764182\nbt: 60  loss: 1.2498881298562754\nbt: 80  loss: 1.1573798967444378\nbt: 100  loss: 1.200309421705163\nbt: 120  loss: 1.14855782882027\nbt: 0  loss: 0.010968738276025524\nbt: 200  loss: 1.9174798053243887\nbt: 400  loss: 0.00897908988206283\nbt: 600  loss: 1.6728499039359714\nbt: 800  loss: 0.025056846763776695\nbt: 1000  loss: 0.029844960440760075\nbt: 1200  loss: 1.6684892073921536\nbt: 1400  loss: 1.475334996762483\nbt: 0  loss: 0.036034345626831055\nbt: 20  loss: 1.1938445879065471\nbt: 40  loss: 0.03342609561007956\nbt: 60  loss: 1.2130470275878906\nbt: 80  loss: 1.1226127458655315\nbt: 100  loss: 1.1982009721838909\nbt: 120  loss: 1.2154447306757388\nbt: 0  loss: 1.609096858812415\nbt: 200  loss: 0.03428147409273231\nbt: 400  loss: 1.3535919189453125\nbt: 600  loss: 1.5861937481424082\nbt: 800  loss: 1.6111186483631963\nbt: 1000  loss: 1.7429562444272249\nbt: 1200  loss: 0.022744170997453773\nbt: 1400  loss: 1.6435667950174082\nbt: 0  loss: 1.23559628362241\nbt: 20  loss: 1.3151060187298318\nbt: 40  loss: 1.2201806773310122\nbt: 60  loss: 1.2877057946246604\nbt: 80  loss: 1.3451169884723166\nbt: 100  loss: 0.01728110468905905\nbt: 120  loss: 1.2146765667459238\nbt: 0  loss: 1.456306789232337\nbt: 200  loss: 1.465827112612517\nbt: 400  loss: 1.3997243798297385\nbt: 600  loss: 1.4196916663128396\nbt: 800  loss: 0.03072791514189347\nbt: 1000  loss: 1.4464579043181047\nbt: 1200  loss: 1.697314220926036\nbt: 1400  loss: 1.5822299459706182\nbt: 0  loss: 1.2106683979863706\nbt: 20  loss: 0.02211033002189968\nbt: 40  loss: 0.02156132848366447\nbt: 60  loss: 0.029186904430389404\nbt: 80  loss: 1.1842595805292544\nbt: 100  loss: 1.2207473257313604\nbt: 120  loss: 0.016120888616727745\nbt: 0  loss: 0.010498456332994543\nbt: 200  loss: 1.7085926221764607\nbt: 400  loss: 1.4600810175356658\nbt: 600  loss: 0.02886748054753179\nbt: 800  loss: 1.6667691106381624\nbt: 1000  loss: 1.4020906531292459\nbt: 1200  loss: 1.5624810923700747\nbt: 1400  loss: 0.009756427096283955\nbt: 0  loss: 0.00972545211729796\nbt: 20  loss: 0.027608078459034794\nbt: 40  loss: 1.4043562515922214\nbt: 60  loss: 1.2055422741433848\nbt: 80  loss: 1.4208654320758323\nbt: 100  loss: 0.013810092988221542\nbt: 120  loss: 0.027811125568721607\nbt: 0  loss: 0.041573812132296356\nbt: 200  loss: 0.17314073313837466\nbt: 400  loss: 0.030843885048576023\nbt: 600  loss: 1.3711092575736668\nbt: 800  loss: 0.12689987472865893\nbt: 1000  loss: 1.5527765025263247\nbt: 1200  loss: 1.5159918743631113\nbt: 1400  loss: 1.5955926646356997\nbt: 0  loss: 0.0964126794234566\nbt: 20  loss: 0.0713214459626571\nbt: 40  loss: 1.0800393975299338\nbt: 60  loss: 0.0812378396158633\nbt: 80  loss: 1.3114407580831777\nbt: 100  loss: 1.2697681758714758\nbt: 120  loss: 1.2870114367941152\nbt: 0  loss: 1.6944729348887568\nbt: 200  loss: 1.5737342834472656\nbt: 400  loss: 1.4964843418287195\nbt: 600  loss: 1.4850523575492527\nbt: 800  loss: 1.4607573799465015\nbt: 1000  loss: 1.4884199059527854\nbt: 1200  loss: 0.014444002638692442\nbt: 1400  loss: 1.65802350251571\nbt: 0  loss: 1.1132932745892068\nbt: 20  loss: 1.1794848234757134\nbt: 40  loss: 1.1608625494915505\nbt: 60  loss: 0.016705056895380436\nbt: 80  loss: 1.2780898550282354\nbt: 100  loss: 0.0203611565672833\nbt: 120  loss: 0.03170844523803047\nbt: 0  loss: 0.009988751748333807\nbt: 200  loss: 1.488998910655146\nbt: 400  loss: 1.5909004211425781\nbt: 600  loss: 0.01708050266556118\nbt: 800  loss: 1.9152188508406929\nbt: 1000  loss: 1.564583156419837\nbt: 1200  loss: 1.5623681441597317\nbt: 1400  loss: 1.5498413417650305\nbt: 0  loss: 1.2966196640678074\nbt: 20  loss: 0.0730647729790729\nbt: 40  loss: 0.03829515498617421\nbt: 60  loss: 1.3131771916928499\nbt: 80  loss: 1.3716432322626528\nbt: 100  loss: 1.329812174258025\nbt: 120  loss: 0.06090526995451554\nbt: 0  loss: 0.06587970775106679\nbt: 200  loss: 0.06093618144159731\nbt: 400  loss: 1.507891447647758\nbt: 600  loss: 0.04347309599752012\nbt: 800  loss: 1.6633385368015454\nbt: 1000  loss: 0.020406694515891697\nbt: 1200  loss: 0.026672039342963177\nbt: 1400  loss: 1.4717717378035835\nbt: 0  loss: 0.029457745344742485\nbt: 20  loss: 0.02617868651514468\nbt: 40  loss: 1.302822444749915\nbt: 60  loss: 1.3342766139818274\nbt: 80  loss: 1.2688689024552056\nbt: 100  loss: 0.014549409565718277\nbt: 120  loss: 0.030138694721719494\nbt: 0  loss: 0.01688905513804892\nbt: 200  loss: 1.6450787419858186\nbt: 400  loss: 1.794686856477157\nbt: 600  loss: 1.6108143018639607\nbt: 800  loss: 0.042938748131627624\nbt: 1000  loss: 0.02923161568848983\nbt: 1200  loss: 1.539255722709324\nbt: 1400  loss: 1.5745653898819634\nbt: 0  loss: 1.3577777199123218\nbt: 20  loss: 0.026542464028234066\nbt: 40  loss: 0.016241007524987926\nbt: 60  loss: 1.289538342019786\nbt: 80  loss: 1.2795142298159392\nbt: 100  loss: 1.1474018926205842\nbt: 120  loss: 1.1635852482007898\n{డెవలప్పర్స్}}}}}}}}}}}   {దార్లు}}}}}}}}}}}}}}}}\n{పోత్తులపై}}}}}}}}}}}}}   {ప్ర్ల్}}}}}}}}}}}}}}}}\n{అపార్టుమెంట్లలోకి}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{నెలక}}}}}}}}}}}}}}}}}}   {నిర్ల్}}}}}}}}}}}}}}}}\n{తరుచుగావెళ్తూ}}}}}}}}}   {త్ర్ల్}}}}}}}}}}}}}}}}\n{అతీంద్రియము}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{మూడికి}}}}}}}}}}}}}}}}   {మెర్లు}}}}}}}}}}}}}}}}\n{అల్క్యూడియా}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{అంశమున}}}}}}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{అచిరకాలంలోనే}}}}}}}}}}   {అన్ర్్}}}}}}}}}}}}}}}}\n{గోడకట్టినట్టు}}}}}}}}}   {గ్ర్ల్}}}}}}}}}}}}}}}}\n{బుర్రుమని}}}}}}}}}}}}}   {బార్లు}}}}}}}}}}}}}}}}\n{ముచ్చటగొలిపింది}}}}}}}   {మెర్ల్}}}}}}}}}}}}}}}}\n{స్టోమ్}}}}}}}}}}}}}}}}   {స్ర్ల్}}}}}}}}}}}}}}}}\n{అలమందను}}}}}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{తోచింది}}}}}}}}}}}}}}}   {త్ర్ల్}}}}}}}}}}}}}}}}\n{విశ్వసిస్తోందని}}}}}}}   {విర్ల్}}}}}}}}}}}}}}}}\n{అయ్యవు}}}}}}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{కష్టాలపై}}}}}}}}}}}}}}   {క్ర్ల్}}}}}}}}}}}}}}}}\n{భ్యులంతా}}}}}}}}}}}}}}   {బ్ర్ల్}}}}}}}}}}}}}}}}\n{చిర్రాపూరి}}}}}}}}}}}}   {చెర్లు}}}}}}}}}}}}}}}}\n{డాలర్లన్నా}}}}}}}}}}}}   {ద్ర్ల్}}}}}}}}}}}}}}}}\n{కలిగించినట్టయ్యింది}}}   {క్ర్ల్}}}}}}}}}}}}}}}}\n{భోగలక్ష్మి}}}}}}}}}}}}   {బ్ర్లు}}}}}}}}}}}}}}}}\n{ఛాయాగ్రహణం}}}}}}}}}}}}   {చెర్లు}}}}}}}}}}}}}}}}\n{మింగేస్తాన్}}}}}}}}}}}   {మెర్ల్}}}}}}}}}}}}}}}}\n{స్టికర్లు}}}}}}}}}}}}}   {స్ర్ల్}}}}}}}}}}}}}}}}\n{పెట్టుకున్నాకనే}}}}}}}   {పార్ల్}}}}}}}}}}}}}}}}\n{జాగత్తలు}}}}}}}}}}}}}}   {జ్ర్ల్}}}}}}}}}}}}}}}}\n{కన్నందాస్}}}}}}}}}}}}}   {క్ర్ల్}}}}}}}}}}}}}}}}\n{అవన్నికూడా}}}}}}}}}}}}   {అన్రి్}}}}}}}}}}}}}}}}\n{చూచారో}}}}}}}}}}}}}}}}   {చెర్ల్}}}}}}}}}}}}}}}}\nbt: 0  loss: 1.4860473301099695\nbt: 200  loss: 1.7206142259680706\nbt: 400  loss: 1.5636482238769531\nbt: 600  loss: 1.785366390062415\nbt: 800  loss: 1.5816957224970278\nbt: 1000  loss: 1.49340936411982\nbt: 1200  loss: 1.8246814893639607\nbt: 1400  loss: 1.5334124357804009\nbt: 0  loss: 0.032584304394929306\nbt: 20  loss: 1.4128986856211787\nbt: 40  loss: 0.04897815766541854\nbt: 60  loss: 0.056242605914240296\nbt: 80  loss: 1.4296384065047554\nbt: 100  loss: 0.06359830109969429\nbt: 120  loss: 1.4342580048934273\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▄▅▇▇▇▇█▇█▇▇█▅▇▇▇▇█</td></tr><tr><td>train_loss</td><td>█▃▁▁▂▂▃▂▂▂▂▂▂▂▃▂▃▃▃▂</td></tr><tr><td>validation_accuracy</td><td>▁▂▅▆▆▆▆▇▆▆▇▆▆▇▅▇▅█▇▆</td></tr><tr><td>validation_loss</td><td>▆▂▃▃▂▂▄▁▅▅▁▅▄▅▃▃▇▂▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>37.03711</td></tr><tr><td>train_loss</td><td>1525.75755</td></tr><tr><td>validation_accuracy</td><td>27.90527</td></tr><tr><td>validation_loss</td><td>120.46994</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/4zh4esf1</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_210632-4zh4esf1/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w8taimxj with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_212747-w8taimxj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">valiant-sweep-8</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:w8taimxj) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">valiant-sweep-8</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_212747-w8taimxj/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:w8taimxj). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_212804-w8taimxj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">embedding32cellTypeRNNbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.194726031759511\nbt: 200  loss: 1.8319212872049082\nbt: 400  loss: 1.6024999203889265\nbt: 600  loss: 1.4853659920070483\nbt: 800  loss: 1.14294491643491\nbt: 1000  loss: 1.869881007982337\nbt: 1200  loss: 1.7415632164996604\nbt: 1400  loss: 1.7455243649690046\nbt: 0  loss: 1.7161420739215354\nbt: 20  loss: 1.5222668855086616\nbt: 40  loss: 1.5419256790824558\nbt: 60  loss: 1.554827482804008\nbt: 80  loss: 1.4996832142705503\nbt: 100  loss: 0.6550215430881666\nbt: 120  loss: 0.6535017179406207\nbt: 0  loss: 1.7913259423297385\nbt: 200  loss: 0.8512656170388927\nbt: 400  loss: 1.8094411103621773\nbt: 600  loss: 1.7212081577466882\nbt: 800  loss: 1.8654408662215523\nbt: 1000  loss: 1.7723098423170007\nbt: 1200  loss: 1.8460550722868547\nbt: 1400  loss: 1.819146197775136\nbt: 0  loss: 0.802468258401622\nbt: 20  loss: 0.83013916015625\nbt: 40  loss: 1.487105825672979\nbt: 60  loss: 1.6033723250679348\nbt: 80  loss: 1.40094342439071\nbt: 100  loss: 0.7193725420081097\nbt: 120  loss: 1.4344160660453464\nbt: 0  loss: 1.8641559766686482\nbt: 200  loss: 0.9626601675282354\nbt: 400  loss: 2.1187919948412026\nbt: 600  loss: 1.028203300807787\nbt: 800  loss: 1.9251251220703125\nbt: 1000  loss: 0.9417975052543308\nbt: 1200  loss: 1.8948707580566406\nbt: 1400  loss: 2.235932225766389\nbt: 0  loss: 0.6896103983340056\nbt: 20  loss: 0.7007476143215013\nbt: 40  loss: 1.5882788948390796\nbt: 60  loss: 1.4193377287491509\nbt: 80  loss: 1.4565630373747454\nbt: 100  loss: 0.6534855469413425\nbt: 120  loss: 0.652749434761379\nbt: 0  loss: 1.7906805950662363\nbt: 200  loss: 1.7566287828528362\nbt: 400  loss: 1.982387874437415\nbt: 600  loss: 2.135131006655486\nbt: 800  loss: 1.9517656409222146\nbt: 1000  loss: 1.826239710268767\nbt: 1200  loss: 2.110521399456522\nbt: 1400  loss: 1.9835470448369565\nbt: 0  loss: 1.5388248277747112\nbt: 20  loss: 1.6419324460236921\nbt: 40  loss: 1.599902111551036\nbt: 60  loss: 1.7104757557744565\nbt: 80  loss: 1.627357648766559\nbt: 100  loss: 1.5822141896123472\nbt: 120  loss: 1.555761254352072\nbt: 0  loss: 2.0769910397736924\nbt: 200  loss: 1.9955698096233865\nbt: 400  loss: 2.09721158898395\nbt: 600  loss: 1.8927461375360903\nbt: 800  loss: 1.761953768522843\nbt: 1000  loss: 1.7665559519892153\nbt: 1200  loss: 1.8793650088102922\nbt: 1400  loss: 2.04943731556768\nbt: 0  loss: 1.5897983053456182\nbt: 20  loss: 1.6917991638183594\nbt: 40  loss: 1.5378273673679517\nbt: 60  loss: 1.7852640566618547\nbt: 80  loss: 1.6380276887313179\nbt: 100  loss: 1.6139654076617698\nbt: 120  loss: 1.750678020974864\nbt: 0  loss: 1.9247438182001528\nbt: 200  loss: 2.1170204826023267\nbt: 400  loss: 1.998029791790506\nbt: 600  loss: 2.247794773267663\nbt: 800  loss: 2.105452827785326\nbt: 1000  loss: 2.181242901345958\nbt: 1200  loss: 1.9648709504500679\nbt: 1400  loss: 2.1071080746858017\nbt: 0  loss: 1.8870788242505945\nbt: 20  loss: 1.90600702036982\nbt: 40  loss: 1.9544626318890115\nbt: 60  loss: 1.8647966799528704\nbt: 80  loss: 1.7822127964185632\nbt: 100  loss: 1.940512118132218\nbt: 120  loss: 1.8296072586722996\nbt: 0  loss: 2.1622015911599863\nbt: 200  loss: 2.072548244310462\nbt: 400  loss: 2.0639182381007983\nbt: 600  loss: 2.216645448104195\nbt: 800  loss: 2.2414862591287363\nbt: 1000  loss: 2.0327969426694126\nbt: 1200  loss: 2.044406559156335\nbt: 1400  loss: 2.099783524222996\nbt: 0  loss: 1.7101369111434273\nbt: 20  loss: 1.767637004023013\nbt: 40  loss: 1.790697844132133\nbt: 60  loss: 1.60431256501571\nbt: 80  loss: 1.7830792302670686\nbt: 100  loss: 1.6503798443338145\nbt: 120  loss: 1.827110124670941\nbt: 0  loss: 2.2980638586956523\nbt: 200  loss: 2.311916848887568\nbt: 400  loss: 2.2444731670877207\nbt: 600  loss: 2.0220545893130093\nbt: 800  loss: 2.042885987654976\nbt: 1000  loss: 2.050407243811566\nbt: 1200  loss: 2.001738506814708\nbt: 1400  loss: 1.9392607315726902\nbt: 0  loss: 1.876435653023098\nbt: 20  loss: 1.7112040312393852\nbt: 40  loss: 1.6775753187096638\nbt: 60  loss: 1.770887457806131\nbt: 80  loss: 1.8779416291610054\nbt: 100  loss: 1.6656714729640796\nbt: 120  loss: 1.738069783086362\nbt: 0  loss: 2.0831189362899116\nbt: 200  loss: 2.2192396081012227\nbt: 400  loss: 2.0737596594769023\nbt: 600  loss: 2.1866546299146568\nbt: 800  loss: 2.1739042530889097\nbt: 1000  loss: 2.1553263456925102\nbt: 1200  loss: 2.0458425438922383\nbt: 1400  loss: 2.1448953048042627\nbt: 0  loss: 1.5997510163680366\nbt: 20  loss: 1.6577795277471128\nbt: 40  loss: 1.6321407815684443\nbt: 60  loss: 1.6203732697860054\nbt: 80  loss: 1.6940383911132812\nbt: 100  loss: 1.6285733761994734\nbt: 120  loss: 1.7690796230150305\nbt: 0  loss: 2.2123326840608017\nbt: 200  loss: 2.162580738896909\nbt: 400  loss: 2.1313242704971977\nbt: 600  loss: 1.988831893257473\nbt: 800  loss: 2.062235459037449\nbt: 1000  loss: 2.084412616232167\nbt: 1200  loss: 1.9854873988939368\nbt: 1400  loss: 2.143702797267748\nbt: 0  loss: 1.5313037374745244\nbt: 20  loss: 1.8985134622325068\nbt: 40  loss: 1.720362953517748\nbt: 60  loss: 1.8000879702360735\nbt: 80  loss: 1.645330346148947\nbt: 100  loss: 1.6635156714397927\nbt: 120  loss: 1.7701873779296875\nbt: 0  loss: 2.201812909997028\nbt: 200  loss: 2.173461748206097\nbt: 400  loss: 2.0545682492463486\nbt: 600  loss: 2.1243796970533286\nbt: 800  loss: 2.1279021553371265\nbt: 1000  loss: 2.155102439548658\nbt: 1200  loss: 2.210300113843835\nbt: 1400  loss: 2.1680846836255943\nbt: 0  loss: 1.6549860083538552\nbt: 20  loss: 1.7005336595618206\nbt: 40  loss: 1.5893231267514436\nbt: 60  loss: 1.6856152078379756\nbt: 80  loss: 1.5188266920006794\nbt: 100  loss: 1.723334270974864\nbt: 120  loss: 1.726317032523777\nbt: 0  loss: 2.1143342723017153\nbt: 200  loss: 1.9239642931067424\nbt: 400  loss: 2.3346179464588994\nbt: 600  loss: 2.220368260922639\nbt: 800  loss: 1.9588558362877888\nbt: 1000  loss: 1.9686451787533967\nbt: 1200  loss: 2.2372259057086445\nbt: 1400  loss: 1.9329120801842732\nbt: 0  loss: 1.8144468224566916\nbt: 20  loss: 1.6628658460534138\nbt: 40  loss: 1.6080338851265286\nbt: 60  loss: 1.7436307824176291\nbt: 80  loss: 1.698437898055367\nbt: 100  loss: 1.9022495435631794\nbt: 120  loss: 1.663497427235479\nbt: 0  loss: 2.079282180122707\nbt: 200  loss: 2.0349872423254927\nbt: 400  loss: 2.0859701737113623\nbt: 600  loss: 2.0416228252908457\nbt: 800  loss: 2.05951276032821\nbt: 1000  loss: 2.0663163558296533\nbt: 1200  loss: 2.0620215042777685\nbt: 1400  loss: 1.9413729128630266\nbt: 0  loss: 1.769160560939623\nbt: 20  loss: 1.686654629914657\nbt: 40  loss: 1.5992094952127207\nbt: 60  loss: 1.5765205051587976\nbt: 80  loss: 1.6206260349439539\nbt: 100  loss: 1.736662491508152\nbt: 120  loss: 1.6738697549571162\nbt: 0  loss: 1.9821435679560122\nbt: 200  loss: 2.247400532598081\nbt: 400  loss: 2.0247283603834068\nbt: 600  loss: 2.208399067754331\nbt: 800  loss: 2.219588735829229\nbt: 1000  loss: 1.900146484375\nbt: 1200  loss: 2.1125032176142153\nbt: 1400  loss: 2.0288291599439536\nbt: 0  loss: 1.7633514404296875\nbt: 20  loss: 1.804126905358356\nbt: 40  loss: 1.7731623442276665\nbt: 60  loss: 1.7491458395253057\nbt: 80  loss: 1.6344324194866677\nbt: 100  loss: 1.7584344615106997\nbt: 120  loss: 1.614983600118886\nbt: 0  loss: 2.0587864751401157\nbt: 200  loss: 2.165746274201766\nbt: 400  loss: 2.184887761655061\nbt: 600  loss: 2.0988154203995415\nbt: 800  loss: 2.0127457328464673\nbt: 1000  loss: 2.212021205736243\nbt: 1200  loss: 2.1014580104662026\nbt: 1400  loss: 2.0487720655358355\nbt: 0  loss: 1.63329845926036\nbt: 20  loss: 1.577017245085343\nbt: 40  loss: 1.7547678740128227\nbt: 60  loss: 1.640057771102242\nbt: 80  loss: 1.5486956057341204\nbt: 100  loss: 1.6791323786196501\nbt: 120  loss: 1.7446378624957541\nbt: 0  loss: 2.2386388364045517\nbt: 200  loss: 2.155923097029976\nbt: 400  loss: 2.2109756469726562\nbt: 600  loss: 1.9392093160878057\nbt: 800  loss: 2.161323713219684\nbt: 1000  loss: 2.0547039197838823\nbt: 1200  loss: 2.213046861731488\nbt: 1400  loss: 2.0596492601477583\nbt: 0  loss: 1.6502931014351223\nbt: 20  loss: 1.6073160586149797\nbt: 40  loss: 1.5809470466945483\nbt: 60  loss: 1.7107490871263586\nbt: 80  loss: 1.6977281985075579\nbt: 100  loss: 1.6954838296641475\nbt: 120  loss: 1.665220011835513\nbt: 0  loss: 2.152795708697775\nbt: 200  loss: 2.1834171129309614\nbt: 400  loss: 2.2307664622431216\nbt: 600  loss: 2.0642263992973\nbt: 800  loss: 2.048187421715778\nbt: 1000  loss: 2.1544813073199727\nbt: 1200  loss: 2.0181086996327275\nbt: 1400  loss: 2.0961804597274116\nbt: 0  loss: 1.6925022291100544\nbt: 20  loss: 1.694929371709409\nbt: 40  loss: 1.7222903707753057\nbt: 60  loss: 1.5781649713930876\nbt: 80  loss: 1.754387896993886\nbt: 100  loss: 1.5906469925590183\nbt: 120  loss: 1.69390172543733\nbt: 0  loss: 1.9824260214100713\nbt: 200  loss: 1.9065487073815388\nbt: 400  loss: 2.2527558699898096\nbt: 600  loss: 2.0137213002080503\nbt: 800  loss: 2.024254508640455\nbt: 1000  loss: 2.111759849216627\nbt: 1200  loss: 2.180209781812585\nbt: 1400  loss: 2.1242967688519023\nbt: 0  loss: 1.6666414012079653\nbt: 20  loss: 1.7850831073263418\nbt: 40  loss: 1.8252573427946672\nbt: 60  loss: 1.7256327090056047\nbt: 80  loss: 1.7433367190153704\nbt: 100  loss: 1.7363171784774116\nbt: 120  loss: 1.7070806752080503\nbt: 0  loss: 2.079118313996688\nbt: 200  loss: 2.135525247325068\nbt: 400  loss: 2.0255685889202617\nbt: 600  loss: 2.044531117314878\nbt: 800  loss: 2.1155241261357847\nbt: 1000  loss: 2.1232361171556557\nbt: 1200  loss: 2.1288483661154043\nbt: 1400  loss: 2.2511906831160835\nbt: 0  loss: 1.7597704348356829\nbt: 20  loss: 1.7512459132982336\nbt: 40  loss: 1.7675038213315217\nbt: 60  loss: 1.7161895088527515\nbt: 80  loss: 1.675926871921705\nbt: 100  loss: 1.7901601376740828\nbt: 120  loss: 1.7286385245945142\n{ఆరిలోవా}}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{జలవివాదాలు}}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{రావిబాబు}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{దృఢపడుతూ}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{దాటించకూడదు}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{డర్బర్}}}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{భద్రతనిస్తున్న}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{యువతీయువలకు}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{ఉంచడంతో}}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{త్రికాలాలకు}}}}}}}}}}}   {మ}}}}}}}}}}}}}}}}}}}}}\n{హబ్లాస్}}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{తెలిసినంతమాత్రాన}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{వెధవకబుర్లు}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{బుర్రగుజ్జులో}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{విపరీతములతో}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{నికోలాయెవ్నా}}}}}}}}}}   {మ}}}}}}}}}}}}}}}}}}}}}\n{నెట్టిందన్నారు}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{భావుకత్వమో}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{స్ఫూర్తినిస్తోందని}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{వెదచల్లితే}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{చావుకయినా}}}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{అటకేక్కించడం}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{పొక్రాన్}}}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{రెగ్యులేటరును}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{ఎన్బ్రెల్ను}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{సైక్లికల్}}}}}}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{కవులవుతారే}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{తెలుగోళ్లు}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{రుద్రప్రయాగలో}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{క్షేత్రస్దాయిలో}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\n{రెండెంటిపై}}}}}}}}}}}}   {ప}}}}}}}}}}}}}}}}}}}}}\n{స్కూళ్ళున్నాయి}}}}}}}}   {వ}}}}}}}}}}}}}}}}}}}}}\nbt: 0  loss: 2.160191245701002\nbt: 200  loss: 2.008788233217986\nbt: 400  loss: 2.0990243994671367\nbt: 600  loss: 2.1815266816512398\nbt: 800  loss: 2.134968964949898\nbt: 1000  loss: 2.0977978913680366\nbt: 1200  loss: 2.0397534577742866\nbt: 1400  loss: 2.073050291641899\nbt: 0  loss: 1.6128231546153193\nbt: 20  loss: 1.6350331513778023\nbt: 40  loss: 1.7714077493418818\nbt: 60  loss: 1.7531723354173743\nbt: 80  loss: 1.7422458814538044\nbt: 100  loss: 1.7106971740722656\nbt: 120  loss: 1.6164272142493206\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁█▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▃▁▁▅▆▇██████████████</td></tr><tr><td>validation_accuracy</td><td>▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>▂▁▁▅▆█▇▆▆▆▆▆▆▆▆▆▆▇▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>3382.86434</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>219.99753</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeRNNbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/w8taimxj</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_212804-w8taimxj/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n3dojbtf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_214929-n3dojbtf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">pleasant-sweep-9</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:n3dojbtf) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pleasant-sweep-9</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_214929-n3dojbtf/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:n3dojbtf). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_214946-n3dojbtf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.134094569994056\nbt: 200  loss: 1.7742102249808933\nbt: 400  loss: 1.6372421928074048\nbt: 600  loss: 1.6032754649286685\nbt: 800  loss: 1.5375255087147588\nbt: 1000  loss: 1.6208559119183084\nbt: 1200  loss: 1.4535958663277004\nbt: 1400  loss: 1.836615520974864\nbt: 0  loss: 1.258638216101605\nbt: 20  loss: 0.6894628275995669\nbt: 40  loss: 1.2358205214790676\nbt: 60  loss: 1.316437928572945\nbt: 80  loss: 0.6728105545043945\nbt: 100  loss: 1.3263343313465947\nbt: 120  loss: 1.3447898367176885\nbt: 0  loss: 0.9865788169529127\nbt: 200  loss: 0.9283925761347231\nbt: 400  loss: 1.644248630689538\nbt: 600  loss: 1.6305190376613452\nbt: 800  loss: 1.7642684604810632\nbt: 1000  loss: 0.6517395351244055\nbt: 1200  loss: 0.6928487031356149\nbt: 1400  loss: 0.6458216542782991\nbt: 0  loss: 1.2665260149085003\nbt: 20  loss: 1.2538838593856148\nbt: 40  loss: 1.194021059119183\nbt: 60  loss: 0.4441718225893767\nbt: 80  loss: 0.48420118248980976\nbt: 100  loss: 1.2200495678445566\nbt: 120  loss: 1.1832334269648013\nbt: 0  loss: 0.5971011286196501\nbt: 200  loss: 1.4950183370838994\nbt: 400  loss: 0.4439398724099864\nbt: 600  loss: 1.6701719864555027\nbt: 800  loss: 0.4333235284556513\nbt: 1000  loss: 0.4007236231928286\nbt: 1200  loss: 0.37920649155326513\nbt: 1400  loss: 1.6558924135954485\nbt: 0  loss: 0.20505229286525561\nbt: 20  loss: 0.23835292069808298\nbt: 40  loss: 1.151574010434358\nbt: 60  loss: 1.251336719678796\nbt: 80  loss: 0.22365306771319846\nbt: 100  loss: 0.21627096507860266\nbt: 120  loss: 1.2755408079727837\nbt: 0  loss: 0.3392248775648034\nbt: 200  loss: 0.3255728638690451\nbt: 400  loss: 0.3440083628115447\nbt: 600  loss: 1.661332835321841\nbt: 800  loss: 0.2782668030780295\nbt: 1000  loss: 1.743187945822011\nbt: 1200  loss: 1.6353373320206352\nbt: 1400  loss: 0.24555399106896442\nbt: 0  loss: 1.3589608565620754\nbt: 20  loss: 1.3738398344620415\nbt: 40  loss: 1.3275772592295771\nbt: 60  loss: 1.5014733024265454\nbt: 80  loss: 1.4287966852602751\nbt: 100  loss: 1.3223630656366763\nbt: 120  loss: 1.2028962840204653\nbt: 0  loss: 1.710508927055027\nbt: 200  loss: 0.2708786259526792\nbt: 400  loss: 1.5844811149265454\nbt: 600  loss: 1.7035086258597996\nbt: 800  loss: 0.21418787085491678\nbt: 1000  loss: 1.5524960393490999\nbt: 1200  loss: 1.6154889645783796\nbt: 1400  loss: 0.2064419000045113\nbt: 0  loss: 1.4109702732252039\nbt: 20  loss: 0.10525405925253163\nbt: 40  loss: 1.3908591063126274\nbt: 60  loss: 1.3597206447435461\nbt: 80  loss: 0.1316891960475756\nbt: 100  loss: 0.1391978056534477\nbt: 120  loss: 1.155496763146442\nbt: 0  loss: 1.6183892954950747\nbt: 200  loss: 1.7647879227347996\nbt: 400  loss: 1.8411793916121773\nbt: 600  loss: 0.1482906548873238\nbt: 800  loss: 0.12816145109093707\nbt: 1000  loss: 0.1351029043612273\nbt: 1200  loss: 0.14061608521834665\nbt: 1400  loss: 0.1333696220232093\nbt: 0  loss: 1.3775445689325747\nbt: 20  loss: 1.4012694980787195\nbt: 40  loss: 1.3658907517142918\nbt: 60  loss: 0.1645080213961394\nbt: 80  loss: 0.1526797232420548\nbt: 100  loss: 1.2295927794083306\nbt: 120  loss: 1.3838717419168223\nbt: 0  loss: 0.2169364016989003\nbt: 200  loss: 1.8208473868992017\nbt: 400  loss: 1.6782661106275476\nbt: 600  loss: 1.7023006936778193\nbt: 800  loss: 1.638450456702191\nbt: 1000  loss: 1.634716863217561\nbt: 1200  loss: 1.6874538919200068\nbt: 1400  loss: 1.6760811183763586\nbt: 0  loss: 1.4173701742421025\nbt: 20  loss: 0.053692662197610604\nbt: 40  loss: 0.0533856723619544\nbt: 60  loss: 1.141774965369183\nbt: 80  loss: 1.2729140571925952\nbt: 100  loss: 1.2472753110139265\nbt: 120  loss: 1.215582391490107\nbt: 0  loss: 1.7343799756920857\nbt: 200  loss: 1.7780847964079485\nbt: 400  loss: 1.701548203178074\nbt: 600  loss: 0.07848305287568466\nbt: 800  loss: 1.6410333384638247\nbt: 1000  loss: 0.09896485701851222\nbt: 1200  loss: 1.8301106328549592\nbt: 1400  loss: 1.6548412157141643\nbt: 0  loss: 1.3769982379415762\nbt: 20  loss: 1.3935075842815896\nbt: 40  loss: 1.4158371635105298\nbt: 60  loss: 0.07112602047298265\nbt: 80  loss: 0.06797295549641484\nbt: 100  loss: 0.04343081038931142\nbt: 120  loss: 0.06585443019866943\nbt: 0  loss: 1.6167554440705671\nbt: 200  loss: 1.5927799058997112\nbt: 400  loss: 0.08691352864970332\nbt: 600  loss: 1.8784184663192085\nbt: 800  loss: 0.1192742223324983\nbt: 1000  loss: 0.07890901358231255\nbt: 1200  loss: 1.9043249047320823\nbt: 1400  loss: 1.778295434039572\nbt: 0  loss: 1.2523755612580671\nbt: 20  loss: 1.3873047206712805\nbt: 40  loss: 0.04294385599053424\nbt: 60  loss: 1.2645104449728262\nbt: 80  loss: 1.2872144450312075\nbt: 100  loss: 0.038220027218694275\nbt: 120  loss: 1.4004536504330842\nbt: 0  loss: 1.9028237384298574\nbt: 200  loss: 0.08032863036445949\nbt: 400  loss: 1.9548739557680876\nbt: 600  loss: 0.05923865670743196\nbt: 800  loss: 1.5226800338081692\nbt: 1000  loss: 0.0618231141048929\nbt: 1200  loss: 0.04663153316663659\nbt: 1400  loss: 1.6554787677267324\nbt: 0  loss: 0.032162850317747696\nbt: 20  loss: 1.2689262058423914\nbt: 40  loss: 1.3400737928307576\nbt: 60  loss: 0.06843828636667003\nbt: 80  loss: 0.03831470012664795\nbt: 100  loss: 0.03599219736845597\nbt: 120  loss: 1.3055583290431811\nbt: 0  loss: 1.7907014929729959\nbt: 200  loss: 1.6904678344726562\nbt: 400  loss: 0.058172936024873154\nbt: 600  loss: 1.7119167162024456\nbt: 800  loss: 0.07320389540299126\nbt: 1000  loss: 0.1590423583984375\nbt: 1200  loss: 1.8428838978643003\nbt: 1400  loss: 1.9571027341096296\nbt: 0  loss: 1.245389689569888\nbt: 20  loss: 0.0482278647630111\nbt: 40  loss: 1.2675714078156843\nbt: 60  loss: 0.037892787352852196\nbt: 80  loss: 1.5236356984014097\nbt: 100  loss: 0.04764709265335747\nbt: 120  loss: 0.024579602739085323\nbt: 0  loss: 0.07233249104541281\nbt: 200  loss: 1.675638779349949\nbt: 400  loss: 1.6665609608525815\nbt: 600  loss: 0.08161307936129363\nbt: 800  loss: 1.7345924377441406\nbt: 1000  loss: 2.0605359284774116\nbt: 1200  loss: 0.06465548017750615\nbt: 1400  loss: 0.05195833807406218\nbt: 0  loss: 1.519419296928074\nbt: 20  loss: 0.0524188694746598\nbt: 40  loss: 1.2174598030422046\nbt: 60  loss: 0.03491683887398761\nbt: 80  loss: 1.2958497586457625\nbt: 100  loss: 1.3181688059931216\nbt: 120  loss: 0.04124588292577992\nbt: 0  loss: 1.8675948433254077\nbt: 200  loss: 1.776879186215608\nbt: 400  loss: 0.12771887364594833\nbt: 600  loss: 0.09674105436905571\nbt: 800  loss: 0.0490214669186136\nbt: 1000  loss: 1.6442612357761548\nbt: 1200  loss: 1.7243959178095278\nbt: 1400  loss: 1.8896364958389946\nbt: 0  loss: 1.5340934421705164\nbt: 20  loss: 1.236799903537916\nbt: 40  loss: 1.2212426558784817\nbt: 60  loss: 1.3133991075598674\nbt: 80  loss: 1.351768161939538\nbt: 100  loss: 1.3056289838707966\nbt: 120  loss: 1.5814059713612432\nbt: 0  loss: 1.851997541344684\nbt: 200  loss: 0.04658429000688636\nbt: 400  loss: 0.04836792531220809\nbt: 600  loss: 1.8076337731402854\nbt: 800  loss: 0.0464763589527296\nbt: 1000  loss: 1.9486588187839673\nbt: 1200  loss: 0.03654320602831633\nbt: 1400  loss: 1.754010241964589\nbt: 0  loss: 1.416545702063519\nbt: 20  loss: 1.5725273464037024\nbt: 40  loss: 1.4021634640900984\nbt: 60  loss: 1.428031755530316\nbt: 80  loss: 1.4923822154169497\nbt: 100  loss: 1.4572734003481658\nbt: 120  loss: 0.04060566943624745\nbt: 0  loss: 1.6142526709515115\nbt: 200  loss: 1.9090365534243376\nbt: 400  loss: 0.13332568044247833\nbt: 600  loss: 0.1256004623744799\nbt: 800  loss: 0.10783934593200684\nbt: 1000  loss: 1.699565721594769\nbt: 1200  loss: 0.12814477215642514\nbt: 1400  loss: 1.745893727178159\nbt: 0  loss: 0.1481504129326862\nbt: 20  loss: 0.11599702420442001\nbt: 40  loss: 0.1387951374053955\nbt: 60  loss: 0.12889119853144107\nbt: 80  loss: 1.420364877452021\nbt: 100  loss: 0.13190564901932425\nbt: 120  loss: 0.14369705448979916\nbt: 0  loss: 1.940203459366508\nbt: 200  loss: 1.859637384829314\nbt: 400  loss: 0.19339121942934784\nbt: 600  loss: 1.8525680873704993\nbt: 800  loss: 1.7492931200110393\nbt: 1000  loss: 1.820337378460428\nbt: 1200  loss: 1.9053399459175442\nbt: 1400  loss: 1.7715621616529382\nbt: 0  loss: 0.037779639596524445\nbt: 20  loss: 1.3240444349206013\nbt: 40  loss: 0.0938399770985479\nbt: 60  loss: 1.4107818603515625\nbt: 80  loss: 1.3565332993217136\nbt: 100  loss: 1.4974154596743376\nbt: 120  loss: 1.5771680085555366\nbt: 0  loss: 1.7853874538255774\nbt: 200  loss: 1.7222115889839504\nbt: 400  loss: 0.105487118596616\nbt: 600  loss: 1.7987247964610225\nbt: 800  loss: 1.7909819561502207\nbt: 1000  loss: 1.6699890468431555\nbt: 1200  loss: 1.7900140181831692\nbt: 1400  loss: 1.64214971791143\nbt: 0  loss: 1.4210161955460259\nbt: 20  loss: 0.012294366307880568\nbt: 40  loss: 1.4531313025433084\nbt: 60  loss: 0.0298559017803358\nbt: 80  loss: 1.5478152399477751\nbt: 100  loss: 1.433245783266814\nbt: 120  loss: 1.5326959361200747\nbt: 0  loss: 1.9700224503226902\nbt: 200  loss: 1.7756742394488791\nbt: 400  loss: 1.5725173950195312\nbt: 600  loss: 1.7229289179262908\nbt: 800  loss: 1.9265063741932744\nbt: 1000  loss: 0.10768492325492528\nbt: 1200  loss: 1.6171662703804348\nbt: 1400  loss: 1.7619237485139265\nbt: 0  loss: 0.045654561208642044\nbt: 20  loss: 1.4248255854067595\nbt: 40  loss: 1.4914907372516135\nbt: 60  loss: 1.5260555433190388\nbt: 80  loss: 1.5816879272460938\nbt: 100  loss: 1.3579878599747368\nbt: 120  loss: 1.4602105513862942\nbt: 0  loss: 1.9034685881241509\nbt: 200  loss: 0.07326029176297395\nbt: 400  loss: 1.6542444643766985\nbt: 600  loss: 0.09230292361715565\nbt: 800  loss: 1.5945837601371433\nbt: 1000  loss: 1.9333058232846467\nbt: 1200  loss: 1.8768662162449048\nbt: 1400  loss: 1.7670394234035327\nbt: 0  loss: 0.07701286543970523\nbt: 20  loss: 0.05790425383526346\nbt: 40  loss: 0.06627186484958815\nbt: 60  loss: 1.341627203899881\nbt: 80  loss: 0.05820112124733303\nbt: 100  loss: 1.2198390131411345\nbt: 120  loss: 0.0646583256514176\nbt: 0  loss: 0.09294756599094557\nbt: 200  loss: 1.683062346085258\nbt: 400  loss: 2.091063457986583\nbt: 600  loss: 1.8658710977305537\nbt: 800  loss: 1.7362461919369905\nbt: 1000  loss: 1.804444686226223\nbt: 1200  loss: 0.17952680587768555\nbt: 1400  loss: 1.7456711478855298\nbt: 0  loss: 1.4829693669858186\nbt: 20  loss: 0.059017881103183914\nbt: 40  loss: 1.5624719702679177\nbt: 60  loss: 1.3360405797543733\nbt: 80  loss: 1.5264897553817085\nbt: 100  loss: 1.3772603739862856\nbt: 120  loss: 1.4189605712890625\nbt: 0  loss: 1.7526497218919836\nbt: 200  loss: 1.8371500761612602\nbt: 400  loss: 1.6916089265242866\nbt: 600  loss: 1.7501948812733525\nbt: 800  loss: 1.9787478239639946\nbt: 1000  loss: 0.08307906855707584\nbt: 1200  loss: 1.9181677776834238\nbt: 1400  loss: 1.905408942181131\nbt: 0  loss: 0.06285231009773586\nbt: 20  loss: 2.143871307373047\nbt: 40  loss: 2.1332641269849693\nbt: 60  loss: 1.973855557649032\nbt: 80  loss: 0.08370898080908734\nbt: 100  loss: 0.05880983497785485\nbt: 120  loss: 2.050220821214759\nbt: 0  loss: 0.09251787351525348\nbt: 200  loss: 0.09522101153498111\nbt: 400  loss: 1.7560453000275984\nbt: 600  loss: 1.7580639383067256\nbt: 800  loss: 1.8884846231211787\nbt: 1000  loss: 0.06223777066106382\nbt: 1200  loss: 0.051546029422594154\nbt: 1400  loss: 1.7286328854768171\nbt: 0  loss: 0.026077944299449093\nbt: 20  loss: 0.03702017535334048\nbt: 40  loss: 0.02348558799080227\nbt: 60  loss: 1.3254630876624065\nbt: 80  loss: 1.4071860935377039\nbt: 100  loss: 1.4901424905528193\nbt: 120  loss: 0.019395942273347275\nbt: 0  loss: 1.8362906082816746\nbt: 200  loss: 0.04036900012389473\nbt: 400  loss: 1.8364247861115828\nbt: 600  loss: 1.8348053641941235\nbt: 800  loss: 1.8891734247622283\nbt: 1000  loss: 1.827936255413553\nbt: 1200  loss: 0.07071756279986838\nbt: 1400  loss: 0.07442364485367485\nbt: 0  loss: 0.07092540678770645\nbt: 20  loss: 0.07157860631528108\nbt: 40  loss: 1.3475680143936821\nbt: 60  loss: 1.5338038568911345\nbt: 80  loss: 1.4908762392790422\nbt: 100  loss: 1.4123598181683084\nbt: 120  loss: 1.5782838904339334\nbt: 0  loss: 0.08054519217947255\nbt: 200  loss: 0.051718888075455376\nbt: 400  loss: 1.8544301572053328\nbt: 600  loss: 0.06804333562436311\nbt: 800  loss: 1.733740930971892\nbt: 1000  loss: 1.7244148254394531\nbt: 1200  loss: 0.04733047796332318\nbt: 1400  loss: 0.039769050867661186\nbt: 0  loss: 0.023281265860018524\nbt: 20  loss: 0.030951165634652843\nbt: 40  loss: 1.54663434235946\nbt: 60  loss: 1.5841975004776665\nbt: 80  loss: 0.028727777626203453\nbt: 100  loss: 1.2383934518565303\nbt: 120  loss: 1.346125312473463\nbt: 0  loss: 1.9633742622707202\nbt: 200  loss: 2.07611664481785\nbt: 400  loss: 1.7030465499214504\nbt: 600  loss: 2.1523424231487773\nbt: 800  loss: 0.06653720917909042\nbt: 1000  loss: 1.8219694054645041\nbt: 1200  loss: 0.044678180114082665\nbt: 1400  loss: 0.07567983606587285\nbt: 0  loss: 0.021068846401960953\nbt: 20  loss: 1.4249090111773948\nbt: 40  loss: 0.018376095139462013\nbt: 60  loss: 1.4019986028256624\nbt: 80  loss: 1.504421565843665\nbt: 100  loss: 0.020207331232402637\nbt: 120  loss: 0.017379026050152985\nbt: 0  loss: 0.06834765102552331\nbt: 200  loss: 0.035692842110343605\nbt: 400  loss: 1.897564763608186\nbt: 600  loss: 1.6467072860054348\nbt: 800  loss: 1.7929344177246094\nbt: 1000  loss: 0.05886103277621062\nbt: 1200  loss: 0.074588594229325\nbt: 1400  loss: 0.06961022770923117\nbt: 0  loss: 1.5694153827169668\nbt: 20  loss: 0.012303129486415697\nbt: 40  loss: 0.02169776351555534\nbt: 60  loss: 0.010150225914042929\nbt: 80  loss: 0.0202404014442278\nbt: 100  loss: 1.3586511197297468\nbt: 120  loss: 1.4270210266113281\nbt: 0  loss: 1.9669206038765286\nbt: 200  loss: 1.6092952230702275\nbt: 400  loss: 1.7942985866380774\nbt: 600  loss: 1.8492653888204824\nbt: 800  loss: 1.6344632687775984\nbt: 1000  loss: 1.7311296877653704\nbt: 1200  loss: 1.8734769406525984\nbt: 1400  loss: 1.8953144239342732\nbt: 0  loss: 0.013657063245773315\nbt: 20  loss: 1.3896492667820142\nbt: 40  loss: 1.6236645242442256\nbt: 60  loss: 0.018314912267353222\nbt: 80  loss: 1.4209694240404211\nbt: 100  loss: 0.026636929615684177\nbt: 120  loss: 1.3643521847932234\nbt: 0  loss: 1.9310297758682915\nbt: 200  loss: 1.7581012559973674\nbt: 400  loss: 1.7325976827870244\nbt: 600  loss: 2.1865620820418648\nbt: 800  loss: 1.832816911780316\nbt: 1000  loss: 1.669119295866593\nbt: 1200  loss: 1.728305484937585\nbt: 1400  loss: 1.759671916132388\nbt: 0  loss: 1.449081918467646\nbt: 20  loss: 1.3845551532247793\nbt: 40  loss: 1.5308303833007812\nbt: 60  loss: 0.01107870366262353\nbt: 80  loss: 1.3816903985064963\nbt: 100  loss: 1.4465695256772249\nbt: 120  loss: 0.01690354813700137\nbt: 0  loss: 0.03461263749910438\nbt: 200  loss: 0.055782312932221786\nbt: 400  loss: 0.04507410526275635\nbt: 600  loss: 1.8853237317956013\nbt: 800  loss: 0.03713898036790931\nbt: 1000  loss: 0.03735529080681179\nbt: 1200  loss: 0.04093514577202175\nbt: 1400  loss: 1.77911609152089\nbt: 0  loss: 0.011398614748664524\nbt: 20  loss: 0.009648233004238295\nbt: 40  loss: 0.027276497820149296\nbt: 60  loss: 0.014490794876347418\nbt: 80  loss: 0.012551636799522068\nbt: 100  loss: 0.006702774244806041\nbt: 120  loss: 1.3501810820206352\n{వికల్పాలూ}}}}}}}}}}}}}   {సిస్ు}}}}}}}}}}}}}}}}}\n{కైకిలికి}}}}}}}}}}}}}}   {పా}్ి}}}}}}}}}}}}}}}}}\n{దేవీదత్తు}}}}}}}}}}}}}   {ఆా్ివి}}}}}}}}}}}}}}}}\n{వూపుకుంటుంటే}}}}}}}}}}   {కార్ససా}}}}}}}}}}}}}}}\n{మారాలిగా}}}}}}}}}}}}}}   {వా్ిుు}}}}}}}}}}}}}}}}\n{తీర్చిదద్దారు}}}}}}}}}   {బివ్్}}}}}}}}}}}}}}}}}\n{డెక్జాజోసిన్}}}}}}}}}}   {సిర}్్}}}}}}}}}}}}}}}}\n{గొడుగుపడుతున్నా}}}}}}}   {సి్్తు}}}}}}}}}}}}}}}}\n{మొదలుపెట్టేయగా}}}}}}}}   {సి్్}}}}}}}}}}}}}}}}}}\n{వస్తాడంటారా}}}}}}}}}}}   {సి}్స}}}}}}}}}}}}}}}}}\n{రాజేశ్వరరెడ్డికి}}}}}}   {పా్్సు}}}}}}}}}}}}}}}}\n{సూర్జీవాలా}}}}}}}}}}}}   {సాసాా}}}}}}}}}}}}}}}}}\n{ఆకర్షింపబడదు}}}}}}}}}}   {మిర}వస్}}}}}}}}}}}}}}}\n{భ్యమైన}}}}}}}}}}}}}}}}   {పార}్}}}}}}}}}}}}}}}}}\n{నివృత్తిచేయాల్సి}}}}}}   {కిసి}}}}}}}}}}}}}}}}}}\n{దించేశాడు}}}}}}}}}}}}}   {సాస్ి}}}}}}}}}}}}}}}}}\n{విప్పిందిలేదు}}}}}}}}}   {పి్ిిు}}}}}}}}}}}}}}}}\n{ఉండితీరాలంటున్నారు}}}}   {కా్కి}}}}}}}}}}}}}}}}}\n{పిలిచారట}}}}}}}}}}}}}}   {సాస్ి}}}}}}}}}}}}}}}}}\n{ప్రయాణించసాగింది}}}}}}   {సి్్ి}}}}}}}}}}}}}}}}}\n{బుద్ధిలతో}}}}}}}}}}}}}   {సా్్ి}}}}}}}}}}}}}}}}}\n{రాజ్యాంగమే}}}}}}}}}}}}   {సా}్ి}}}}}}}}}}}}}}}}}\n{భగవన్మయంగా}}}}}}}}}}}}   {సాాిత్}}}}}}}}}}}}}}}}\n{పెట్టేసుకున్నా}}}}}}}}   {పార్}ు}}}}}}}}}}}}}}}}\n{సర్వాత్ముడు}}}}}}}}}}}   {మారుస}}}}}}}}}}}}}}}}}\n{మాయాదర్పణం}}}}}}}}}}}}   {పసరస్ి}}}}}}}}}}}}}}}}\n{సమాచారాత్మకంగా}}}}}}}}   {తాస్్్}}}}}}}}}}}}}}}}\n{అంతరింద్రియాలకు}}}}}}}   {మా్్ిా}}}}}}}}}}}}}}}}\n{అత్మవిశ్వాసాన్ని}}}}}}   {సార్ిం}}}}}}}}}}}}}}}}\n{పునాదిలలో}}}}}}}}}}}}}   {సా్్ుా}}}}}}}}}}}}}}}}\n{భక్తుడిలోని}}}}}}}}}}}   {పిర్్}}}}}}}}}}}}}}}}}\n{మాబోటి}}}}}}}}}}}}}}}}   {సారా్}}}}}}}}}}}}}}}}}\nbt: 0  loss: 1.9581924106763757\nbt: 200  loss: 0.03806138816087142\nbt: 400  loss: 0.13421886900196905\nbt: 600  loss: 0.08674628838248875\nbt: 800  loss: 1.6976958565090015\nbt: 1000  loss: 2.1161585268766983\nbt: 1200  loss: 1.8130609263544497\nbt: 1400  loss: 1.8306866521420686\nbt: 0  loss: 1.5186271667480469\nbt: 20  loss: 1.4517638165017832\nbt: 40  loss: 1.521666153617527\nbt: 60  loss: 1.4557105354640796\nbt: 80  loss: 1.4990899459175442\nbt: 100  loss: 1.5234809543775476\nbt: 120  loss: 1.5170906730320142\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▂▂▄▆▆▆▆▆▆▆▇▄▆▇▇▅▅▆▆▇▇▇█▇█▇▆</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▂▁▂▁▁▁▁▂▃▂▂▂▂▂▂▂▁▂▂▁▂▂▃▂</td></tr><tr><td>validation_accuracy</td><td>▁▁▂▂▄▃▅▅▆▅▆▅▆█▄▇▇▇▆▅▆▇▆▇█▇▇███</td></tr><tr><td>validation_loss</td><td>█▃▂▃▁▅▂▃▂▃▃▄▂▁▂▃▄▃▃▅█▂▄▂▂▃▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>24.8125</td></tr><tr><td>train_loss</td><td>1835.0687</td></tr><tr><td>validation_accuracy</td><td>37.45117</td></tr><tr><td>validation_loss</td><td>112.5817</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/n3dojbtf</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_214946-n3dojbtf/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fhxj9l4v with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: no\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_222226-fhxj9l4v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">fluent-sweep-10</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:fhxj9l4v) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fluent-sweep-10</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_222226-fhxj9l4v/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:fhxj9l4v). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_222244-fhxj9l4v</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">embedding32cellTypeGRUbatchSize32</a></strong> to <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/sweeps/szetb869</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v</a>"},"metadata":{}},{"name":"stdout","text":"bt: 0  loss: 4.230383831521739\nbt: 200  loss: 1.8155243915060293\nbt: 400  loss: 1.6882574661918308\nbt: 600  loss: 1.9067445837933084\nbt: 800  loss: 1.7214713718580164\nbt: 1000  loss: 1.8272680199664573\nbt: 1200  loss: 1.6798770738684612\nbt: 1400  loss: 1.559990758481233\nbt: 0  loss: 1.4743002186650815\nbt: 20  loss: 1.3469985464344854\nbt: 40  loss: 1.201673590618631\nbt: 60  loss: 1.1767677638841711\nbt: 80  loss: 1.3478279113769531\nbt: 100  loss: 1.2965687461521314\nbt: 120  loss: 1.278730060743249\nbt: 0  loss: 1.6447405607804009\nbt: 200  loss: 1.5715463057808254\nbt: 400  loss: 1.727368396261464\nbt: 600  loss: 1.4546789086383323\nbt: 800  loss: 1.491669862166695\nbt: 1000  loss: 1.5522298398225203\nbt: 1200  loss: 1.5987699757451597\nbt: 1400  loss: 1.5656854380731997\nbt: 0  loss: 1.305498040240744\nbt: 20  loss: 1.1883277063784392\nbt: 40  loss: 1.2576819710109546\nbt: 60  loss: 1.2755326810090437\nbt: 80  loss: 1.08703090833581\nbt: 100  loss: 1.1662929369055706\nbt: 120  loss: 1.1947825058646824\nbt: 0  loss: 1.535776718803074\nbt: 200  loss: 1.4819578087848166\nbt: 400  loss: 1.5255465300186821\nbt: 600  loss: 1.520801710045856\nbt: 800  loss: 1.4967185310695483\nbt: 1000  loss: 1.55669933816661\nbt: 1200  loss: 1.7280840666397759\nbt: 1400  loss: 1.4963611105213994\nbt: 0  loss: 1.304651343304178\nbt: 20  loss: 1.354184855585513\nbt: 40  loss: 1.2251366325046704\nbt: 60  loss: 1.303557188614555\nbt: 80  loss: 1.1275944917098335\nbt: 100  loss: 1.1699227042820142\nbt: 120  loss: 1.1367338429326597\nbt: 0  loss: 1.4244920481806216\nbt: 200  loss: 1.576550691024117\nbt: 400  loss: 1.4713468136994734\nbt: 600  loss: 1.4798792963442595\nbt: 800  loss: 1.4183852154275645\nbt: 1000  loss: 1.5162582397460938\nbt: 1200  loss: 1.5832796511442766\nbt: 1400  loss: 1.4440495034922725\nbt: 0  loss: 1.1210697837497876\nbt: 20  loss: 1.2507157533065132\nbt: 40  loss: 1.0278721684994905\nbt: 60  loss: 1.2233463784922725\nbt: 80  loss: 1.2186528910761294\nbt: 100  loss: 1.3759267226509426\nbt: 120  loss: 1.1436182105022927\nbt: 0  loss: 1.5260706362516985\nbt: 200  loss: 1.473742609438689\nbt: 400  loss: 1.5611112843389097\nbt: 600  loss: 1.42723912778108\nbt: 800  loss: 1.4477532428243887\nbt: 1000  loss: 1.4698774918265964\nbt: 1200  loss: 1.435327612835428\nbt: 1400  loss: 1.5393557341202446\nbt: 0  loss: 1.0699832750403362\nbt: 20  loss: 1.205433472343113\nbt: 40  loss: 1.3169010825779126\nbt: 60  loss: 1.1939061206320059\nbt: 80  loss: 1.1154883011527683\nbt: 100  loss: 1.1443959941034731\nbt: 120  loss: 1.0832619874373726\nbt: 0  loss: 1.5027155668839165\nbt: 200  loss: 1.3448468083920686\nbt: 400  loss: 1.519316300101902\nbt: 600  loss: 1.5175704956054688\nbt: 800  loss: 1.3916395436162534\nbt: 1000  loss: 1.5334703196649966\nbt: 1200  loss: 1.5683883998704993\nbt: 1400  loss: 1.5440222698709238\nbt: 0  loss: 1.3097444617229959\nbt: 20  loss: 1.2568875188412874\nbt: 40  loss: 1.2049377275549846\nbt: 60  loss: 1.1904215605362602\nbt: 80  loss: 1.3068798728611157\nbt: 100  loss: 1.2088600656260615\nbt: 120  loss: 1.2633500306502632\nbt: 0  loss: 1.3787336764128313\nbt: 200  loss: 1.4475250244140625\nbt: 400  loss: 1.501182390295941\nbt: 600  loss: 1.503099192743716\nbt: 800  loss: 1.4879213416058084\nbt: 1000  loss: 1.5272140502929688\nbt: 1200  loss: 1.5286938211192256\nbt: 1400  loss: 1.6146386188009512\nbt: 0  loss: 1.0739736142365828\nbt: 20  loss: 1.1948548192563264\nbt: 40  loss: 1.2164501521898352\nbt: 60  loss: 1.348578577456267\nbt: 80  loss: 1.0121355471403704\nbt: 100  loss: 1.3150382663892664\nbt: 120  loss: 1.1556714099386465\nbt: 0  loss: 1.5584633868673574\nbt: 200  loss: 1.5324043605638586\nbt: 400  loss: 1.4772584334663723\nbt: 600  loss: 1.43676873911982\nbt: 800  loss: 1.4962965923806895\nbt: 1000  loss: 1.5391699749490488\nbt: 1200  loss: 1.5170880193295686\nbt: 1400  loss: 1.399816430133322\nbt: 0  loss: 1.1900034365446672\nbt: 20  loss: 1.1524192146632983\nbt: 40  loss: 1.1455929797628652\nbt: 60  loss: 1.230315581611965\nbt: 80  loss: 1.0856228704037874\nbt: 100  loss: 1.123588230298913\nbt: 120  loss: 1.0926570892333984\nbt: 0  loss: 1.2899855738100798\nbt: 200  loss: 1.4756149623704993\nbt: 400  loss: 1.3759430595066235\nbt: 600  loss: 1.3081615282141643\nbt: 800  loss: 1.4037684565005095\nbt: 1000  loss: 1.637687351392663\nbt: 1200  loss: 1.4381803429645041\nbt: 1400  loss: 1.3325614099917205\nbt: 0  loss: 1.1363222702689793\nbt: 20  loss: 1.005106552787449\nbt: 40  loss: 1.0496104696522588\nbt: 60  loss: 1.3068634530772334\nbt: 80  loss: 1.2443726581075918\nbt: 100  loss: 1.0665638135827107\nbt: 120  loss: 1.2732349064039148\nbt: 0  loss: 1.3624770952307659\nbt: 200  loss: 1.5166078650433084\nbt: 400  loss: 1.3759053271749746\nbt: 600  loss: 1.3907700414242952\nbt: 800  loss: 1.3649272089419158\nbt: 1000  loss: 1.317976661350416\nbt: 1200  loss: 1.4366057022758152\nbt: 1400  loss: 1.503359089726987\nbt: 0  loss: 1.2482874497123386\nbt: 20  loss: 1.0910411503003992\nbt: 40  loss: 1.1273645318072776\nbt: 60  loss: 1.1306265955385955\nbt: 80  loss: 1.1849463089652683\nbt: 100  loss: 1.094332570615022\nbt: 120  loss: 1.169773765232252\nbt: 0  loss: 1.343407506528108\nbt: 200  loss: 1.4523094840671704\nbt: 400  loss: 1.5273963264797046\nbt: 600  loss: 1.4805770542310632\nbt: 800  loss: 1.3240850697393003\nbt: 1000  loss: 1.6080811542013418\nbt: 1200  loss: 1.5387455484141475\nbt: 1400  loss: 1.4849279652471128\nbt: 0  loss: 1.2499095253322436\nbt: 20  loss: 1.0835818415102751\nbt: 40  loss: 1.1088228640349016\nbt: 60  loss: 1.14007510309634\nbt: 80  loss: 1.2703888105309529\nbt: 100  loss: 1.1619037959886633\nbt: 120  loss: 1.1157161878502888\nbt: 0  loss: 1.5002557505731997\nbt: 200  loss: 1.448030886442765\nbt: 400  loss: 1.4702029020889946\nbt: 600  loss: 1.3931377245032268\nbt: 800  loss: 1.4847461866295857\nbt: 1000  loss: 1.4933045428732168\nbt: 1200  loss: 1.5862695445185122\nbt: 1400  loss: 1.3419456481933594\nbt: 0  loss: 1.1095288318136465\nbt: 20  loss: 1.113926597263502\nbt: 40  loss: 1.1292338163956352\nbt: 60  loss: 1.2100783638332202\nbt: 80  loss: 1.174544044162916\nbt: 100  loss: 1.1990162393321162\nbt: 120  loss: 1.174556068752123\nbt: 0  loss: 1.3888442827307659\nbt: 200  loss: 1.3489400614862856\nbt: 400  loss: 1.3490265556003735\nbt: 600  loss: 1.3673699420431387\nbt: 800  loss: 1.4797005031419836\nbt: 1000  loss: 1.5310722019361414\nbt: 1200  loss: 1.4012562295664912\nbt: 1400  loss: 1.5327247951341711\nbt: 0  loss: 1.1062421384065046\nbt: 20  loss: 1.18078264982804\nbt: 40  loss: 1.242025790007218\nbt: 60  loss: 1.0647883207901665\nbt: 80  loss: 1.2525077488111414\nbt: 100  loss: 1.1432624485181726\nbt: 120  loss: 1.1541786193847656\nbt: 0  loss: 1.355549024498981\nbt: 200  loss: 1.7795758454695991\nbt: 400  loss: 1.5185546875\nbt: 600  loss: 1.5307501088018003\nbt: 800  loss: 1.4363418247388757\nbt: 1000  loss: 1.4109465557595957\nbt: 1200  loss: 1.5024107228154722\nbt: 1400  loss: 1.2976348711096721\nbt: 0  loss: 1.1588410087253735\nbt: 20  loss: 1.162886329319166\nbt: 40  loss: 1.259923852008322\nbt: 60  loss: 1.0738200312075408\nbt: 80  loss: 1.206527792889139\nbt: 100  loss: 1.138170574022376\nbt: 120  loss: 1.041475544805112\nbt: 0  loss: 1.4093045773713484\nbt: 200  loss: 1.3921009561289912\nbt: 400  loss: 1.384773586107337\nbt: 600  loss: 1.5091453220533289\nbt: 800  loss: 1.4693379609481148\nbt: 1000  loss: 1.185754444288171\nbt: 1200  loss: 1.5589121942934783\nbt: 1400  loss: 1.497191055961277\nbt: 0  loss: 1.1090969417406165\nbt: 20  loss: 1.0946044092592986\nbt: 40  loss: 1.2669120456861414\nbt: 60  loss: 1.1042127194611921\nbt: 80  loss: 1.1424127661663552\nbt: 100  loss: 1.0953203284222146\nbt: 120  loss: 1.1381778717041016\nbt: 0  loss: 1.4680658423382302\nbt: 200  loss: 1.545448634935462\nbt: 400  loss: 1.3586552661398184\nbt: 600  loss: 1.3636816273564878\nbt: 800  loss: 1.3288421630859375\nbt: 1000  loss: 1.501924929411515\nbt: 1200  loss: 1.5301339522652004\nbt: 1400  loss: 1.4412155151367188\nbt: 0  loss: 1.0396167920983357\nbt: 20  loss: 1.0906454998513926\nbt: 40  loss: 1.2014418892238452\nbt: 60  loss: 1.1823476708453635\nbt: 80  loss: 1.1107021829356318\nbt: 100  loss: 1.1142540807309358\nbt: 120  loss: 1.2417309802511465\nbt: 0  loss: 1.4303355009659477\nbt: 200  loss: 1.4794847239618716\nbt: 400  loss: 1.4193700707477073\nbt: 600  loss: 1.5557546200959578\nbt: 800  loss: 1.4980798804241677\nbt: 1000  loss: 1.2990554312001104\nbt: 1200  loss: 1.452910050101902\nbt: 1400  loss: 1.497454601785411\nbt: 0  loss: 1.0324775861657185\nbt: 20  loss: 1.1057518668796704\nbt: 40  loss: 1.0062954114831013\nbt: 60  loss: 1.1027293827222742\nbt: 80  loss: 1.015485431836999\nbt: 100  loss: 1.1962117734162703\nbt: 120  loss: 1.0618811068327532\nbt: 0  loss: 1.4457253165867017\nbt: 200  loss: 1.474921185037364\nbt: 400  loss: 1.426174495531165\nbt: 600  loss: 1.321196348770805\nbt: 800  loss: 1.3940469493036685\nbt: 1000  loss: 1.5018494647482168\nbt: 1200  loss: 1.5135290726371433\nbt: 1400  loss: 1.4143635293711787\nbt: 0  loss: 1.3126236459483271\nbt: 20  loss: 1.1987982210905657\nbt: 40  loss: 1.1465563566788384\nbt: 60  loss: 1.2094238115393596\nbt: 80  loss: 1.1115924171779468\nbt: 100  loss: 1.1179122095522673\nbt: 120  loss: 1.1961026399031929\nbt: 0  loss: 1.5300190137780232\nbt: 200  loss: 1.3357994245446247\nbt: 400  loss: 1.5602023912512737\nbt: 600  loss: 1.5590170155400815\nbt: 800  loss: 1.3913164553434954\nbt: 1000  loss: 1.51471295564071\nbt: 1200  loss: 1.2702782672384512\nbt: 1400  loss: 1.276961782704229\nbt: 0  loss: 1.096122990483823\nbt: 20  loss: 1.1780144235362178\nbt: 40  loss: 1.2315391042958135\nbt: 60  loss: 1.016542683476987\nbt: 80  loss: 1.10656796330991\nbt: 100  loss: 1.1413803100585938\nbt: 120  loss: 1.1807813229768171\n{కొండప్రదేశం}}}}}}}}}}}   {పెర్ుుుునన}}}}}}}}}}}}\n{సంగులోయ}}}}}}}}}}}}}}}   {పెర్ుు్న}}}}}}}}}}}}}}\n{ఆమోదిస్తున్నాం}}}}}}}}   {ని్్ిుుుునన}}}}}}}}}}}\n{వెళ్లుతారని}}}}}}}}}}}   {వి్్ా్ానన}}}}}}}}}}}}}\n{వెళ్లాలనుకున్నపుడు}}}}   {వి్్ిిుుుుుుును}}}}}}}\n{పరిస్థితిలా}}}}}}}}}}}   {పాి్ిు్ననన}}}}}}}}}}}}\n{ముయల్}}}}}}}}}}}}}}}}}   {ఇా్ా}}}}}}}}}}}}}}}}}}\n{విగ్రహములు}}}}}}}}}}}}   {వి్్ా్ాలు}}}}}}}}}}}}}\n{బయటపడిపోతూనే}}}}}}}}}}   {ని్ిిుుునను}}}}}}}}}}}\n{స్పందనలపై}}}}}}}}}}}}}   {పెర్ుుుుుు}}}}}}}}}}}}\n{నిలబెట్టినప్పటికీ}}}}}   {ని్్ిి్్్ననననన}}}}}}}}\n{స్థితిస్థాపకతని}}}}}}}   {ప్రిిిి్్నననన}}}}}}}}}\n{విప్పబోతూ}}}}}}}}}}}}}   {వి్్్్్్}}}}}}}}}}}}}}\n{బట్టలుకు}}}}}}}}}}}}}}   {పెర్ుుుు}}}}}}}}}}}}}}\n{రాజకీయపార్టీలైన}}}}}}}   {ప్ర్ిిిి్నననన}}}}}}}}}\n{పత్రీకారం}}}}}}}}}}}}}   {పెర్ుుునన}}}}}}}}}}}}}\n{వర్తిస్తుంటుంది}}}}}}}   {వి్్ిుుుుుుననన}}}}}}}}\n{పేర్చిన}}}}}}}}}}}}}}}   {కెర్ిి}}}}}}}}}}}}}}}}\n{గర్వంలేదు}}}}}}}}}}}}}   {పాిిిుుుు}}}}}}}}}}}}}\n{ఫ్లూటుగా}}}}}}}}}}}}}}   {పెర్ుున}}}}}}}}}}}}}}}\n{బోనేసి}}}}}}}}}}}}}}}}   {బారా}}}}}}}}}}}}}}}}}}\n{తులసమ్మక్కా}}}}}}}}}}}   {పెర్ిిాన}}}}}}}}}}}}}}\n{ఒల్బియా}}}}}}}}}}}}}}}   {కారిిి}}}}}}}}}}}}}}}}\n{ప్రమాదాలనుండి}}}}}}}}}   {పెరిిిిునని}}}}}}}}}}}\n{నివారితులకు}}}}}}}}}}}   {ని్్ిు్నను}}}}}}}}}}}}\n{డెన్సిటైజేషన్}}}}}}}}}   {పెర్ిిిునని}}}}}}}}}}}\n{మనస్సువిప్పి}}}}}}}}}}   {వి్్ాు్్ననన}}}}}}}}}}}\n{కలుస్తాయో}}}}}}}}}}}}}   {పెర్ాిు}}}}}}}}}}}}}}}\n{కళ్యాణోత్సవాన్ని}}}}}}   {పాి్ిు్్్ననననన}}}}}}}}\n{మహావిశాఖలో}}}}}}}}}}}}   {వి్్ా్ాను}}}}}}}}}}}}}\n{తీసుకురాగలుగుతుంది}}}}   {పెర్ుుుుుుుుననన}}}}}}}\n{జ్యుడీషియరీ}}}}}}}}}}}   {పెరిిిిన}}}}}}}}}}}}}}\nbt: 0  loss: 1.5064695607060972\nbt: 200  loss: 1.496005680250085\nbt: 400  loss: 1.4374281841775645\nbt: 600  loss: 1.4402485723080842\nbt: 800  loss: 1.436158553413723\nbt: 1000  loss: 1.4071967083474863\nbt: 1200  loss: 1.3740229399307915\nbt: 1400  loss: 1.428662341573964\nbt: 0  loss: 1.1520383254341457\nbt: 20  loss: 1.2218162702477497\nbt: 40  loss: 1.1969162484873896\nbt: 60  loss: 1.0451020779817\nbt: 80  loss: 1.1434380075205928\nbt: 100  loss: 1.1373467652694038\nbt: 120  loss: 1.2098303255827532\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▁█▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_loss</td><td>█▆▆▃▃▄▄▃▂▂▂▃▂▁▁▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.0</td></tr><tr><td>train_loss</td><td>2282.04487</td></tr><tr><td>validation_accuracy</td><td>0.0</td></tr><tr><td>validation_loss</td><td>147.09849</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">embedding32cellTypeGRUbatchSize32</strong> at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3/runs/fhxj9l4v</a><br/> View project at: <a href='https://wandb.ai/cs23m021/DL_Assignment_3' target=\"_blank\">https://wandb.ai/cs23m021/DL_Assignment_3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_222244-fhxj9l4v/logs</code>"},"metadata":{}},{"name":"stdout","text":"Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x786fb4e12020>> (for post_run_cell), with arguments args (<ExecutionResult object at 786e9c055330, execution_count=19 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 786e9c055540, raw_cell=\"def main_fun():\n    wandb.init(project ='DL_Assign..\" store_history=True silent=False shell_futures=True cell_id=cded4911-8367-4039-b941-4183d7ae7c6a> result=None>,),kwargs {}:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:433\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:682\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}