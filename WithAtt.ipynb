{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8273608,"sourceType":"datasetVersion","datasetId":4912633},{"sourceId":8400322,"sourceType":"datasetVersion","datasetId":4998024}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T10:39:53.551647Z","iopub.execute_input":"2024-05-16T10:39:53.552339Z","iopub.status.idle":"2024-05-16T10:39:55.612974Z","shell.execute_reply.started":"2024-05-16T10:39:53.552307Z","shell.execute_reply":"2024-05-16T10:39:55.612172Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install wandb\nimport wandb\nfrom wandb.keras import WandbCallback\nwandb.login()\nwandb.init(project ='DL_Assignment_3')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:39:55.614668Z","iopub.execute_input":"2024-05-16T10:39:55.615149Z","iopub.status.idle":"2024-05-16T10:40:30.122343Z","shell.execute_reply.started":"2024-05-16T10:39:55.615115Z","shell.execute_reply":"2024-05-16T10:40:30.121227Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"2024-05-16 10:40:08.634164: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-16 10:40:08.634227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-16 10:40:08.635822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m066\u001b[0m (\u001b[33mdlassignment\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_104013-e7o5cpdv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/AttentionRNN/runs/e7o5cpdv' target=\"_blank\">legendary-star-49</a></strong> to <a href='https://wandb.ai/dlassignment/AttentionRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/AttentionRNN' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/AttentionRNN/runs/e7o5cpdv' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN/runs/e7o5cpdv</a>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dlassignment/AttentionRNN/runs/e7o5cpdv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7d1e124464d0>"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:40:32.177422Z","iopub.execute_input":"2024-05-16T10:40:32.177804Z","iopub.status.idle":"2024-05-16T10:40:32.185698Z","shell.execute_reply.started":"2024-05-16T10:40:32.177771Z","shell.execute_reply":"2024-05-16T10:40:32.184394Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_csv = \"/kaggle/input/telugu/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/telugu/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/telugu/tel/tel_valid.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:18.014769Z","iopub.execute_input":"2024-05-16T10:41:18.015142Z","iopub.status.idle":"2024-05-16T10:41:18.021379Z","shell.execute_reply.started":"2024-05-16T10:41:18.015105Z","shell.execute_reply":"2024-05-16T10:41:18.020042Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(train_csv, header=None)\ntrain_input = train_data[0].to_numpy()\ntrain_output = train_data[1].to_numpy()\nval_data = pd.read_csv(val_csv,header = None)\nval_input = val_data[0].to_numpy()\nval_output = val_data[1].to_numpy()\ntest_data = pd.read_csv(test_csv,header= None)\ntest_input = test_data[0].to_numpy()\ntest_output = test_data[1].to_numpy()\nprint(len(train_input))\nprint(len(train_output))\nprint(len(val_input))\nprint(len(test_data))\nprint(val_input)\nprint(val_output)\nprint(test_input)\nprint(test_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:19.452975Z","iopub.execute_input":"2024-05-16T10:41:19.454037Z","iopub.status.idle":"2024-05-16T10:41:19.576369Z","shell.execute_reply.started":"2024-05-16T10:41:19.453980Z","shell.execute_reply":"2024-05-16T10:41:19.575170Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"51200\n51200\n4096\n4096\n['bheeshmudini' 'vinyasaanni' 'kaavachhunu' ... 'asramam' 'divine' 'dis']\n['భీష్ముడిని' 'విన్యాసాన్ని' 'కావచ్చును' ... 'ఆశ్రమం' 'డివైన్' 'డిస్']\n['vithananni' 'prayaanikulu' 'hassan' ... 'telamgaanha' 'patel' 'peda']\n['విత్తనాన్ని' 'ప్రయాణికులు' 'హసన్' ... 'తెలంగాణ' 'పటేల్' 'పేడ']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_output[0][5]) #the size of input and output is 4096\nmaxi = 0\nt =''\nfor x in val_input:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\nt =''\nmaxi =0 \nfor x in val_output:\n    maxi = max(maxi,len(x))\n    if(maxi == len(x)):\n        t=x\n        \nprint(maxi,t)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef pre_processing(train_input,train_output):\n    data = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(train_input),30, dtype=torch.int, device=device),\n    \"source_data\" : train_input,\n        \n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(train_output),23, dtype=torch.int, device=device),\n    \"target_data\" : train_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    for i in range(0,len(train_input)):\n        train_input[i] = \"{\" + train_input[i] + \"}\"*(29-len(train_input[i]))\n        charToNum = []\n        for char in (train_input[i]):\n            index = 0\n            if(char not in data[\"all_characters\"]):\n                data[\"all_characters\"].append(char)\n                index = data[\"all_characters\"].index(char)\n                data[\"char_num_map\"][char] = index\n                data[\"num_char_map\"][index] = char\n            else:\n                index = data[\"all_characters\"].index(char)\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        \n        train_output[i] = \"{\" + train_output[i] + \"}\"*(22-len(train_output[i]))\n        for char in (train_output[i]):\n            index = 0\n            if(char not in data[\"all_characters_2\"]):\n                data[\"all_characters_2\"].append(char)\n                index = data[\"all_characters_2\"].index(char)\n                data[\"char_num_map_2\"][char] = index\n                data[\"num_char_map_2\"][index] = char\n            else:\n                index = data[\"all_characters_2\"].index(char)\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data[\"source_len\"] = len(data[\"all_characters\"])\n    data[\"target_len\"] = len(data[\"all_characters_2\"])\n        \n    return data\n    \n    \ndata = pre_processing(copy.copy(train_input),copy.copy(train_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data[\"source_charToNum\"])\nprint(data['val_charToNum'])\nprint(data[\"num_char_map_2\"])\nprint(data[\"num_char_map\"])\nprint(train_input[0])\nprint(data['source_len'])\nprint(data['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:23.571240Z","iopub.execute_input":"2024-05-16T10:41:23.571620Z","iopub.status.idle":"2024-05-16T10:41:31.137240Z","shell.execute_reply.started":"2024-05-16T10:41:23.571590Z","shell.execute_reply":"2024-05-16T10:41:31.136280Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"tensor([[ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0,  1,  2,  ...,  9,  9,  9],\n        [ 0, 13,  2,  ...,  9,  9,  9],\n        ...,\n        [ 0,  1,  8,  ...,  9,  9,  9],\n        [ 0,  3, 16,  ...,  9,  9,  9],\n        [ 0, 14, 20,  ...,  9,  9,  9]], device='cuda:0', dtype=torch.int32)\ntensor([[ 0,  1,  2,  ..., 10, 10, 10],\n        [ 0,  1, 11,  ..., 10, 10, 10],\n        [ 0, 14,  3,  ..., 10, 10, 10],\n        ...,\n        [ 0,  1, 25,  ..., 10, 10, 10],\n        [ 0,  2, 20,  ..., 10, 10, 10],\n        [ 0, 27, 25,  ..., 10, 10, 10]], device='cuda:0', dtype=torch.int32)\n{0: '{', 1: 'వ', 2: 'ర', 3: '్', 4: 'గ', 5: 'ా', 6: 'ల', 7: 'ి', 8: 'న', 9: 'ే', 10: '}', 11: 'స', 12: 'త', 13: 'ద', 14: 'ఫ', 15: 'య', 16: 'క', 17: 'ట', 18: 'మ', 19: 'ో', 20: 'ూ', 21: 'ళ', 22: 'ప', 23: 'ధ', 24: 'ు', 25: 'ె', 26: 'ం', 27: 'చ', 28: 'ై', 29: 'డ', 30: 'ఖ', 31: 'ఉ', 32: 'ష', 33: 'ఆ', 34: 'ొ', 35: 'శ', 36: 'అ', 37: 'భ', 38: 'ృ', 39: 'ణ', 40: 'హ', 41: 'జ', 42: 'ీ', 43: 'ఇ', 44: 'బ', 45: 'ఐ', 46: 'ఒ', 47: 'ఎ', 48: 'ౌ', 49: 'థ', 50: 'ఈ', 51: 'ఊ', 52: 'ఏ', 53: 'ఢ', 54: 'ఓ', 55: 'ఔ', 56: 'ఞ', 57: 'ఠ', 58: 'ఘ', 59: 'ఛ', 60: 'ః', 61: 'ఝ', 62: 'ఋ', 63: 'ఱ'}\n{0: '{', 1: 'v', 2: 'a', 3: 'r', 4: 'g', 5: 'l', 6: 'i', 7: 'n', 8: 'e', 9: '}', 10: 's', 11: 't', 12: 'd', 13: 'f', 14: 'c', 15: 'm', 16: 'o', 17: 'u', 18: 'w', 19: 'p', 20: 'h', 21: 'k', 22: 'y', 23: 'b', 24: 'j', 25: 'z', 26: 'x', 27: 'q'}\nvargaalavaarine\n28\n64\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef pre_processing_validation(val_input,val_output):\n    data2 = {\n    \"all_characters\" : [],\n    \"char_num_map\" : {},\n    \"num_char_map\" : {},\n    \"source_charToNum\": torch.zeros(len(val_input),30, dtype=torch.int, device=device),\n    \"source_data\" : val_input,\n    \"all_characters_2\" : [],\n    \"char_num_map_2\" : {},\n    \"num_char_map_2\" : {},\n    \"val_charToNum\": torch.zeros(len(val_output),23, dtype=torch.int, device=device),\n    \"target_data\" : val_output,\n    \"source_len\" : 0,\n    \"target_len\" : 0\n }\n    k = 0 \n    l = 0\n    \n    m1 = data[\"char_num_map\"]\n    m2 = data[\"char_num_map_2\"]\n    \n    for i in range(0,len(val_input)):\n        val_input[i] = \"{\" + val_input[i] + \"}\"*(29-len(val_input[i]))\n        charToNum = []\n        for char in (val_input[i]):\n            index = 0\n            if(char not in data2[\"all_characters\"]):\n                data2[\"all_characters\"].append(char)\n                index = m1[char]\n                data2[\"char_num_map\"][char] = index\n                data2[\"num_char_map\"][index] = char\n            else:\n                index = m1[char]\n            \n            charToNum.append(index)\n            \n        my_tensor = torch.tensor(charToNum,device = device)\n        data2[\"source_charToNum\"][k] = my_tensor\n        \n        charToNum1 = []\n        val_output[i] = \"{\" + val_output[i] + \"}\"*(22-len(val_output[i]))\n        for char in (val_output[i]):\n            index = 0\n            if(char not in data2[\"all_characters_2\"]):\n                data2[\"all_characters_2\"].append(char)\n                index = m2[char]\n                data2[\"char_num_map_2\"][char] = index\n                data2[\"num_char_map_2\"][index] = char\n            else:\n                index = m2[char]\n                \n            charToNum1.append(index)\n            \n        my_tensor1 = torch.tensor(charToNum1,device = device)\n        data2[\"val_charToNum\"][k] = my_tensor1\n        \n        k+=1\n    \n    data2[\"source_len\"] = len(data2[\"all_characters\"])\n    data2[\"target_len\"] = len(data2[\"all_characters_2\"])\n        \n    return data2\n    \n    \ndata2 = pre_processing_validation(copy.copy(val_input),copy.copy(val_output))\n# print(data[\"all_characters\"])\n# print(data[\"char_num_map\"])\n# print(data[\"num_char_map\"])\n# print(data[\"all_characters_2\"])\n# print(data[\"char_num_map_2\"])\n# print(data[\"num_char_map_2\"])\nprint(data2[\"num_char_map\"])\nprint(data2[\"source_charToNum\"].shape)\n\nprint(data2[\"num_char_map_2\"])\nprint(data2['val_charToNum'][0])\n\n\nprint(val_input[0])\nprint(data2['source_len'])\nprint(data2['target_len'])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:35.883633Z","iopub.execute_input":"2024-05-16T10:41:35.884245Z","iopub.status.idle":"2024-05-16T10:41:36.418660Z","shell.execute_reply.started":"2024-05-16T10:41:35.884210Z","shell.execute_reply":"2024-05-16T10:41:36.417603Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{0: '{', 23: 'b', 20: 'h', 8: 'e', 10: 's', 15: 'm', 17: 'u', 12: 'd', 6: 'i', 7: 'n', 9: '}', 1: 'v', 22: 'y', 2: 'a', 21: 'k', 14: 'c', 11: 't', 3: 'r', 19: 'p', 5: 'l', 16: 'o', 4: 'g', 24: 'j', 18: 'w', 26: 'x', 13: 'f', 25: 'z', 27: 'q'}\ntorch.Size([4096, 30])\n{0: '{', 37: 'భ', 42: 'ీ', 32: 'ష', 3: '్', 18: 'మ', 24: 'ు', 29: 'డ', 7: 'ి', 8: 'న', 10: '}', 1: 'వ', 15: 'య', 5: 'ా', 11: 'స', 16: 'క', 27: 'చ', 12: 'త', 2: 'ర', 26: 'ం', 22: 'ప', 6: 'ల', 20: 'ూ', 49: 'థ', 33: 'ఆ', 35: 'శ', 40: 'హ', 19: 'ో', 4: 'గ', 41: 'జ', 13: 'ద', 34: 'ొ', 28: 'ై', 9: 'ే', 46: 'ఒ', 25: 'ె', 17: 'ట', 39: 'ణ', 43: 'ఇ', 38: 'ృ', 54: 'ఓ', 23: 'ధ', 45: 'ఐ', 47: 'ఎ', 36: 'అ', 44: 'బ', 52: 'ఏ', 14: 'ఫ', 31: 'ఉ', 30: 'ఖ', 21: 'ళ', 51: 'ఊ', 48: 'ౌ', 55: 'ఔ', 57: 'ఠ', 58: 'ఘ', 56: 'ఞ', 50: 'ఈ', 59: 'ఛ', 62: 'ఋ', 60: 'ః', 53: 'ఢ'}\ntensor([ 0, 37, 42, 32,  3, 18, 24, 29,  7,  8,  7, 10, 10, 10, 10, 10, 10, 10,\n        10, 10, 10, 10, 10], device='cuda:0', dtype=torch.int32)\nbheeshmudini\n28\n62\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, x,y):\n        self.source = x\n        self.target = y\n    \n    def __len__(self):\n        return len(self.source)\n    \n    def __getitem__(self, idx):\n        source_data = self.source[idx]\n        target_data = self.target[idx]\n        return source_data, target_data","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:41.849959Z","iopub.execute_input":"2024-05-16T10:41:41.850332Z","iopub.status.idle":"2024-05-16T10:41:41.857934Z","shell.execute_reply.started":"2024-05-16T10:41:41.850300Z","shell.execute_reply":"2024-05-16T10:41:41.856851Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def heat_map_generation(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n    \n    data3 = pre_processing_validation(copy.copy(test_input),copy.copy(test_output))\n    \n    dataset = MyDataset(data[\"source_charToNum\"],data3['val_charToNum'])\n    dataLoader = DataLoader(dataset, batch_size=batchsize, shuffle=True)\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    \n    \n    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n        if(bidirection == \"Yes\"):\n            reversed_batch = torch.flip(sourceBatch, dims=[1]) # reverse the batch across rows.\n            sourceBatch = (sourceBatch + reversed_batch)//2 # adding reversed data to source data by averaging\n\n        if(cellType == 'LSTM'):\n            encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n\n        encoderStates , encoderOutput = encoder(sourceBatch,encoder_initial_state)\n\n        decoderCurrentState = encoderOutput # this selects the last state from encoder states\n\n        encoderFinalLayerStates = encoderStates[:, -1, :, :]\n\n        \n\n        loss = 0 # decoder starts\n            \n        outputSeqLen = targetBatch.shape[1] # here you will get as name justified. 40\n        \n        Output = []\n        #print(targetBatch)\n\n        randNumber = random.random()\n        \n        for i in range(0,outputSeqLen):\n            \n            if(i == 0):\n                decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n                #decoder_input_tensor = targetBatch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n                    #decoder_input_tensor = targetBatch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n                    #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n            \n            for j in range (0,10):\n                temp = []\n                if(i<length[j]):\n                    for k in range(0,30):\n                        temp.append(attentionWeights[j][0][k].item())\n                    attentions[j].append(temp)\n                \n            dummy, topi = decoderOutput.topk(1)\n    \n            decoderOutput = decoderOutput[:, -1, :]\n            curr_target_chars = targetBatch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            loss+=(lossFunction(decoderOutput, curr_target_chars))\n\n            decoderCurrentInput = topi.squeeze().detach()\n            Output.append(decoderCurrentInput)\n\n            # tensor_2d = torch.stack(Output)\n            # Output = tensor_2d.t() #it is outside the for loop\n        validation_loss += (loss.item()/outputSeqLen)\n\n        break\n        tensor_2d = torch.stack(Output)\n        Output = tensor_2d.t()\n        \n        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n        \n#         if(batch_num%40 == 0):\n#             print(\"bt:\", batch_num, \" loss:\", loss.item()/outputSeqLen)\n          \n    'l'/24\n    encoder.train()\n    decoder.train()\n    print(\"validation_accuracy\",validation_accuracy/40.96)\n    print(\"validation_loss\",validation_loss)\n#     wandb.log({'validation_accuracy':validation_accuracy/40.96})\n#     wandb.log({'validation_loss':validation_loss})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection):\n    \n    dataLoader = dataLoaderFun(\"validation\",batchsize) # dataLoader depending on train or validation\n    \n    encoder.eval()\n    decoder.eval()\n    \n    validation_accuracy = 0\n    validation_loss = 0\n    \n    lossFunction = nn.NLLLoss()\n    \n    for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n        \n        encoder_initial_state = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n        if(bidirection == \"Yes\"):\n            reversed_batch = torch.flip(sourceBatch, dims=[1]) # reverse the batch across rows.\n            sourceBatch = (sourceBatch + reversed_batch)//2 # adding reversed data to source data by averaging\n\n        if(cellType == 'LSTM'):\n            encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n\n        encoderStates , encoderOutput = encoder(sourceBatch,encoder_initial_state)\n\n        decoderCurrentState = encoderOutput # this selects the last state from encoder states\n\n        encoderFinalLayerStates = encoderStates[:, -1, :, :]\n\n        attentions = []\n\n        loss = 0 # decoder starts\n            \n        outputSeqLen = targetBatch.shape[1] # here you will get as name justified. 40\n        \n        Output = []\n        #print(targetBatch)\n\n        randNumber = random.random()\n\n\n        for i in range(0,outputSeqLen):\n            \n            if(i == 0):\n                decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n                #decoder_input_tensor = targetBatch[:, i].reshape(batchsize,1) #32*1\n                #print(dec_input_tensor.shape)\n            else:\n                if randNumber < tf_ratio:\n                    decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n                    #decoder_input_tensor = targetBatch[:, i].reshape(batchsize, 1) # current batch is passed\n                else:\n                    decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n                    #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n            decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n\n            attentions.append(attentionWeights)\n            dummy, topi = decoderOutput.topk(1)\n    \n            decoderOutput = decoderOutput[:, -1, :]\n            curr_target_chars = targetBatch[:, i] #(32)\n            curr_target_chars = curr_target_chars.type(dtype=torch.long)\n            loss+=(lossFunction(decoderOutput, curr_target_chars))\n\n            decoderCurrentInput = topi.squeeze().detach()\n            Output.append(decoderCurrentInput)\n\n            # tensor_2d = torch.stack(Output)\n            # Output = tensor_2d.t() #it is outside the for loop\n\n        validation_loss += (loss.item()/outputSeqLen)\n        \n        tensor_2d = torch.stack(Output)\n        Output = tensor_2d.t()\n        \n        validation_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n        \n        if(batch_num%40 == 0):\n            print(\"bt:\", batch_num, \" loss:\", loss.item()/outputSeqLen)\n            #'k'/24\n            # here you get the actual word letters seqeunces softamx indeces\n            #[[0,1,2],[0,1,2]] = [shr,ram] 32*40\n            #correct = (Output == targetBatch).all(dim=1).sum().item()\n            #accuracy = accuracy + correct           \n    encoder.train()\n    decoder.train()\n    print(\"validation_accuracy\",validation_accuracy/40.96)\n    print(\"validation_loss\",validation_loss)\n    wandb.log({'validation_accuracy':validation_accuracy/40.96})\n    wandb.log({'validation_loss':validation_loss})","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:49.594628Z","iopub.execute_input":"2024-05-16T10:41:49.594962Z","iopub.status.idle":"2024-05-16T10:41:49.615980Z","shell.execute_reply.started":"2024-05-16T10:41:49.594937Z","shell.execute_reply":"2024-05-16T10:41:49.614523Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hiddenSize):\n        super(Attention, self).__init__()\n        self.Watt = nn.Linear(hiddenSize, hiddenSize)\n        self.Uatt = nn.Linear(hiddenSize, hiddenSize)\n        self.Vatt = nn.Linear(hiddenSize, 1)\n\n    def forward(self, query, keys):\n        calc = self.Watt(query) + self.Uatt(keys)\n        scores = self.Vatt(torch.tanh(calc))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:53.236370Z","iopub.execute_input":"2024-05-16T10:41:53.237362Z","iopub.status.idle":"2024-05-16T10:41:53.248285Z","shell.execute_reply.started":"2024-05-16T10:41:53.237323Z","shell.execute_reply":"2024-05-16T10:41:53.247091Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    \n    def __init__(self,inputDim,embSize,encoderLayers,hiddenLayerNuerons,cellType,batch_size):\n        super(Encoder, self).__init__()\n        self.embedding = nn.Embedding(inputDim, embSize)\n        self.encoderLayers = encoderLayers\n        self.hiddenLayerNuerons = hiddenLayerNuerons\n        self.batch_size = batch_size\n        self.cellType = cellType\n        if(cellType=='GRU'):\n            self.rnn = nn.GRU(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        elif(cellType=='RNN'):\n            self.rnn = nn.RNN(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize,hiddenLayerNuerons,num_layers=encoderLayers, batch_first=True)\n\n    def forward(self,sourceBatch,encoderCurrState):\n        sequenceLength = len(sourceBatch[0])\n        encoderStates = torch.zeros(sequenceLength,self.encoderLayers,self.batch_size,self.hiddenLayerNuerons,device=device)\n        for i in range(0,sequenceLength):\n            currInput = sourceBatch[:,i].reshape(self.batch_size,1)\n            dummy , encoderCurrState = self.statesCalculation(currInput,encoderCurrState)\n            if(self.cellType == 'LSTM'):\n                encoderStates[i] = encoderCurrState[1]\n            else: \n                encoderStates[i] = encoderCurrState\n\n        return encoderStates ,encoderCurrState\n\n\n    def statesCalculation(self, currentInput, prevState):\n        embdInput = self.embedding(currentInput)\n        output, prev_state = self.rnn(embdInput, prevState)\n        return output, prev_state\n    \n    def getInitialState(self):\n        return torch.zeros(self.encoderLayers,self.batch_size,self.hiddenLayerNuerons, device=device)\n    \nclass Decoder(nn.Module):\n    def __init__(self,outputDim,embSize,hiddenLayerNuerons,decoderLayers,cellType,dropout_p):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(outputDim, embSize)\n        self.cellType=cellType\n        if(cellType == 'GRU'): # changed here\n            self.rnn = nn.GRU(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        elif(cellType == 'RNN'):\n            self.rnn = nn.RNN(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n        else:\n            self.rnn = nn.LSTM(embSize+hiddenLayerNuerons,hiddenLayerNuerons,num_layers=decoderLayers, batch_first=True)\n            \n        self.fc = nn.Linear(hiddenLayerNuerons, outputDim) # it is useful for mapping the calculation to vocabularu\n        self.softmax = nn.LogSoftmax(dim=2) #output is in 3rd column \n        self.dropout = nn.Dropout(dropout_p)\n        self.attention = Attention(hiddenLayerNuerons).to(device)\n\n    def forward(self, current_input, prev_state,encoder_final_layers):\n        if(self.cellType == 'LSTM'):\n            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)\n        else:\n            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n        embd_input = self.embedding(current_input)\n        curr_embd = F.relu(embd_input)\n        input_gru = torch.cat((curr_embd, context), dim=2)\n        output, prev_state = self.rnn(input_gru, prev_state)\n        output = self.dropout(output)\n        output = self.softmax(self.fc(output)) \n        return output, prev_state, attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:41:55.425506Z","iopub.execute_input":"2024-05-16T10:41:55.426163Z","iopub.status.idle":"2024-05-16T10:41:55.446145Z","shell.execute_reply.started":"2024-05-16T10:41:55.426129Z","shell.execute_reply":"2024-05-16T10:41:55.445225Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pre_processing(copy.copy(train_input),copy.copy(train_output))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:42:04.247396Z","iopub.execute_input":"2024-05-16T10:42:04.248275Z","iopub.status.idle":"2024-05-16T10:42:11.639645Z","shell.execute_reply.started":"2024-05-16T10:42:04.248241Z","shell.execute_reply":"2024-05-16T10:42:11.638535Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def dataLoaderFun(dataName,batch_size):\n    if(dataName == 'train'):\n        dataset = MyDataset(data[\"source_charToNum\"],data['val_charToNum'])\n        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    else:\n        dataset = MyDataset(data2[\"source_charToNum\"],data2['val_charToNum'])\n        return  DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:42:01.873304Z","iopub.execute_input":"2024-05-16T10:42:01.873684Z","iopub.status.idle":"2024-05-16T10:42:01.880899Z","shell.execute_reply.started":"2024-05-16T10:42:01.873652Z","shell.execute_reply":"2024-05-16T10:42:01.879806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(embSize,encoderLayers,decoderLayers,hiddenLayerNuerons,cellType,bidirection,dropout,epochs,batchsize,learningRate,optimizer,tf_ratio):\n    #add optimizer,tf_ratio to wandb parameters\n    \n    dataLoader = dataLoaderFun(\"train\",batchsize) # dataLoader depending on train or validation\n    \n    encoder = Encoder(data[\"source_len\"],embSize,encoderLayers,hiddenLayerNuerons,cellType,batchsize).to(device)\n    decoder = Decoder(data[\"target_len\"],embSize,hiddenLayerNuerons,encoderLayers,cellType,dropout).to(device)\n    \n    # done till here\n    if(optimizer == 'Adam'):\n        encoderOptimizer = optim.Adam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.Adam(decoder.parameters(), lr=learningRate)\n    else:\n        encoderOptimizer = optim.NAdam(encoder.parameters(), lr=learningRate)\n        decoderOptimizer = optim.NAdam(decoder.parameters(), lr=learningRate)\n    \n    lossFunction = nn.NLLLoss()\n\n    for epoch in range (0,epochs):\n    \n        train_accuracy = 0 \n        train_loss = 0 \n\n        for batch_num, (sourceBatch, targetBatch) in enumerate(dataLoader):\n                        \n            encoderInitialState = encoder.getInitialState() #hiddenlayers * BatchSize * Neurons\n            \n            if(bidirection == \"Yes\"):\n                reversed_batch = torch.flip(sourceBatch, dims=[1]) # reverse the batch across rows.\n                sourceBatch = (sourceBatch + reversed_batch)//2 # adding reversed data to source data by averaging\n            \n            if(cellType == 'LSTM'):\n                encoderInitialState = (encoderInitialState, encoder.getInitialState())\n                \n            encoderStates,EcoderOutput= encoder(sourceBatch,encoderInitialState)\n\n            encoderFinalLayerStates = encoderStates[:, -1, :, :] # this selects the hidden top layers from each sequence\n\n            decoderCurrentState = EcoderOutput            \n            attentions = []\n            loss = 0 # decoder starts form \n            \n            outputSeqLen = targetBatch.shape[1] # here you will get as name justified. 40\n            \n            Output = []\n            #print(targetBatch)\n            \n            randNumber = random.random()\n\n            \n\n            for i in range(0,outputSeqLen):\n\n                if(i == 0):\n                    decoderCurrentInput = torch.full((batchsize,1),0, device=device)\n                    #decoder_input_tensor = targetBatch[:, i].reshape(batchsize,1) #32*1\n                    #print(dec_input_tensor.shape)\n                else:\n                    if randNumber < tf_ratio:\n                        decoderCurrentInput = targetBatch[:, i].reshape(batchsize, 1)\n                        #decoder_input_tensor = targetBatch[:, i].reshape(batchsize, 1) # current batch is passed\n                    else:\n                        decoderCurrentInput = decoderCurrentInput.reshape(batchsize, 1)\n                        #decoder_input_tensor = decoder_input_tensor.reshape(batchsize, 1) # prev result is passed\n\n                decoderOutput, decoderCurrentState, attentionWeights = decoder(decoderCurrentInput, decoderCurrentState, encoderFinalLayerStates)\n                \n                dummy, topIndeces = decoderOutput.topk(1)\n\n                decoderOutput = decoderOutput[:, -1, :]\n                curr_target_chars = targetBatch[:, i] #(32)\n                curr_target_chars = curr_target_chars.type(dtype=torch.long)\n                loss+=(lossFunction(decoderOutput, curr_target_chars))\n\n                \n                decoderCurrentInput = topIndeces.squeeze().detach()\n                Output.append(decoderCurrentInput)\n\n                attentions.append(attentionWeights)\n\n            tensor_2d = torch.stack(Output)\n            Output = tensor_2d.t() \n            train_accuracy += (Output == targetBatch).all(dim=1).sum().item()\n            \n            # tensor_2d = torch.stack(Output)\n            # Output = tensor_2d.t() #it is outside the for loop\n            # #print(Output) #32*40\n            # if(batch_num == 0 and epoch == epochs-1):\n            #     numToCharConverter(targetBatch,Output,data) \n                \n            # train_accuracy += (Output == targetBatch).all(dim=1).sum().item() # it is simple just summing up the equal values\n\n            train_loss += (loss.item()/outputSeqLen)\n            \n            if(batch_num%200 == 0):\n                print(\"bt:\", batch_num, \" loss:\", loss.item()/outputSeqLen)\n                \n            encoderOptimizer.zero_grad()\n            decoderOptimizer.zero_grad()\n            loss.backward()\n            encoderOptimizer.step()\n            decoderOptimizer.step()\n            \n        print(\"train_accuracy\",train_accuracy/512)\n        print(\"train_loss\",train_loss)\n        wandb.log({'train_accuracy':train_accuracy/512})\n        wandb.log({'train_loss':train_loss})\n        validationAccuracy(encoder,decoder,batchsize,tf_ratio,cellType,bidirection)\n        #heat_map_generation(encoder,decoder,batchsize,tf_ratio,cellType,bidirection)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:42:12.324660Z","iopub.execute_input":"2024-05-16T10:42:12.324999Z","iopub.status.idle":"2024-05-16T10:42:12.347201Z","shell.execute_reply.started":"2024-05-16T10:42:12.324974Z","shell.execute_reply":"2024-05-16T10:42:12.346174Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def main_fun():\n    wandb.init(project ='AttentionRNN')\n    params = wandb.config\n    with wandb.init(project = 'AttentionRNN', name='embedding'+str(params.embSize)+'cellType'+params.cellType+'batchSize'+str(params.batchsize)) as run:\n        train(params.embSize,params.encoderLayers,params.decoderLayers,params.hiddenLayerNuerons,params.cellType,params.bidirection,params.dropout,params.epochs,params.batchsize,params.learningRate,params.optimizer,params.tf_ratio)\n    \nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DeepLearningAssignmentAttention3',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'validation_accuracy',\n    },\n    'parameters' : {\n        'embSize':{'values':[16,32,64]},\n        'encoderLayers':{'values':[1,5,10]},\n        'decoderLayers' : {'values' : [1,5,10]},\n        'hiddenLayerNuerons'   : {'values' : [64,256,512]},\n        'cellType' : {'values' : ['GRU','RNN'] } ,\n        'bidirection' : {'values' : ['no','Yes']},\n        'dropout' : {'values' : [0,0.2,0.3]},\n        'epochs'  : {'values': [10,15]},\n        'batchsize' : {'values' : [32,64]},\n        'learningRate' : {'values' : [1e-2,1e-3,1e-4]},\n        'optimizer':{'values' : ['Adam','Nadam']},\n        'tf_ratio' :{'values' : [0.2,0.4,0.5]}\n    }\n}\nsweepId = wandb.sweep(sweep_params,project = 'AttentionRNN')\nwandb.agent(sweepId,function =main_fun,count = 10)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:42:19.985128Z","iopub.execute_input":"2024-05-16T10:42:19.985507Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: nf9cjyla\nSweep URL: https://wandb.ai/dlassignment/AttentionRNN/sweeps/nf9cjyla\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqhtyzyy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchsize: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirection: Yes\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcellType: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoderLayers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembSize: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoderLayers: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenLayerNuerons: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: Nadam\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttf_ratio: 0.5\n","output_type":"stream"},{"name":"stdout","text":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))\n<IPython.core.display.HTML object>\n<IPython.core.display.HTML object>\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\nException in thread ChkStopThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\nException in thread NetStatThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self._loop_check_status(\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\nException in thread IntMsgThr:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n    return self._deliver_stop_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n        self._target(*self._args, **self._kwargs)self._loop_check_status(\n    \n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\nreturn self._deliver_record(record)  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n\n      File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\nself._loop_check_status(    \n    local_handle = request()  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\nhandle = mailbox._deliver_record(record, interface=self)\n\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    local_handle = request()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    return self._deliver_network_status(status)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n    return self._deliver_internal_messages(internal_message)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    return self._deliver_record(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    handle = mailbox._deliver_record(record, interface=self)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    interface._publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._sock_client.send_record_publish(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n    self.send_server_request(server_req)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._send_message(msg)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    self._sendall_with_error_handle(header + data)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n    sent = self._sock.send(data)\nBrokenPipeError: [Errno 32] Broken pipe\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240516_104228-eqhtyzyy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dlassignment/AttentionRNN/runs/eqhtyzyy' target=\"_blank\">kind-sweep-1</a></strong> to <a href='https://wandb.ai/dlassignment/AttentionRNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dlassignment/AttentionRNN/sweeps/nf9cjyla' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN/sweeps/nf9cjyla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dlassignment/AttentionRNN' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/dlassignment/AttentionRNN/sweeps/nf9cjyla' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN/sweeps/nf9cjyla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dlassignment/AttentionRNN/runs/eqhtyzyy' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN/runs/eqhtyzyy</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:eqhtyzyy) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">kind-sweep-1</strong> at: <a href='https://wandb.ai/dlassignment/AttentionRNN/runs/eqhtyzyy' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN/runs/eqhtyzyy</a><br/> View project at: <a href='https://wandb.ai/dlassignment/AttentionRNN' target=\"_blank\">https://wandb.ai/dlassignment/AttentionRNN</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240516_104228-eqhtyzyy/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:eqhtyzyy). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112547699991007, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511a66c97aa748cbb3096cb8ce79d204"}},"metadata":{}}]}]}